{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: d:\\Study Stuff\\RAG model\\Implementation Locally\\venv_py312\\Scripts\\python.exe\n",
      "Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n",
      "‚úÖ Using venv_py312 virtual environment\n"
     ]
    }
   ],
   "source": [
    "# Check which Python executable is being used\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if we're in the venv\n",
    "if 'venv_py312' in sys.executable:\n",
    "    print(\"‚úÖ Using venv_py312 virtual environment\")\n",
    "else:\n",
    "    print(\"‚ùå NOT using venv_py312 - using global Python installation\")\n",
    "    print(f\"   Expected path should contain: venv_py312\")\n",
    "    print(f\"   Actual path: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding RAG (Retrieval Augmented Generation) Implementation\n",
    "\n",
    "RAG combines two main components:\n",
    "1. **Retrieval**: Finding relevant information from a knowledge base\n",
    "2. **Generation**: Using that information to generate accurate answers\n",
    "\n",
    "## Phase 1: Setup and Data Preparation\n",
    "- Loading and processing documents\n",
    "- Converting text into chunks\n",
    "- Creating embeddings for efficient searching\n",
    "- Setting up the language model for generation\n",
    "\n",
    "Let's go through each step in detail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "This section sets up all required dependencies and configurations for the Hugging Face environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing PyTorch with CUDA 12.4 support...\n",
      "PyTorch with CUDA support installed!\n",
      "Installing huggingface_hub...\n",
      "huggingface_hub installed successfully!\n",
      "Installing transformers...\n",
      "transformers installed successfully!\n",
      "Installing accelerate...\n",
      "accelerate installed successfully!\n",
      "Installing bitsandbytes...\n",
      "bitsandbytes installed successfully!\n",
      "Installing sentencepiece...\n",
      "sentencepiece installed successfully!\n",
      "Installing requests...\n",
      "requests installed successfully!\n",
      "All required packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install CUDA-enabled PyTorch\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Installing PyTorch with CUDA 12.4 support...\")\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \n",
    "                       \"torch\", \"--index-url\", \"https://download.pytorch.org/whl/cu124\", \"-q\"])\n",
    "print(\"PyTorch with CUDA support installed!\")\n",
    "\n",
    "# Install required packages\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"{package} installed successfully!\")\n",
    "\n",
    "# Install essential packages\n",
    "packages = [\n",
    "    \"huggingface_hub\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"bitsandbytes\",\n",
    "    \"sentencepiece\",\n",
    "    \"safetensors\",\n",
    "    \"requests\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"All required packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing PyTorch with CUDA 12.1 support...\n",
      "PyTorch with CUDA 12.1 support installed!\n",
      "\n",
      "‚úÖ CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch with CUDA 12.1 support (compatible with your CUDA 13.1)\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Installing PyTorch with CUDA 12.1 support...\")\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \n",
    "                       \"torch\", \"torchvision\", \"torchaudio\", \n",
    "                       \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
    "print(\"PyTorch with CUDA 12.1 support installed!\")\n",
    "\n",
    "# Verify CUDA is available\n",
    "import torch\n",
    "print(f\"\\n‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GPU AVAILABILITY CHECK & CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "üìä System Information:\n",
      "  PyTorch Version: 2.5.1+cu121\n",
      "\n",
      "üîß NVIDIA Driver Information:\n",
      "\n",
      "‚úÖ GPU IS AVAILABLE AND READY!\n",
      "  Number of GPUs: 1\n",
      "  GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "  GPU Memory: 4.00 GB\n",
      "  CUDA Version: 12.1\n",
      "  Current GPU Memory Used: 3.81 MB\n",
      "\n",
      "üì¶ Optional Libraries:\n",
      "  BitsAndBytes: ‚úì Available (for 4-bit/8-bit quantization)\n",
      "\n",
      "‚ú® GPU Environment Ready!\n",
      "  Device: CUDA\n",
      "  PyTorch: 2.5.1+cu121\n",
      "  Transformers: 5.0.0\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA availability and setup GPU settings\n",
    "import torch\n",
    "import transformers\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GPU AVAILABILITY CHECK & CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verify CUDA is available - REQUIRED for this notebook\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available! This notebook requires GPU acceleration. \"\n",
    "                       \"Please ensure you have PyTorch installed with CUDA support.\")\n",
    "\n",
    "print(\"\\nüìä System Information:\")\n",
    "print(f\"  PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Check NVIDIA driver\n",
    "print(\"\\nüîß NVIDIA Driver Information:\")\n",
    "os.system(\"nvidia-smi --query-gpu=name,driver_version,cuda_version --format=csv,noheader\")\n",
    "\n",
    "# Set GPU device\n",
    "device = \"cuda\"\n",
    "gpu_count = torch.cuda.device_count()\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "\n",
    "print(f\"\\n‚úÖ GPU IS AVAILABLE AND READY!\")\n",
    "print(f\"  Number of GPUs: {gpu_count}\")\n",
    "print(f\"  GPU Name: {gpu_name}\")\n",
    "print(f\"  GPU Memory: {gpu_memory:.2f} GB\")\n",
    "if torch.version.cuda:\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Test GPU\n",
    "test_tensor = torch.randn(1000, 1000, device=device)\n",
    "allocated = torch.cuda.memory_allocated() / (1024**2)\n",
    "print(f\"  Current GPU Memory Used: {allocated:.2f} MB\")\n",
    "del test_tensor\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set default device\n",
    "torch.set_default_device(device)\n",
    "\n",
    "# Check BitsAndBytes\n",
    "try:\n",
    "    import bitsandbytes\n",
    "    print(f\"\\nüì¶ Optional Libraries:\")\n",
    "    print(f\"  BitsAndBytes: ‚úì Available (for 4-bit/8-bit quantization)\")\n",
    "except ImportError:\n",
    "    print(f\"\\nüì¶ Optional Libraries:\")\n",
    "    print(f\"  BitsAndBytes: ‚úó Not available\")\n",
    "\n",
    "print(f\"\\n‚ú® GPU Environment Ready!\")\n",
    "print(f\"  Device: {device.upper()}\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  Transformers: {transformers.__version__}\")\n",
    "print(\"=\" * 70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "# Install huggingface_hub if not already installed\n",
    "try:\n",
    "    import huggingface_hub\n",
    "except ImportError:\n",
    "    print(\"Installing huggingface_hub...\")\n",
    "    !pip install --quiet huggingface_hub\n",
    "\n",
    "# Authenticate with Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login with the token (never share or commit this token)\n",
    "login(token=\"YOUR_HF_TOKEN_HERE\")\n",
    "print(\"Successfully logged in to Hugging Face!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GPU CONFIGURATION (CUDA Required)\n",
      "======================================================================\n",
      "\n",
      "‚úÖ CUDA Available - GPU Mode Enabled\n",
      "   Device: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   Memory: 4.0 GB\n",
      "\n",
      "üöÄ Applying GPU Optimizations...\n",
      "  ‚úì CuDNN auto-tuning enabled\n",
      "  ‚úì Flash Attention enabled (faster, lower memory)\n",
      "  ‚úì CUDA memory optimization enabled\n",
      "  ‚úì Memory fraction set to 90%\n",
      "  ‚úì GPU cache cleared\n",
      "\n",
      "======================================================================\n",
      "üéØ Ready for GPU acceleration! Starting embeddings on GPU...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GPU Configuration - CUDA Required\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GPU CONFIGURATION (CUDA Required)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verify CUDA is available\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available! Please install Python 3.13 with PyTorch CUDA support.\")\n",
    "\n",
    "print(\"\\n‚úÖ CUDA Available - GPU Mode Enabled\")\n",
    "print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# GPU Optimization Settings\n",
    "print(\"\\nüöÄ Applying GPU Optimizations...\")\n",
    "\n",
    "# Enable cuDNN auto-tuner for best performance\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"  ‚úì CuDNN auto-tuning enabled\")\n",
    "\n",
    "# Enable Flash Attention for faster computations\n",
    "torch.backends.cuda.enable_flash_sdp(True)\n",
    "print(\"  ‚úì Flash Attention enabled (faster, lower memory)\")\n",
    "\n",
    "# Memory efficient mode\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "print(\"  ‚úì CUDA memory optimization enabled\")\n",
    "\n",
    "# For RTX 3050 (4GB VRAM), use 90% of available memory\n",
    "torch.cuda.set_per_process_memory_fraction(0.9)\n",
    "print(\"  ‚úì Memory fraction set to 90%\")\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "print(\"  ‚úì GPU cache cleared\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéØ Ready for GPU acceleration! Starting embeddings on GPU...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Setup Status\n",
    "\n",
    "### Current Status\n",
    "- **GPU Detected**: ‚úÖ NVIDIA RTX 3050 (4GB VRAM)\n",
    "- **NVIDIA Drivers**: ‚úÖ Installed (CUDA 13.1 capable)\n",
    "- **PyTorch CUDA Support**: ‚ùå Not available for Python 3.14\n",
    "\n",
    "### Issue\n",
    "PyTorch 2.10.0 is compiled only for Python 3.13 and earlier. Python 3.14 requires newer PyTorch versions that aren't available yet on PyPI.\n",
    "\n",
    "### Solutions\n",
    "\n",
    "**Option 1: Use PyTorch CPU (Current)**\n",
    "- Processing will use your CPU\n",
    "- For embeddings with sentence-transformers, you can still use quantization\n",
    "- Takes longer but produces same results\n",
    "\n",
    "**Option 2: Downgrade Python (Recommended for GPU)**\n",
    "```bash\n",
    "# Install Python 3.13\n",
    "python -m pip install --upgrade \"python<3.14\"\n",
    "# Then reinstall PyTorch with CUDA support\n",
    "```\n",
    "\n",
    "**Option 3: Build PyTorch from source**\n",
    "- Advanced option, requires CUDA toolkit and compiler\n",
    "- See: https://github.com/pytorch/pytorch#from-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell will ask for your Hugging Face token (it will not be saved to disk).\n",
      "If you prefer to use an environment variable or the CLI, leave the token blank and press enter.\n",
      "[CONFIG] Token set in-kernel for this session.\n",
      "\n",
      "[NOTICE] The default model is a gated model. Make sure you have accepted its terms on Hugging Face and that your token has access.\n",
      "If you have not agreed to the model terms, consider using an open model like \"sshleifer/tiny-gpt2\" for testing.\n",
      "\n",
      "[CONFIG] model_id=google/gemma-2b-it\n",
      "[CONFIG] use_quantization_config=True\n"
     ]
    }
   ],
   "source": [
    "# Notebook config: prompt for HF token and model selection (safer ‚Äî no plaintext tokens saved)\n",
    "# This cell will run interactively in the notebook. It sets the token only for the running kernel.\n",
    "# Do NOT commit this notebook to version control if you enter a real token.\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "print(\"This cell will ask for your Hugging Face token (it will not be saved to disk).\")\n",
    "print(\"If you prefer to use an environment variable or the CLI, leave the token blank and press enter.\")\n",
    "\n",
    "try:\n",
    "    token = getpass.getpass(prompt='Enter Hugging Face token (leave blank to skip): ')\n",
    "except Exception:\n",
    "    # In some notebook frontends getpass may not work; fall back to input with a warning\n",
    "    print(\"Warning: secure prompt unavailable, using visible input.\")\n",
    "    token = input('Enter Hugging Face token (leave blank to skip): ')\n",
    "\n",
    "if token:\n",
    "    os.environ['HUGGINGFACE_HUB_TOKEN'] = token\n",
    "    print('[CONFIG] Token set in-kernel for this session.')\n",
    "else:\n",
    "    print('[CONFIG] No token provided. Will use existing environment or anonymous access.')\n",
    "\n",
    "# Prompt for model_id with a sensible default. Use an open model for quick testing if unsure.\n",
    "def _input_with_default(prompt, default):\n",
    "    resp = input(f\"{prompt} [{default}]: \").strip()\n",
    "    return resp if resp else default\n",
    "\n",
    "default_model = 'google/gemma-2b-it'  # gated by default\n",
    "chosen_model = _input_with_default('Model id to use (enter a model id or press enter for default)', default_model)\n",
    "\n",
    "if chosen_model == default_model:\n",
    "    print('\\n[NOTICE] The default model is a gated model. Make sure you have accepted its terms on Hugging Face and that your token has access.')\n",
    "    print('If you have not agreed to the model terms, consider using an open model like \"sshleifer/tiny-gpt2\" for testing.')\n",
    "\n",
    "# Ask about quantization\n",
    "use_q = _input_with_default('Use 4-bit quantization (y/N)', 'N')\n",
    "use_quantization_config = use_q.lower().startswith('y')\n",
    "\n",
    "# Publish into notebook globals so downstream cells can read them\n",
    "globals()['model_id'] = chosen_model\n",
    "globals()['use_quantization_config'] = use_quantization_config\n",
    "\n",
    "print(f\"\\n[CONFIG] model_id={chosen_model}\")\n",
    "print(f\"[CONFIG] use_quantization_config={use_quantization_config}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face Authentication\n",
    "First, we'll set up authentication with Hugging Face to access the models. You'll need to provide your Hugging Face token, which you can get from [your Hugging Face account settings](https://huggingface.co/settings/tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "# Install huggingface_hub if not already installed\n",
    "try:\n",
    "    import huggingface_hub\n",
    "except ImportError:\n",
    "    print(\"Installing huggingface_hub...\")\n",
    "    !pip install --quiet huggingface_hub\n",
    "\n",
    "# Authenticate with Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login with the token (never share or commit this token)\n",
    "login(token=\"YOUR_HF_TOKEN_HERE\")\n",
    "print(\"Successfully logged in to Hugging Face!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mrdbourke/simple-local-rag/blob/main/00-simple-local-rag.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Create and run a local RAG pipeline from scratch\n",
    "\n",
    "The goal of this notebook is to build a RAG (Retrieval Augmented Generation) pipeline from scratch and have it run on a local GPU.\n",
    "\n",
    "Specifically, we'd like to be able to open a PDF file, ask questions (queries) of it and have them answered by a Large Language Model (LLM).\n",
    "\n",
    "There are frameworks that replicate this kind of workflow, including [LlamaIndex](https://www.llamaindex.ai/) and [LangChain](https://www.langchain.com/), however, the goal of building from scratch is to be able to inspect and customize all the parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is RAG?\n",
    "\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "\n",
    "It was introduced in the paper [*Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks*](https://arxiv.org/abs/2005.11401).\n",
    "\n",
    "Each step can be roughly broken down to:\n",
    "\n",
    "* **Retrieval** - Seeking relevant information from a source given a query. For example, getting relevant passages of Wikipedia text from a database given a question.\n",
    "* **Augmented** - Using the relevant retrieved information to modify an input to a generative model (e.g. an LLM).\n",
    "* **Generation** - Generating an output given an input. For example, in the case of an LLM, generating a passage of text given an input prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why RAG?\n",
    "\n",
    "The main goal of RAG is to improve the generation outptus of LLMs.\n",
    "\n",
    "Two primary improvements can be seen as:\n",
    "1. **Preventing hallucinations** - LLMs are incredible but they are prone to potential hallucination, as in, generating something that *looks* correct but isn't. RAG pipelines can help LLMs generate more factual outputs by providing them with factual (retrieved) inputs. And even if the generated answer from a RAG pipeline doesn't seem correct, because of retrieval, you also have access to the sources where it came from.\n",
    "2. **Work with custom data** - Many base LLMs are trained with internet-scale text data. This means they have a great ability to model language, however, they often lack specific knowledge. RAG systems can provide LLMs with domain-specific data such as medical information or company documentation and thus customized their outputs to suit specific use cases.\n",
    "\n",
    "The authors of the original RAG paper mentioned above outlined these two points in their discussion.\n",
    "\n",
    "> This work offers several positive societal benefits over previous work: the fact that it is more\n",
    "strongly grounded in real factual knowledge (in this case Wikipedia) makes it ‚Äúhallucinate‚Äù less\n",
    "with generations that are more factual, and offers more control and interpretability. RAG could be\n",
    "employed in a wide variety of scenarios with direct benefit to society, for example by endowing it\n",
    "with a medical index and asking it open-domain questions on that topic, or by helping people be more\n",
    "effective at their jobs.\n",
    "\n",
    "RAG can also be a much quicker solution to implement than fine-tuning an LLM on specific data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What kind of problems can RAG be used for?\n",
    "\n",
    "RAG can help anywhere there is a specific set of information that an LLM may not have in its training data (e.g. anything not publicly accessible on the internet).\n",
    "\n",
    "For example you could use RAG for:\n",
    "* **Customer support Q&A chat** - By treating your existing customer support documentation as a resource, when a customer asks a question, you could have a system retrieve relevant documentation snippets and then have an LLM craft those snippets into an answer. Think of this as a \"chatbot for your documentation\". Klarna, a large financial company, [uses a system like this](https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/) to save $40M per year on customer support costs.\n",
    "* **Email chain analysis** - Let's say you're an insurance company with long threads of emails between customers and insurance agents. Instead of searching through each individual email, you could retrieve relevant passages and have an LLM create strucutred outputs of insurance claims.\n",
    "* **Company internal documentation chat** - If you've worked at a large company, you know how hard it can be to get an answer sometimes. Why not let a RAG system index your company information and have an LLM answer questions you may have? The benefit of RAG is that you will have references to resources to learn more if the LLM answer doesn't suffice.\n",
    "* **Textbook Q&A** - Let's say you're studying for your exams and constantly flicking through a large textbook looking for answers to your quesitons. RAG can help provide answers as well as references to learn more.\n",
    "\n",
    "All of these have the common theme of retrieving relevant resources and then presenting them in an understandable way using an LLM.\n",
    "\n",
    "From this angle, you can consider an LLM a calculator for words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why local?\n",
    "\n",
    "Privacy, speed, cost.\n",
    "\n",
    "Running locally means you use your own hardware.\n",
    "\n",
    "From a privacy standpoint, this means you don't have send potentially sensitive data to an API.\n",
    "\n",
    "From a speed standpoint, it means you won't necessarily have to wait for an API queue or downtime, if your hardware is running, the pipeline can run.\n",
    "\n",
    "And from a cost standpoint, running on your own hardware often has a heavier starting cost but little to no costs after that.\n",
    "\n",
    "Performance wise, LLM APIs may still perform better than an open-source model running locally on general tasks but there are more and more examples appearing of smaller, focused models outperforming larger models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key terms\n",
    "\n",
    "| Term | Description |\n",
    "| ----- | ----- | \n",
    "| **Token** | A sub-word piece of text. For example, \"hello, world!\" could be split into [\"hello\", \",\", \"world\", \"!\"]. A token can be a whole word,<br> part of a word or group of punctuation characters. 1 token ~= 4 characters in English, 100 tokens ~= 75 words.<br> Text gets broken into tokens before being passed to an LLM. |\n",
    "| **Embedding** | A learned numerical representation of a piece of data. For example, a sentence of text could be represented by a vector with<br> 768 values. Similar pieces of text (in meaning) will ideally have similar values. |\n",
    "| **Embedding model** | A model designed to accept input data and output a numerical representation. For example, a text embedding model may take in 384 <br>tokens of text and turn it into a vector of size 768. An embedding model can and often is different to an LLM model. |\n",
    "| **Similarity search/vector search** | Similarity search/vector search aims to find two vectors which are close together in high-demensional space. For example, <br>two pieces of similar text passed through an embedding model should have a high similarity score, whereas two pieces of text about<br> different topics will have a lower similarity score. Common similarity score measures are dot product and cosine similarity. |\n",
    "| **Large Language Model (LLM)** | A model which has been trained to numerically represent the patterns in text. A generative LLM will continue a sequence when given a sequence. <br>For example, given a sequence of the text \"hello, world!\", a genertive LLM may produce \"we're going to build a RAG pipeline today!\".<br> This generation will be highly dependant on the training data and prompt. |\n",
    "| **LLM context window** | The number of tokens a LLM can accept as input. For example, as of March 2024, GPT-4 has a default context window of 32k tokens<br> (about 96 pages of text) but can go up to 128k if needed. A recent open-source LLM from Google, Gemma (March 2024) has a context<br> window of 8,192 tokens (about 24 pages of text). A higher context window means an LLM can accept more relevant information<br> to assist with a query. For example, in a RAG pipeline, if a model has a larger context window, it can accept more reference items<br> from the retrieval system to aid with its generation. |\n",
    "| **Prompt** | A common term for describing the input to a generative LLM. The idea of \"[prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering)\" is to structure a text-based<br> (or potentially image-based as well) input to a generative LLM in a specific way so that the generated output is ideal. This technique is<br> possible because of a LLMs capacity for in-context learning, as in, it is able to use its representation of language to breakdown <br>the prompt and recognize what a suitable output may be (note: the output of LLMs is probable, so terms like \"may output\" are used). | \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## What we're going to build\n",
    "\n",
    "We're going to build RAG pipeline which enables us to chat with a PDF document, specifically an open-source [nutrition textbook](https://pressbooks.oer.hawaii.edu/humannutrition2/), ~1200 pages long.\n",
    "\n",
    "You could call our project NutriChat!\n",
    "\n",
    "We'll write the code to:\n",
    "1. Open a PDF document (you could use almost any PDF here).\n",
    "2. Format the text of the PDF textbook ready for an embedding model (this process is known as text splitting/chunking).\n",
    "3. Embed all of the chunks of text in the textbook and turn them into numerical representation which we can store for later.\n",
    "4. Build a retrieval system that uses vector search to find relevant chunks of text based on a query.\n",
    "5. Create a prompt that incorporates the retrieved pieces of text.\n",
    "6. Generate an answer to a query based on passages from the textbook.\n",
    "\n",
    "The above steps can broken down into two major sections:\n",
    "1. Document preprocessing/embedding creation (steps 1-3).\n",
    "2. Search and answer (steps 4-6).\n",
    "\n",
    "And that's the structure we'll follow.\n",
    "\n",
    "It's similar to the workflow outlined on the NVIDIA blog which [details a local RAG pipeline](https://developer.nvidia.com/blog/rag-101-demystifying-retrieval-augmented-generation-pipelines/).\n",
    "\n",
    "<img src=\"https://github.com/mrdbourke/simple-local-rag/blob/main/images/simple-local-rag-workflow-flowchart.png?raw=true\" alt=\"flowchart of a local RAG workflow\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements and setup\n",
    "\n",
    "* Local NVIDIA GPU (I used a NVIDIA RTX 4090 on a Windows 11 machine) or Google Colab with access to a GPU.\n",
    "* Environment setup (see [setup details on GitHub](https://github.com/mrdbourke/simple-local-rag/?tab=readme-ov-file#setup)).\n",
    "* Data source (for example, a PDF). \n",
    "* Internet connection (to download the models, but once you have them, it'll run offline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Google Colab installs (if running in Google Colab)\n",
    "import os\n",
    "\n",
    "if \"COLAB_GPU\" in os.environ:\n",
    "    print(\"[INFO] Running in Google Colab, installing requirements.\")\n",
    "    !pip install -U torch # requires torch 2.1.1+ (for efficient sdpa implementation)\n",
    "    !pip install PyMuPDF # for reading PDFs with Python\n",
    "    !pip install tqdm # for progress bars\n",
    "    !pip install sentence-transformers # for embedding models\n",
    "    !pip install accelerate # for quantization model loading\n",
    "    !pip install bitsandbytes # for quantizing models (less storage space)\n",
    "    !pip install flash-attn --no-build-isolation # for faster attention mechanism = faster LLM inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document/Text Processing and Embedding Creation\n",
    "\n",
    "Ingredients:\n",
    "* PDF document of choice.\n",
    "* Embedding model of choice.\n",
    "\n",
    "Steps:\n",
    "1. Import PDF document.\n",
    "2. Process text for embedding (e.g. split into chunks of sentences).\n",
    "3. Embed text chunks with embedding model.\n",
    "4. Save embeddings to file for later use (embeddings will store on file for many years or until you lose your hard drive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PDF Document \n",
    "\n",
    "This will work with many other kinds of documents.\n",
    "\n",
    "However, we'll start with PDF since many people have PDFs.\n",
    "\n",
    "But just keep in mind, text files, email chains, support documentation, articles and more can also work.\n",
    "\n",
    "We're going to work with the javabook.pdf document to build our knowledge base.\n",
    "\n",
    "There are several libraries to open PDFs with Python but I found that [PyMuPDF](https://github.com/pymupdf/pymupdf) works quite well in many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File javabook.pdf exists and is ready to be processed.\n"
     ]
    }
   ],
   "source": [
    "# Set PDF file path\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Get PDF document\n",
    "pdf_path = \"javabook.pdf\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(pdf_path):\n",
    "    print(f\"File {pdf_path} exists and is ready to be processed.\")\n",
    "else:\n",
    "    print(f\"Error: {pdf_path} not found in the current directory\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")\n",
    "    print(f\"Files in directory: {os.listdir('.')}\")\n",
    "    print(\"\\nPlease ensure javabook.pdf is in the working directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF acquired!\n",
    "\n",
    "We can import the pages of our PDF to text by first defining the PDF path and then opening and reading it with PyMuPDF (`import fitz`).\n",
    "\n",
    "We'll write a small helper function to preprocess the text as it gets read. Note that not all text will be read in the same so keep this in mind for when you prepare your text.\n",
    "\n",
    "We'll save each page to a dictionary and then append that dictionary to a list for ease of use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMuPDF installed. You can now import fitz.\n"
     ]
    }
   ],
   "source": [
    "# Fix PyMuPDF import issue (remove conflicting 'fitz' package, install pymupdf)\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def _pip(args):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", *args])\n",
    "\n",
    "try:\n",
    "    _pip([\"uninstall\", \"-y\", \"fitz\"])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_pip([\"install\", \"-q\", \"pymupdf\"])\n",
    "print(\"PyMuPDF installed. You can now import fitz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e37630903b4066b67818e484c8d863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': 0,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''},\n",
       " {'page_number': 1,\n",
       "  'page_char_count': 47,\n",
       "  'page_word_count': 10,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 11.75,\n",
       "  'text': 'The   Complete  Reference Java‚Ñ¢ Ninth Edition ¬Æ'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
    "import fitz # (pymupdf, found this is better than pypdf for our use case, note: licence is AGPL-3.0, keep that in mind if you want to use any code commercially)\n",
    "from tqdm.auto import tqdm # for progress bars, requires !pip install tqdm \n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
    "\n",
    "    # Other potential text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "# Open PDF and get lines/pages\n",
    "# Note: this only focuses on text, rather than images/figures etc\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing the page number\n",
    "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
    "        for each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\": page_number,  # keep original page numbers\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get a random sample of the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 237,\n",
       "  'page_char_count': 1453,\n",
       "  'page_word_count': 354,\n",
       "  'page_sentence_count_raw': 5,\n",
       "  'page_token_count': 363.25,\n",
       "  'text': 'Chapter 9\\u2003    Packages and Interfaces\\u2003 \\u2002  203 Part I       stck = temp;       stck[++tos] = item;     }     else       stck[++tos] = item;   }    // Pop an item from the stack   public int pop() {     if(tos < 0) {       System.out.println(\"Stack underflow.\");       return 0;     }     else       return stck[tos--];   } }  class IFTest2 {   public static void main(String args[]) {     DynStack mystack1 = new DynStack(5);     DynStack mystack2 = new DynStack(8);      // these loops cause each stack to grow     for(int i=0; i<12; i++) mystack1.push(i);     for(int i=0; i<20; i++) mystack2.push(i);      System.out.println(\"Stack in mystack1:\");     for(int i=0; i<12; i++)        System.out.println(mystack1.pop());      System.out.println(\"Stack in mystack2:\");     for(int i=0; i<20; i++)        System.out.println(mystack2.pop());   } } The following class uses both the FixedStack and DynStack implementations. It does so  through an interface reference. This means that calls to push( ) and pop( ) are resolved at  run time rather than at compile time. /* Create an interface variable and    access stacks through it. */ class IFTest3 {   public static void main(String args[]) {     IntStack mystack; // create an interface reference variable     DynStack ds = new DynStack(5);     FixedStack fs = new FixedStack(8);      mystack = ds; // load dynamic stack     // push some numbers onto the stack     for(int i=0; i<12; i++) mystack.push(i);'},\n",
       " {'page_number': 114,\n",
       "  'page_char_count': 43,\n",
       "  'page_word_count': 7,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 10.75,\n",
       "  'text': 'This page has been intentionally left blank'},\n",
       " {'page_number': 457,\n",
       "  'page_char_count': 2061,\n",
       "  'page_word_count': 458,\n",
       "  'page_sentence_count_raw': 16,\n",
       "  'page_token_count': 515.25,\n",
       "  'text': 'Chapter 16\\u2003    String Handling\\u2003 \\u2002  423 Part II     String s1 = \"Hello\";     String s2 = new String(s1);      System.out.println(s1 + \" equals \" + s2 + \" -> \" +                        s1.equals(s2));     System.out.println(s1 + \" == \" + s2 + \" -> \" + (s1 == s2));   } } The variable s1 refers to the String instance created by \"Hello\". The object referred  to by s2 is created with s1 as an initializer. Thus, the contents of the two String objects are  identical, but they are distinct objects. This means that s1 and s2 do not refer to the same  objects and are, therefore, not ==, as is shown here by the output of the preceding example:    Hello equals Hello -> true    Hello == Hello -> false compareTo( ) Often, it is not enough to simply know whether two strings are identical. For sorting  applications, you need to know which is less than, equal to, or greater than the next. A string  is less than another if it comes before the other in dictionary order. A string is greater than  another if it comes after the other in dictionary order. The method compareTo( ) serves  this purpose. It is specified by the Comparable<T> interface, which String implements. It  has this general form: int compareTo(String str) Here, str is the String being compared with the invoking String. The result of the  comparison is returned and is interpreted as shown here: Value Meaning Less than zero The invoking string is less than str. Greater than zero The invoking string is greater than str. Zero The two strings are equal. Here is a sample program that sorts an array of strings. The program uses compareTo( )  to determine sort ordering for a bubble sort: // A bubble sort for Strings. class SortString {   static String arr[] = {     \"Now\", \"is\", \"the\", \"time\", \"for\", \"all\", \"good\", \"men\",     \"to\", \"come\", \"to\", \"the\", \"aid\", \"of\", \"their\", \"country\"   };   public static void main(String args[]) {     for(int j = 0; j < arr.length; j++) {       for(int i = j + 1; i < arr.length; i++) {         if(arr[i].compareTo(arr[j]) < 0) {           String t = arr[j];'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some stats on the text\n",
    "\n",
    "Let's perform a rough exploratory data analysis (EDA) to get an idea of the size of the texts (e.g. character counts, word counts etc) we're working with.\n",
    "\n",
    "The different sizes of texts will be a good indicator into how we should split our texts.\n",
    "\n",
    "Many embedding models have limits on the size of texts they can ingest, for example, the [`sentence-transformers`](https://www.sbert.net/docs/pretrained_models.html) model [`all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) has an input size of 384 tokens.\n",
    "\n",
    "This means that the model has been trained in ingest and turn into embeddings texts with 384 tokens (1 token ~= 4 characters ~= 0.75 words).\n",
    "\n",
    "Texts over 384 tokens which are encoded by this model will be auotmatically reduced to 384 tokens in length, potentially losing some information.\n",
    "\n",
    "We'll discuss this more in the embedding section.\n",
    "\n",
    "For now, let's turn our list of dictionaries into a DataFrame and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11.75</td>\n",
       "      <td>The&nbsp;&nbsp; Complete&nbsp;&nbsp;Reference Java‚Ñ¢ Ninth Edition ¬Æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1728</td>\n",
       "      <td>291</td>\n",
       "      <td>17</td>\n",
       "      <td>432.00</td>\n",
       "      <td>About the Author Best-selling author Herbert S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>44.50</td>\n",
       "      <td>The&nbsp;&nbsp;Complete&nbsp;&nbsp;Reference Herbert Schildt New Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4265</td>\n",
       "      <td>693</td>\n",
       "      <td>26</td>\n",
       "      <td>1066.25</td>\n",
       "      <td>Copyright ¬© 2014 by McGraw-Hill Education (Pub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0            0                0                1                        1   \n",
       "1            1               47               10                        1   \n",
       "2            2             1728              291                       17   \n",
       "3            3              178               29                        1   \n",
       "4            4             4265              693                       26   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0              0.00                                                     \n",
       "1             11.75    The   Complete  Reference Java‚Ñ¢ Ninth Edition ¬Æ  \n",
       "2            432.00  About the Author Best-selling author Herbert S...  \n",
       "3             44.50  The  Complete  Reference Herbert Schildt New Y...  \n",
       "4           1066.25  Copyright ¬© 2014 by McGraw-Hill Education (Pub...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>656.00</td>\n",
       "      <td>2100.16</td>\n",
       "      <td>428.19</td>\n",
       "      <td>44.02</td>\n",
       "      <td>525.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>379.17</td>\n",
       "      <td>819.82</td>\n",
       "      <td>303.30</td>\n",
       "      <td>205.07</td>\n",
       "      <td>204.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.00</td>\n",
       "      <td>1612.00</td>\n",
       "      <td>332.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>403.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>656.00</td>\n",
       "      <td>2049.00</td>\n",
       "      <td>396.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>512.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>984.00</td>\n",
       "      <td>2513.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>628.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1312.00</td>\n",
       "      <td>5644.00</td>\n",
       "      <td>2893.00</td>\n",
       "      <td>1841.00</td>\n",
       "      <td>1411.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1313.00          1313.00          1313.00                  1313.00   \n",
       "mean        656.00          2100.16           428.19                    44.02   \n",
       "std         379.17           819.82           303.30                   205.07   \n",
       "min           0.00             0.00             1.00                     1.00   \n",
       "25%         328.00          1612.00           332.00                    10.00   \n",
       "50%         656.00          2049.00           396.00                    16.00   \n",
       "75%         984.00          2513.00           466.00                    24.00   \n",
       "max        1312.00          5644.00          2893.00                  1841.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           1313.00  \n",
       "mean             525.04  \n",
       "std              204.96  \n",
       "min                0.00  \n",
       "25%              403.00  \n",
       "50%              512.25  \n",
       "75%              628.25  \n",
       "max             1411.00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Get stats\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like our average token count per page is 287.\n",
    "\n",
    "For this particular use case, it means we could embed an average whole page with the `all-mpnet-base-v2` model (this model has an input capacity of 384)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further text processing (splitting pages into sentences)\n",
    "\n",
    "The ideal way of processing text before embedding it is still an active area of research.\n",
    "\n",
    "A simple method I've found helpful is to break the text into chunks of sentences.\n",
    "\n",
    "As in, chunk a page of text into groups of 5, 7, 10 or more sentences (these values are not set in stone and can be explored).\n",
    "\n",
    "But we want to follow the workflow of:\n",
    "\n",
    "`Ingest text -> split it into groups/chunks -> embed the groups/chunks -> use the embeddings`\n",
    "\n",
    "Some options for splitting text into sentences:\n",
    "\n",
    "1. Split into sentences with simple rules (e.g. split on \". \" with `text = text.split(\". \")`, like we did above).\n",
    "2. Split into sentences with a natural language processing (NLP) library such as [spaCy](https://spacy.io/) or [nltk](https://www.nltk.org/).\n",
    "\n",
    "Why split into sentences?\n",
    "\n",
    "* Easier to handle than larger pages of text (especially if pages are densely filled with text).\n",
    "* Can get specific and find out which group of sentences were used to help within a RAG pipeline.\n",
    "\n",
    "> **Resource:** See [spaCy install instructions](https://spacy.io/usage). \n",
    "\n",
    "Let's use spaCy to break our text into sentences since it's likely a bit more robust than just using `text.split(\". \")`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence tokenizer works! Found 2 sentences in test text.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This is a sentence.', 'This is another sentence.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using NLTK instead of spacy for sentence tokenization (spacy has compatibility issues with Python 3.14)\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Create a simple sentence splitter using regular expression as a fallback\n",
    "import re\n",
    "\n",
    "def sentence_tokenizer(text):\n",
    "    \"\"\"Simple sentence tokenizer that splits on sentence endings.\"\"\"\n",
    "    # Split on sentence boundaries (period, exclamation, question mark followed by space)\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "# Test the sentence tokenizer\n",
    "test_text = \"This is a sentence. This is another sentence.\"\n",
    "sents = sentence_tokenizer(test_text)\n",
    "assert len(sents) == 2, f\"Expected 2 sentences, got {len(sents)}\"\n",
    "print(f\"Sentence tokenizer works! Found {len(sents)} sentences in test text.\")\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't necessarily need to use spaCy, however, it's an open-source library designed to do NLP tasks like this at scale.\n",
    "\n",
    "So let's run our small sentencizing pipeline on our pages of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884eb7b3ee9d45dc990c98647704959b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = sentence_tokenizer(item[\"text\"])\n",
    "    \n",
    "    # Count the sentences\n",
    "    item[\"page_sentence_count_nltk\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1289,\n",
       "  'page_char_count': 3422,\n",
       "  'page_word_count': 435,\n",
       "  'page_sentence_count_raw': 2,\n",
       "  'page_token_count': 855.5,\n",
       "  'text': 'Index\\u2003 \\u2002  1255 getOppositeComponent(\\xa0), 775 getOppositeWindow(\\xa0), 781 getOutputStream(\\xa0), 461, 464, 732, 1219 getParallelism(\\xa0), 958 getParameter(\\xa0), 749, 761‚Äì762, 1219, 1221, 1228, 1229 getParameterNames(\\xa0), 1219, 1221 getParent(\\xa0), 485, 643, 694, 712, 936, 1161 getPath(\\xa0), 1063‚Äì1064, 1226 getPhase(\\xa0), 931 getPoint(\\xa0), 778 getPoolSize(\\xa0), 963 getPort(\\xa0), 732, 743, 744 getPreciseWheelRotation(\\xa0), 780 getPreferredSize(\\xa0), 856 getPriority(\\xa0), 236, 246, 483 getProperties(\\xa0), 468, 572 getProperty(\\xa0), 468, 470, 573, 574, 575 getPropertyDescriptors(\\xa0), 1202, 1203, 1208, 1209 getQueuedTaskCount(\\xa0), 962 getRed(\\xa0), 816 getRegisteredParties(\\xa0), 936 getRemoveListenerMethod(\\xa0), 1206 getRGB(\\xa0), 817 getRuntime(\\xa0), 461, 462 getScreenX(\\xa0), 1188 getScreenY(\\xa0), 1188 getScript(\\xa0), 595 getScrollAmount(\\xa0), 780 getScrollType(\\xa0), 780 getSecurityManager(\\xa0), 490 getSelectedCheckbox(\\xa0), 842 getSelectedIndex(\\xa0), 844, 846, 1059 getSelectedIndexes(\\xa0), 847 getSelectedItem(\\xa0), 844, 846, 1062 getSelectedItems(\\xa0), 847, 1150 getSelectedText(\\xa0), 852, 854 getSelectedToggle(\\xa0), 1142 getSelectedValue(\\xa0), 1059 getSelectionModel(\\xa0), 1147, 1160 getServletConfig(\\xa0), 1217 getServletContext(\\xa0), 1218 getServletInfo(\\xa0), 1217 getServletName(\\xa0), 1218 getSession(\\xa0), 1223, 1232 getSize(\\xa0), 802, 814, 820 getSource(\\xa0), 772, 838, 1052, 1115 getStackTrace(\\xa0), 228, 483, 491 getState(\\xa0), 259‚Äì261, 483, 840, 871 getStateChange(\\xa0), 777, 847 getSubElements(\\xa0), 1072 getSuperclass(\\xa0), 475, 476 getSuppressed(\\xa0), 228, 318 getSurplusQueuedTaskCount(\\xa0), 962 getTarget(\\xa0), 1180 getText(\\xa0), 835, 852, 854, 1042, 1044, 1045, 1050,  1154, 1180 getTimeInstance(\\xa0), 1010‚Äì1011 getTransforms(\\xa0), 1166 getUnarrivedParties(\\xa0), 936 getTotalSpace(\\xa0), 645 getUsableSpace(\\xa0), 645 getValue(\\xa0), 537, 539, 774, 849, 1226, 1231,  1151‚Äì1152, 1161 getVvalue(\\xa0), 1158 getWheelRotation(\\xa0), 780 getWhen(\\xa0), 773 getWidth(\\xa0), 1037 getWindow(\\xa0), 781 getWriter(\\xa0), 1215, 1219 getX(\\xa0), 778, 1084, 1086 getXOnScreen(\\xa0), 779, 1084, 1086 getY(\\xa0), 778 getYear(\\xa0), 1017 getYOnScreen(\\xa0), 779 GIF image format, 885‚Äì886, 887 Glass pane, 1025 Glassfish, 1212, 1213 Glob, 715‚Äì716 Glow class, 1165 program demonstrating, 1167‚Äì1170 Gosling, James, 6 goto keyword, 34 Goto statement, using labeled break as form of,  104‚Äì106 grabPixels(\\xa0), 897 Graphical User Interface. See GUI (Graphical User  Interface) Graphics and JavaFX retained mode, 1106, 1119  context, 319, 753, 811  sizing, 814‚Äì815 Graphics class, 319, 753, 754, 799, 811, 817, 824,  887, 890 drawing methods, 811‚Äì814 Graphics2D class, 811 GraphicsContext class, 1119‚Äì1123 GraphicsEnvironment class, 799, 821 GregorianCalendar class, 588, 591‚Äì592, 596, 1013 Grid bag layouts, 865‚Äì870 GridBagConstraints class, 799, 866‚Äì868 constraint fields, table of, 866‚Äì867 GridBagLayout class, 799, 865, 866, 868, 870 gridheight constraint field, 866, 868 GridLayout class, 799, 861‚Äì862 GridPane class, 1107 gridwidth constraint field, 866, 868 Group class, 1107 group(\\xa0), 699, 994 GIU (Graphical User Interface), 301, 319, 321, 797, 833 applets based on the, 751 approaches to the, 1105 effects and transforms to customize the look of a  JavaFX, using, 1164‚Äì1170 programs, handling events generated by, 769‚Äì795 GZIP file format, 639 H handle(\\xa0), 1115, 1118, 1179 hasCharacteristics(\\xa0), 527, 528 Hash code, 516 Hash table, 516 hashCode(\\xa0), 185, 280, 443, 445, 448, 449, 450, 452,  458, 460, 471, 490, 491, 492, 502, 532, 537, 560, 569,  581, 584, 587, 820',\n",
       "  'sentences': ['Index\\u2003 \\u2002  1255 getOppositeComponent(\\xa0), 775 getOppositeWindow(\\xa0), 781 getOutputStream(\\xa0), 461, 464, 732, 1219 getParallelism(\\xa0), 958 getParameter(\\xa0), 749, 761‚Äì762, 1219, 1221, 1228, 1229 getParameterNames(\\xa0), 1219, 1221 getParent(\\xa0), 485, 643, 694, 712, 936, 1161 getPath(\\xa0), 1063‚Äì1064, 1226 getPhase(\\xa0), 931 getPoint(\\xa0), 778 getPoolSize(\\xa0), 963 getPort(\\xa0), 732, 743, 744 getPreciseWheelRotation(\\xa0), 780 getPreferredSize(\\xa0), 856 getPriority(\\xa0), 236, 246, 483 getProperties(\\xa0), 468, 572 getProperty(\\xa0), 468, 470, 573, 574, 575 getPropertyDescriptors(\\xa0), 1202, 1203, 1208, 1209 getQueuedTaskCount(\\xa0), 962 getRed(\\xa0), 816 getRegisteredParties(\\xa0), 936 getRemoveListenerMethod(\\xa0), 1206 getRGB(\\xa0), 817 getRuntime(\\xa0), 461, 462 getScreenX(\\xa0), 1188 getScreenY(\\xa0), 1188 getScript(\\xa0), 595 getScrollAmount(\\xa0), 780 getScrollType(\\xa0), 780 getSecurityManager(\\xa0), 490 getSelectedCheckbox(\\xa0), 842 getSelectedIndex(\\xa0), 844, 846, 1059 getSelectedIndexes(\\xa0), 847 getSelectedItem(\\xa0), 844, 846, 1062 getSelectedItems(\\xa0), 847, 1150 getSelectedText(\\xa0), 852, 854 getSelectedToggle(\\xa0), 1142 getSelectedValue(\\xa0), 1059 getSelectionModel(\\xa0), 1147, 1160 getServletConfig(\\xa0), 1217 getServletContext(\\xa0), 1218 getServletInfo(\\xa0), 1217 getServletName(\\xa0), 1218 getSession(\\xa0), 1223, 1232 getSize(\\xa0), 802, 814, 820 getSource(\\xa0), 772, 838, 1052, 1115 getStackTrace(\\xa0), 228, 483, 491 getState(\\xa0), 259‚Äì261, 483, 840, 871 getStateChange(\\xa0), 777, 847 getSubElements(\\xa0), 1072 getSuperclass(\\xa0), 475, 476 getSuppressed(\\xa0), 228, 318 getSurplusQueuedTaskCount(\\xa0), 962 getTarget(\\xa0), 1180 getText(\\xa0), 835, 852, 854, 1042, 1044, 1045, 1050,  1154, 1180 getTimeInstance(\\xa0), 1010‚Äì1011 getTransforms(\\xa0), 1166 getUnarrivedParties(\\xa0), 936 getTotalSpace(\\xa0), 645 getUsableSpace(\\xa0), 645 getValue(\\xa0), 537, 539, 774, 849, 1226, 1231,  1151‚Äì1152, 1161 getVvalue(\\xa0), 1158 getWheelRotation(\\xa0), 780 getWhen(\\xa0), 773 getWidth(\\xa0), 1037 getWindow(\\xa0), 781 getWriter(\\xa0), 1215, 1219 getX(\\xa0), 778, 1084, 1086 getXOnScreen(\\xa0), 779, 1084, 1086 getY(\\xa0), 778 getYear(\\xa0), 1017 getYOnScreen(\\xa0), 779 GIF image format, 885‚Äì886, 887 Glass pane, 1025 Glassfish, 1212, 1213 Glob, 715‚Äì716 Glow class, 1165 program demonstrating, 1167‚Äì1170 Gosling, James, 6 goto keyword, 34 Goto statement, using labeled break as form of,  104‚Äì106 grabPixels(\\xa0), 897 Graphical User Interface.',\n",
       "   'See GUI (Graphical User  Interface) Graphics and JavaFX retained mode, 1106, 1119  context, 319, 753, 811  sizing, 814‚Äì815 Graphics class, 319, 753, 754, 799, 811, 817, 824,  887, 890 drawing methods, 811‚Äì814 Graphics2D class, 811 GraphicsContext class, 1119‚Äì1123 GraphicsEnvironment class, 799, 821 GregorianCalendar class, 588, 591‚Äì592, 596, 1013 Grid bag layouts, 865‚Äì870 GridBagConstraints class, 799, 866‚Äì868 constraint fields, table of, 866‚Äì867 GridBagLayout class, 799, 865, 866, 868, 870 gridheight constraint field, 866, 868 GridLayout class, 799, 861‚Äì862 GridPane class, 1107 gridwidth constraint field, 866, 868 Group class, 1107 group(\\xa0), 699, 994 GIU (Graphical User Interface), 301, 319, 321, 797, 833 applets based on the, 751 approaches to the, 1105 effects and transforms to customize the look of a  JavaFX, using, 1164‚Äì1170 programs, handling events generated by, 769‚Äì795 GZIP file format, 639 H handle(\\xa0), 1115, 1118, 1179 hasCharacteristics(\\xa0), 527, 528 Hash code, 516 Hash table, 516 hashCode(\\xa0), 185, 280, 443, 445, 448, 449, 450, 452,  458, 460, 471, 490, 491, 492, 502, 532, 537, 560, 569,  581, 584, 587, 820'],\n",
       "  'page_sentence_count_nltk': 2}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an example\n",
    "import random\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful!\n",
    "\n",
    "Now let's turn out list of dictionaries into a DataFrame and get some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_nltk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>656.00</td>\n",
       "      <td>2100.16</td>\n",
       "      <td>428.19</td>\n",
       "      <td>44.02</td>\n",
       "      <td>525.04</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>379.17</td>\n",
       "      <td>819.82</td>\n",
       "      <td>303.30</td>\n",
       "      <td>205.07</td>\n",
       "      <td>204.96</td>\n",
       "      <td>205.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.00</td>\n",
       "      <td>1612.00</td>\n",
       "      <td>332.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>403.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>656.00</td>\n",
       "      <td>2049.00</td>\n",
       "      <td>396.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>512.25</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>984.00</td>\n",
       "      <td>2513.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>628.25</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1312.00</td>\n",
       "      <td>5644.00</td>\n",
       "      <td>2893.00</td>\n",
       "      <td>1841.00</td>\n",
       "      <td>1411.00</td>\n",
       "      <td>1841.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1313.00          1313.00          1313.00                  1313.00   \n",
       "mean        656.00          2100.16           428.19                    44.02   \n",
       "std         379.17           819.82           303.30                   205.07   \n",
       "min           0.00             0.00             1.00                     1.00   \n",
       "25%         328.00          1612.00           332.00                    10.00   \n",
       "50%         656.00          2049.00           396.00                    16.00   \n",
       "75%         984.00          2513.00           466.00                    24.00   \n",
       "max        1312.00          5644.00          2893.00                  1841.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_nltk  \n",
       "count           1313.00                   1313.00  \n",
       "mean             525.04                     44.28  \n",
       "std              204.96                    205.07  \n",
       "min                0.00                      0.00  \n",
       "25%              403.00                     10.00  \n",
       "50%              512.25                     16.00  \n",
       "75%              628.25                     24.00  \n",
       "max             1411.00                   1841.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our set of text, it looks like our raw sentence count (e.g. splitting on `\". \"`) is quite close to what spaCy came up with.\n",
    "\n",
    "Now we've got our text split into sentences, how about we gorup those sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking our sentences together\n",
    "\n",
    "Let's take a step to break down our list of sentences/text into smaller chunks.\n",
    "\n",
    "As you might've guessed, this process is referred to as **chunking**.\n",
    "\n",
    "Why do we do this?\n",
    "\n",
    "1. Easier to manage similar sized chunks of text.\n",
    "2. Don't overload the embedding models capacity for tokens (e.g. if an embedding model has a capacity of 384 tokens, there could be information loss if you try to embed a sequence of 400+ tokens).\n",
    "3. Our LLM context window (the amount of tokens an LLM can take in) may be limited and requires compute power so we want to make sure we're using it as well as possible.\n",
    "\n",
    "Something to note is that there are many different ways emerging for creating chunks of information/text.\n",
    "\n",
    "For now, we're going to keep it simple and break our pages of sentences into groups of 10 (this number is arbitrary and can be changed, I just picked it because it seemed to line up well with our embedding model capacity of 384).\n",
    "\n",
    "On average each of our pages has 10 sentences.\n",
    "\n",
    "And an average total of 287 tokens per page.\n",
    "\n",
    "So our groups of 10 sentences will also be ~287 tokens long.\n",
    "\n",
    "This gives us plenty of room for the text to embedded by our `all-mpnet-base-v2` model (it has a capacity of 384 tokens).\n",
    "\n",
    "To split our groups of sentences into chunks of 10 or less, let's create a function which accepts a list as input and recursively breaks into down into sublists of a specified size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64895016ebd45c49404d7d3833fb952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1187,\n",
       "  'page_char_count': 1238,\n",
       "  'page_word_count': 250,\n",
       "  'page_sentence_count_raw': 10,\n",
       "  'page_token_count': 309.5,\n",
       "  'text': 'Chapter 35\\u2003    Exploring JavaFX Controls\\u2003 \\u2002  1153 Part IV     // Create an ObservableList of entries for the combo box.     ObservableList<String> transportTypes =       FXCollections.observableArrayList( \"Train\", \"Car\", \"Airplane\" );      // Create a combo box.     cbTransport = new ComboBox<String>(transportTypes);      // Set the default value.     cbTransport.setValue(\"Train\");      // Set the response label to indicate the default selection.     response.setText(\"Selected Transport is \" + cbTransport.getValue());      // Listen for action events on the combo box.     cbTransport.setOnAction(new EventHandler<ActionEvent>() {       public void handle(ActionEvent ae) {         response.setText(\"Selected Transport is \" + cbTransport.getValue());       }     });      // Add the label and combo box to the scene graph.     rootNode.getChildren().addAll(cbTransport, response);      // Show the stage and its scene.     myStage.show();   } } Sample output is shown here: As mentioned, ComboBox can be configured to allow the user to edit a selection.  Assuming that it contains only entries of type String, it is easy to enable editing capabilities.  Simply call setEditable(\\xa0), shown here: final void setEditable(boolean enable)',\n",
       "  'sentences': ['Chapter 35\\u2003    Exploring JavaFX Controls\\u2003 \\u2002  1153 Part IV     // Create an ObservableList of entries for the combo box.',\n",
       "   'ObservableList<String> transportTypes =       FXCollections.observableArrayList( \"Train\", \"Car\", \"Airplane\" );      // Create a combo box.',\n",
       "   'cbTransport = new ComboBox<String>(transportTypes);      // Set the default value.',\n",
       "   'cbTransport.setValue(\"Train\");      // Set the response label to indicate the default selection.',\n",
       "   'response.setText(\"Selected Transport is \" + cbTransport.getValue());      // Listen for action events on the combo box.',\n",
       "   'cbTransport.setOnAction(new EventHandler<ActionEvent>() {       public void handle(ActionEvent ae) {         response.setText(\"Selected Transport is \" + cbTransport.getValue());       }     });      // Add the label and combo box to the scene graph.',\n",
       "   'rootNode.getChildren().addAll(cbTransport, response);      // Show the stage and its scene.',\n",
       "   'myStage.show();   } } Sample output is shown here: As mentioned, ComboBox can be configured to allow the user to edit a selection.',\n",
       "   'Assuming that it contains only entries of type String, it is easy to enable editing capabilities.',\n",
       "   'Simply call setEditable(\\xa0), shown here: final void setEditable(boolean enable)'],\n",
       "  'page_sentence_count_nltk': 10,\n",
       "  'sentence_chunks': [['Chapter 35\\u2003    Exploring JavaFX Controls\\u2003 \\u2002  1153 Part IV     // Create an ObservableList of entries for the combo box.',\n",
       "    'ObservableList<String> transportTypes =       FXCollections.observableArrayList( \"Train\", \"Car\", \"Airplane\" );      // Create a combo box.',\n",
       "    'cbTransport = new ComboBox<String>(transportTypes);      // Set the default value.',\n",
       "    'cbTransport.setValue(\"Train\");      // Set the response label to indicate the default selection.',\n",
       "    'response.setText(\"Selected Transport is \" + cbTransport.getValue());      // Listen for action events on the combo box.',\n",
       "    'cbTransport.setOnAction(new EventHandler<ActionEvent>() {       public void handle(ActionEvent ae) {         response.setText(\"Selected Transport is \" + cbTransport.getValue());       }     });      // Add the label and combo box to the scene graph.',\n",
       "    'rootNode.getChildren().addAll(cbTransport, response);      // Show the stage and its scene.',\n",
       "    'myStage.show();   } } Sample output is shown here: As mentioned, ComboBox can be configured to allow the user to edit a selection.',\n",
       "    'Assuming that it contains only entries of type String, it is easy to enable editing capabilities.',\n",
       "    'Simply call setEditable(\\xa0), shown here: final void setEditable(boolean enable)']],\n",
       "  'num_chunks': 1}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_nltk</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>656.00</td>\n",
       "      <td>2100.16</td>\n",
       "      <td>428.19</td>\n",
       "      <td>44.02</td>\n",
       "      <td>525.04</td>\n",
       "      <td>44.28</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>379.17</td>\n",
       "      <td>819.82</td>\n",
       "      <td>303.30</td>\n",
       "      <td>205.07</td>\n",
       "      <td>204.96</td>\n",
       "      <td>205.07</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.00</td>\n",
       "      <td>1612.00</td>\n",
       "      <td>332.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>403.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>656.00</td>\n",
       "      <td>2049.00</td>\n",
       "      <td>396.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>512.25</td>\n",
       "      <td>16.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>984.00</td>\n",
       "      <td>2513.00</td>\n",
       "      <td>466.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>628.25</td>\n",
       "      <td>24.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1312.00</td>\n",
       "      <td>5644.00</td>\n",
       "      <td>2893.00</td>\n",
       "      <td>1841.00</td>\n",
       "      <td>1411.00</td>\n",
       "      <td>1841.00</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1313.00          1313.00          1313.00                  1313.00   \n",
       "mean        656.00          2100.16           428.19                    44.02   \n",
       "std         379.17           819.82           303.30                   205.07   \n",
       "min           0.00             0.00             1.00                     1.00   \n",
       "25%         328.00          1612.00           332.00                    10.00   \n",
       "50%         656.00          2049.00           396.00                    16.00   \n",
       "75%         984.00          2513.00           466.00                    24.00   \n",
       "max        1312.00          5644.00          2893.00                  1841.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_nltk  num_chunks  \n",
       "count           1313.00                   1313.00      1313.0  \n",
       "mean             525.04                     44.28         4.9  \n",
       "std              204.96                    205.07        20.5  \n",
       "min                0.00                      0.00         0.0  \n",
       "25%              403.00                     10.00         1.0  \n",
       "50%              512.25                     16.00         2.0  \n",
       "75%              628.25                     24.00         3.0  \n",
       "max             1411.00                   1841.00       185.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to get stats\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the average number of chunks is around 1.5, this is expected since many of our pages only contain an average of 10 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting each chunk into its own item\n",
    "\n",
    "We'd like to embed each chunk of sentences into its own numerical representation.\n",
    "\n",
    "So to keep things clean, let's create a new list of dictionaries each containing a single chunk of sentences with relative information such as page number as well statistics about each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08861c5308b3431d9ad2e3fba04460f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6429"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 298,\n",
       "  'sentence_chunk': 'For example, this statement compares the value in ap with the GoldenDel constant: if(ap == Apple. GoldenDel) // ... An enumeration value can also be used to control a switch statement. Of course, all of the case statements must use constants from the same enum as that used by the switch expression. For example, this switch is perfectly valid: // Use an enum to control a switch statement.switch(ap) {  case Jonathan:   // ...case Winesap:   // ... Notice that in the case statements, the names of the enumeration constants are used without being qualified by their enumeration type name. That is, Winesap, not Apple. Winesap, is used. This is because the type of the enumeration in the switch expression has already implicitly specified the enum type of the case constants. There is no need to qualify the constants in the case statements with their enum type name.',\n",
       "  'chunk_char_count': 867,\n",
       "  'chunk_word_count': 151,\n",
       "  'chunk_token_count': 216.75}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a random sample\n",
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!\n",
    "\n",
    "Now we've broken our whole textbook into chunks of 10 sentences or less as well as the page number they came from.\n",
    "\n",
    "This means we could reference a chunk of text and know its source.\n",
    "\n",
    "Let's get some stats about our chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6429.00</td>\n",
       "      <td>6429.00</td>\n",
       "      <td>6429.00</td>\n",
       "      <td>6429.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>297.52</td>\n",
       "      <td>409.79</td>\n",
       "      <td>69.13</td>\n",
       "      <td>102.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>400.86</td>\n",
       "      <td>555.34</td>\n",
       "      <td>93.96</td>\n",
       "      <td>138.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>566.00</td>\n",
       "      <td>858.00</td>\n",
       "      <td>144.00</td>\n",
       "      <td>214.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1312.00</td>\n",
       "      <td>4248.00</td>\n",
       "      <td>557.00</td>\n",
       "      <td>1062.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      6429.00           6429.00           6429.00            6429.00\n",
       "mean        297.52            409.79             69.13             102.45\n",
       "std         400.86            555.34             93.96             138.83\n",
       "min           1.00              2.00              1.00               0.50\n",
       "25%          17.00             10.00              1.00               2.50\n",
       "50%          27.00             39.00              6.00               9.75\n",
       "75%         566.00            858.00            144.00             214.50\n",
       "max        1312.00           4248.00            557.00            1062.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm looks like some of our chunks have quite a low token count.\n",
    "\n",
    "How about we check for samples with less than 30 tokens (about the length of a sentence) and see if they are worth keeping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 2.5 | Text: ..........\n",
      "Chunk token count: 2.5 | Text: ..........\n",
      "Chunk token count: 2.5 | Text: ..........\n",
      "Chunk token count: 2.5 | Text: ..........\n",
      "Chunk token count: 2.5 | Text: ..........\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "filtered_df = df[df[\"chunk_token_count\"] <= min_token_length]\n",
    "num_samples = min(5, len(filtered_df))  # Sample up to 5, or less if not enough\n",
    "for row in filtered_df.sample(min(num_samples, len(filtered_df))).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like many of these are headers and footers of different pages.\n",
    "\n",
    "They don't seem to offer too much information.\n",
    "\n",
    "Let's filter our DataFrame/list of dictionaries to only include chunks with over 30 tokens in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 2,\n",
       "  'sentence_chunk': 'About the Author Best-selling author Herbert Schildt has written extensively about programming for nearly three decades and is a leading authority on the Java language. His books have sold millions of copies worldwide and have been translated into all major foreign languages. He is the author of numerous books on Java, including Java: A Beginner‚Äôs Guide, Herb Schildt‚Äôs Java Programming Cookbook, and Swing: A Beginner‚Äôs Guide. He has also written extensively about C, C++, and C#. Although interested in all facets of computing, his primary focus is computer languages, including compilers, interpreters, and robotic control languages. He also has an active interest in the standardization of languages. Schildt holds both graduate and undergraduate degrees from the University of Illinois. He can be reached at his consulting office at (217) 586-4683. His web site is www. HerbSchildt.com. About the Technical Editor Dr.',\n",
       "  'chunk_char_count': 924,\n",
       "  'chunk_word_count': 141,\n",
       "  'chunk_token_count': 231.0},\n",
       " {'page_number': 2,\n",
       "  'sentence_chunk': 'Danny Coward has worked on all editions of the Java platform. He led the definition of Java Servlets into the first version of the Java EE platform and beyond, web services into the Java ME platform, and the strategy and planning for Java SE 7. He founded JavaFX technology and, most recently, designed the largest addition to the Java EE 7 standard, the Java WebSocket API. From coding in Java to designing APIs with industry experts, to serving for several years as an executive to the Java Community Process, he has a uniquely broad perspective into multiple aspects of Java technology. Additionally, he is the author of JavaWebSocket Programming and an upcoming book on Java EE. Dr. Coward holds bachelor‚Äôs, master‚Äôs, and doctorate‚Äôs in mathematics from the University of Oxford.',\n",
       "  'chunk_char_count': 783,\n",
       "  'chunk_word_count': 130,\n",
       "  'chunk_token_count': 195.75}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller chunks filtered!\n",
    "\n",
    "Time to embed our chunks of text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding our text chunks\n",
    "\n",
    "While humans understand text, machines understand numbers best.\n",
    "\n",
    "An [embedding](https://vickiboykis.com/what_are_embeddings/index.html) is a broad concept.\n",
    "\n",
    "But one of my favourite and simple definitions is \"a useful numerical representation\".\n",
    "\n",
    "The most powerful thing about modern embeddings is that they are *learned* representations.\n",
    "\n",
    "Meaning rather than directly mapping words/tokens/characters to numbers directly (e.g. `{\"a\": 0, \"b\": 1, \"c\": 3...}`), the numerical representation of tokens is learned by going through large corpuses of text and figuring out how different tokens relate to each other.\n",
    "\n",
    "Ideally, embeddings of text will mean that similar meaning texts have similar numerical representation.\n",
    "\n",
    "> **Note:** Most modern NLP models deal with \"tokens\" which can be considered as multiple different sizes and combinations of words and characters rather than always whole words or single characters. For example, the string `\"hello world!\"` gets mapped to the token values `{15339: b'hello', 1917: b' world', 0: b'!'}` using [Byte pair encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) (or BPE via OpenAI's [`tiktoken`](https://github.com/openai/tiktoken) library). Google has a tokenization library called [SentencePiece](https://github.com/google/sentencepiece).\n",
    "\n",
    "Our goal is to turn each of our chunks into a numerical representation (an embedding vector, where a vector is a sequence of numbers arranged in order).\n",
    "\n",
    "Once our text samples are in embedding vectors, us humans will no longer be able to understand them.\n",
    "\n",
    "However, we don't need to.\n",
    "\n",
    "The embedding vectors are for our computers to understand.\n",
    "\n",
    "We'll use our computers to find patterns in the embeddings and then we can use their text mappings to further our understanding.\n",
    "\n",
    "Enough talking, how about we import a text embedding model and see what an embedding looks like.\n",
    "\n",
    "To do so, we'll use the [`sentence-transformers`](https://www.sbert.net/docs/installation.html) library which contains many pre-trained embedding models.\n",
    "\n",
    "Specifically, we'll get the `all-mpnet-base-v2` model (you can see the model's intended use on the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#intended-uses))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a98f05c14c24ea083235a16f2d16f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Sentences Transformers library provides an easy and open-source way to create embeddings.\n",
      "Embedding: [-2.07981374e-02  3.03164218e-02 -2.01218128e-02  6.86483532e-02\n",
      " -2.55255643e-02 -8.47689621e-03 -2.07111196e-04 -6.32377416e-02\n",
      "  2.81606149e-02 -3.33353467e-02  3.02634798e-02  5.30721173e-02\n",
      " -5.03526777e-02  2.62287464e-02  3.33313905e-02 -4.51578945e-02\n",
      "  3.63044366e-02 -1.37112767e-03 -1.20171290e-02  1.14946542e-02\n",
      "  5.04510924e-02  4.70857136e-02  2.11913381e-02  5.14607430e-02\n",
      " -2.03746390e-02 -3.58889140e-02 -6.67873712e-04 -2.94393301e-02\n",
      "  4.95858900e-02 -1.05639435e-02 -1.52013786e-02 -1.31752936e-03\n",
      "  4.48196791e-02  1.56022888e-02  8.60379657e-07 -1.21391716e-03\n",
      " -2.37978864e-02 -9.09424969e-04  7.34484987e-03 -2.53933878e-03\n",
      "  5.23369685e-02 -4.68043461e-02  1.66214611e-02  4.71579283e-02\n",
      " -4.15599123e-02  9.01962689e-04  3.60279009e-02  3.42214443e-02\n",
      "  9.68227684e-02  5.94828688e-02 -1.64984874e-02 -3.51249352e-02\n",
      "  5.92517806e-03 -7.07964529e-04 -2.41031889e-02  3.49741168e-02\n",
      " -2.94746812e-02  6.04271563e-03 -9.80647560e-03  2.83217952e-02\n",
      " -1.85376126e-02  3.63213085e-02  1.30292922e-02 -3.71233225e-02\n",
      "  5.27256802e-02 -1.19707026e-02 -7.18082562e-02  1.24431588e-02\n",
      " -6.70564920e-03  7.42154717e-02  1.16357114e-02 -1.74533352e-02\n",
      " -1.82405990e-02 -1.88930407e-02  2.82414649e-02  1.32828942e-02\n",
      " -3.51910144e-02  8.87342438e-04  5.79572096e-02  3.22092846e-02\n",
      " -3.48579814e-03  4.13768478e-02  1.44358026e-02 -3.28044109e-02\n",
      " -9.79083218e-03 -3.16492766e-02  4.23871391e-02 -4.70847450e-02\n",
      " -2.08937414e-02 -1.91249195e-02 -1.22626787e-02  1.01605179e-02\n",
      "  3.91922072e-02 -2.61895806e-02  1.09027866e-02  1.35722496e-02\n",
      " -5.79267256e-02 -3.21500413e-02 -5.75723778e-03 -2.43516024e-02\n",
      "  5.23417331e-02  5.46125975e-03 -2.30995677e-02  2.57169036e-03\n",
      " -6.63346052e-02  3.54126394e-02 -1.03907175e-02  2.25409754e-02\n",
      " -1.84574779e-02 -2.42006090e-02 -4.78364713e-02 -4.79241274e-03\n",
      " -5.34138568e-02  3.01791206e-02 -1.56130176e-02 -5.51475734e-02\n",
      " -3.91875133e-02  5.92152886e-02 -3.47646624e-02  9.68117360e-03\n",
      "  2.13415567e-02  2.30417177e-02  1.91712454e-02  2.77378708e-02\n",
      " -7.73513131e-03  1.04445592e-02 -2.67720111e-02 -2.40199361e-02\n",
      " -1.92289539e-02  3.91499838e-03 -2.54714750e-02  3.61942910e-02\n",
      "  5.12866825e-02 -8.41699354e-03 -3.13829705e-02  1.47484671e-02\n",
      "  2.13939659e-02 -3.84901240e-02  2.01946478e-02  1.20765902e-02\n",
      " -3.12085054e-03  7.84029812e-03  3.30336229e-03 -4.94357608e-02\n",
      "  5.83886243e-02  3.26131587e-03  4.84487321e-03 -4.50681634e-02\n",
      "  2.45682597e-02  3.55427973e-02 -5.32505699e-02  9.21152979e-02\n",
      "  2.04394814e-02 -3.36951762e-02 -6.19804189e-02 -2.11039279e-02\n",
      "  7.82359913e-02  5.11908121e-02  5.93170784e-02 -1.25063889e-04\n",
      "  4.96348813e-02 -1.55722797e-02 -3.35670030e-03  1.82016697e-02\n",
      " -2.73444615e-02 -1.08772432e-02  1.41475741e-02  1.09876953e-02\n",
      "  4.32551419e-03  8.23311359e-02 -9.85413790e-04  7.58791342e-02\n",
      "  9.44997463e-03  2.37688720e-02  1.61928944e-02  6.24994189e-02\n",
      "  4.75921966e-02 -3.92626459e-03  9.07524079e-02  4.49873544e-02\n",
      " -3.47130746e-02  2.14077681e-02 -3.35604399e-02  4.93849628e-02\n",
      "  1.08670080e-02  2.63447370e-02 -3.26088928e-02  8.00303295e-02\n",
      "  9.29765869e-03  7.16567272e-03 -2.79172137e-02 -3.06820553e-02\n",
      "  4.01062192e-03 -4.93906699e-02 -3.13778245e-03  4.00537699e-02\n",
      " -3.97854783e-02  5.48014566e-02  1.35768860e-05 -8.38373974e-02\n",
      " -1.21547235e-02  3.40950154e-02  3.22398497e-03  6.11846745e-02\n",
      "  5.60066961e-02  9.62878112e-03  2.54616179e-02 -4.64168563e-02\n",
      " -3.98900323e-02  7.68132880e-02  2.28408575e-02 -2.26567611e-02\n",
      " -1.91193335e-02 -6.53027967e-02  4.56781089e-02 -4.43656882e-03\n",
      "  1.49631705e-02 -2.15078797e-02  2.74241040e-03  1.90358330e-02\n",
      "  5.91888577e-02 -2.47569084e-02  3.66144739e-02  5.63083626e-02\n",
      " -8.86442605e-03 -1.74324531e-02 -1.03285920e-03  2.47667152e-02\n",
      "  1.30763212e-02  5.04633002e-02 -5.28495898e-03  5.92397489e-02\n",
      "  6.29906431e-02 -4.36783694e-02 -4.97831218e-02  5.56297190e-02\n",
      " -2.44854037e-02 -8.26755390e-02  2.04911362e-02 -1.06446370e-01\n",
      "  6.64837426e-03  2.97303833e-02 -2.36440338e-02 -8.84610415e-03\n",
      "  2.45556538e-03 -3.35234776e-02  7.52212480e-02 -5.89879937e-02\n",
      " -3.67807299e-02  3.41542400e-02  5.41131049e-02 -1.74904969e-02\n",
      "  1.33920396e-02  4.71682101e-02  1.46117331e-02 -2.12310906e-02\n",
      " -6.55339211e-02  1.23857353e-02  2.76074857e-02 -8.02160334e-03\n",
      " -4.59636711e-02 -8.22443329e-03  9.16953664e-03 -1.56398043e-02\n",
      "  7.54615851e-03  1.58314186e-03 -3.03959083e-02 -5.10670654e-02\n",
      "  1.96313318e-02  1.26263145e-02 -1.51733926e-03  2.02890746e-02\n",
      "  1.37817850e-02  1.49110388e-02  2.50766706e-02 -3.62870172e-02\n",
      "  1.08084977e-02  2.74138595e-03  1.81510728e-02  5.39872646e-02\n",
      " -4.74542230e-02 -4.28731441e-02 -2.89914720e-02  2.13234555e-02\n",
      " -3.85161228e-02  6.31921738e-02 -5.77975735e-02  3.77889676e-03\n",
      " -2.54394505e-02 -1.77159120e-04  9.08246636e-03  1.59095302e-02\n",
      "  4.11799364e-02 -3.94369513e-02 -9.64431837e-03  1.30792186e-02\n",
      "  6.87962770e-02  4.32192497e-02  7.54057488e-04  6.77741468e-02\n",
      "  4.93706279e-02 -3.47826141e-03 -1.06054535e-02  6.72492245e-03\n",
      " -1.39062116e-02  4.88276221e-02 -1.05736200e-02  3.50226625e-03\n",
      "  2.90225004e-03  2.40044426e-02  1.20272283e-02 -2.09796503e-02\n",
      " -2.39111949e-02  3.26579288e-02 -1.01322890e-03 -5.92755293e-03\n",
      " -7.40534114e-03  3.63137526e-03 -2.26698723e-02 -2.21242625e-02\n",
      "  3.86996046e-02  1.72322318e-02  3.85921299e-02 -5.04711047e-02\n",
      " -3.42144743e-02 -4.00443524e-02 -3.57910767e-02 -4.62560542e-02\n",
      "  6.70231804e-02 -4.61646402e-03 -3.29679670e-03  2.08443943e-02\n",
      " -5.14258957e-03 -5.00850789e-02  2.22504064e-02  4.66933772e-02\n",
      "  1.36208320e-02  1.77531205e-02  4.28083586e-03 -2.79332083e-02\n",
      " -1.93420835e-02 -3.87860574e-02 -3.09555512e-02 -6.64134175e-02\n",
      " -1.13434372e-02  1.64267290e-02  1.77629646e-02 -2.28220015e-03\n",
      " -3.30088250e-02 -1.36265182e-03 -2.17934083e-02 -2.67508999e-02\n",
      " -1.26376124e-02  1.61864306e-03 -4.95672598e-02  7.85445571e-02\n",
      "  4.10962254e-02  9.65922046e-03 -1.14643155e-02  1.68851623e-03\n",
      "  5.37663847e-02  2.05535605e-03 -4.11201157e-02  1.46330595e-02\n",
      " -3.75564136e-02 -3.35689262e-02  5.19259274e-03 -6.33088946e-02\n",
      "  3.32963802e-02  8.76124948e-03  1.33860554e-03 -3.95752303e-03\n",
      " -1.61677860e-02  8.26747045e-02  4.75944355e-02 -3.43055204e-02\n",
      "  2.50881705e-02 -3.50976065e-02  3.68657112e-02  4.12653107e-03\n",
      "  4.16018516e-02 -1.35181695e-01 -4.76337336e-02 -1.20025398e-02\n",
      " -3.48892026e-02  3.25454324e-02 -2.93570897e-03 -4.85056965e-03\n",
      " -1.04223818e-01  2.78610475e-02  1.41570093e-02  3.94396260e-02\n",
      " -3.88806164e-02 -1.42463353e-02 -5.19984215e-02  8.92738905e-03\n",
      " -1.99770965e-02 -2.51725204e-02 -3.41300331e-02  1.93041228e-02\n",
      " -5.20207323e-02 -6.72000125e-02 -9.46361944e-03 -1.25589606e-03\n",
      " -5.66048473e-02  2.62097921e-02  9.91585385e-03  4.38286513e-02\n",
      "  2.26631714e-03 -3.11896466e-02 -6.25468343e-02 -3.87792811e-02\n",
      " -6.83938935e-02  4.93722633e-02  5.85507266e-02 -4.08729799e-02\n",
      " -1.98638756e-02 -2.12634765e-02  4.98036742e-02 -4.51747887e-02\n",
      " -2.37141475e-02  2.32675411e-02  1.00594811e-01  9.87112522e-03\n",
      " -1.38014322e-02 -5.21040969e-02  9.08212457e-03  1.72427353e-02\n",
      "  5.91432117e-02  2.62337048e-02 -7.04641035e-03 -1.50031755e-02\n",
      " -3.76659376e-03  6.28262246e-03 -5.23982644e-02 -4.96638715e-02\n",
      "  3.06610707e-02 -3.33650457e-03  2.34911181e-02 -8.58829841e-02\n",
      " -4.62449640e-02  5.59700914e-02  3.09075869e-04  2.01729089e-02\n",
      " -2.98066647e-03  1.76645182e-02  1.54670030e-02 -7.41717964e-02\n",
      "  7.34986411e-03 -1.05014490e-02  2.45247446e-02  1.36878937e-02\n",
      " -1.17803579e-02  4.51543964e-02  3.29039693e-02 -3.50392354e-03\n",
      " -2.71315593e-02 -5.27364798e-02 -4.60164584e-02  2.22850014e-02\n",
      "  2.62272228e-02  5.56148728e-03  1.45788584e-02 -2.97145061e-02\n",
      "  3.57042477e-02  2.22534388e-02  3.89618240e-02 -7.92634487e-02\n",
      " -9.01090354e-03  2.19013058e-02 -5.49067371e-03  8.69960058e-03\n",
      "  4.33030687e-02 -2.12631896e-02  1.13292383e-02 -6.33699149e-02\n",
      "  3.63723449e-02  2.67442465e-02 -6.64251819e-02  1.70500036e-02\n",
      " -2.79691759e-02  2.36358005e-03 -1.81953702e-02  1.52955484e-02\n",
      " -8.50429945e-03  1.16647976e-02 -9.75921750e-02 -2.92094108e-02\n",
      " -5.42546958e-02  3.61234881e-02  3.25115919e-02  8.26974213e-03\n",
      " -2.96557904e-04  1.11556258e-02 -3.85188349e-02  2.36161221e-02\n",
      "  9.85921454e-03  5.73998280e-02  4.86060418e-02 -1.37579953e-02\n",
      " -6.19218219e-03  1.11972848e-02 -3.37175056e-02 -1.10515738e-02\n",
      " -7.08332807e-02 -1.01816608e-02 -3.66010629e-02 -1.55561473e-02\n",
      " -2.13109832e-02 -1.02760131e-02 -4.35734168e-02  5.55186793e-02\n",
      " -3.76547538e-02  5.29252030e-02 -3.45224440e-02 -2.43007112e-03\n",
      "  7.25553557e-02  4.45070583e-03  4.71416153e-02 -9.43881553e-03\n",
      " -1.98978279e-02  5.71899526e-02  8.60540271e-02 -5.25057651e-02\n",
      " -1.39550054e-02  1.17373094e-02  1.33974468e-02 -4.73052636e-02\n",
      " -5.41674122e-02  4.62725759e-02 -2.58971099e-02  1.51415374e-02\n",
      "  3.38944793e-02 -3.78252612e-03 -5.76042980e-02 -1.60082094e-02\n",
      "  2.42737513e-02  3.37359831e-02 -1.96820702e-02 -2.53464393e-02\n",
      " -4.75616790e-02 -5.68755977e-02 -2.28193533e-02  3.83186750e-02\n",
      " -1.78330615e-02  1.35963652e-02  7.85971759e-04  9.74015240e-03\n",
      "  3.34298834e-02 -2.60133930e-02 -7.38570746e-03  3.56451198e-02\n",
      " -2.68532559e-02 -7.53624141e-02 -2.66983919e-02 -4.46457640e-33\n",
      " -3.31645980e-02  1.41704008e-02 -3.92909460e-02 -3.46318893e-02\n",
      " -5.88680059e-03 -1.18212234e-02  1.53951179e-02  1.18474141e-02\n",
      "  1.07758036e-02  3.62141244e-02  7.87950587e-03 -2.31844820e-02\n",
      "  1.07623134e-02  1.72345936e-02  9.54293530e-04  2.83640344e-02\n",
      "  2.37420257e-02 -1.48057118e-02  1.24195032e-03  3.52347572e-03\n",
      "  2.33735051e-02  5.58307767e-02  5.38328588e-02 -3.74078676e-02\n",
      " -2.11805291e-02  1.52729073e-04 -7.27789942e-03  5.50559629e-03\n",
      "  3.05824596e-02  4.54633944e-02 -3.35786529e-02  3.16142812e-02\n",
      " -2.56392593e-03  3.96354683e-02 -1.47573035e-02  5.67167252e-02\n",
      " -5.62787354e-02 -5.04603982e-03  3.56154889e-02 -2.76198834e-02\n",
      " -2.32292321e-02 -4.63293009e-02 -3.70919518e-02 -4.23189141e-02\n",
      "  3.70305777e-02  7.88717624e-03  3.85176390e-02  1.74770341e-03\n",
      "  5.62765682e-03  6.18097652e-03 -6.90268725e-02 -9.42970905e-03\n",
      " -7.74675654e-03  1.68349948e-02  1.22767184e-02  2.26406939e-02\n",
      "  1.21008884e-02  1.11743826e-02  1.21539347e-02 -1.16861444e-02\n",
      " -4.41612452e-02  2.30048392e-02  2.20671818e-02 -5.87504432e-02\n",
      " -3.96428704e-02  6.83135316e-02 -3.29948030e-02 -3.66774127e-02\n",
      " -3.53655182e-02  1.76185146e-02  6.95641618e-03  5.92692383e-02\n",
      "  4.12156545e-02  7.98109844e-02 -5.36565669e-03  1.14238476e-02\n",
      " -2.96388399e-02 -1.15411403e-02  2.22812127e-02  7.93188065e-03\n",
      "  2.60356609e-02  1.28211444e-02  1.71346031e-02 -6.90196874e-03\n",
      " -1.07603250e-02  1.35715501e-02 -9.90740489e-04 -6.16075359e-02\n",
      "  4.40513231e-02 -8.26591335e-04 -2.78341342e-02 -1.23619828e-02\n",
      "  1.34629291e-02 -3.85745279e-02  1.08698942e-03  2.18713135e-02\n",
      " -3.32398750e-02  1.84615497e-02 -5.10103209e-03  3.74664888e-02\n",
      " -3.67543893e-03 -2.19246317e-02 -4.96485783e-03 -9.59824771e-03\n",
      "  2.33591106e-02  1.04876608e-02  4.38721627e-02 -1.51423952e-02\n",
      " -6.30309731e-02  8.23253952e-03 -1.09130749e-02 -4.06409428e-02\n",
      " -6.21690527e-02  2.21325867e-02 -2.71434262e-02  4.05539833e-02\n",
      " -8.09454359e-03 -1.76408433e-03  3.01526114e-02 -5.42264106e-03\n",
      " -4.69821356e-02 -1.73767656e-02  4.11631502e-02  3.20635997e-02\n",
      " -2.22943518e-02 -1.58162080e-02 -4.50721011e-02  5.69486693e-02\n",
      "  4.71596159e-02 -5.78058846e-02  1.32474797e-02 -4.71293414e-03\n",
      "  1.66824506e-07  4.81090620e-02  5.03628328e-02  5.45263737e-02\n",
      "  2.07568705e-02 -1.19080925e-02 -6.37494400e-03  5.26373833e-03\n",
      "  7.21948594e-02 -2.21763272e-02  2.20103208e-02 -9.90417087e-04\n",
      " -1.37163736e-02  6.89209392e-03  2.46912371e-02 -1.39462113e-01\n",
      "  2.56979838e-03 -4.64827605e-02 -4.04967181e-02 -6.08555898e-02\n",
      " -1.53212901e-02  1.36129886e-01  9.45034772e-02  4.25741524e-02\n",
      "  4.67130877e-02 -2.30678134e-02 -1.20965578e-02  3.86672951e-02\n",
      "  2.11656629e-03 -2.51473505e-02 -1.15076452e-02 -3.46506014e-02\n",
      " -2.29533687e-02 -6.33849343e-03 -3.05175465e-02 -1.56236636e-02\n",
      "  1.39513863e-02  3.27489543e-04  2.00327043e-03  4.15108446e-03\n",
      " -2.22924799e-02 -3.62589769e-02 -2.36579143e-02 -1.87817533e-02\n",
      " -1.96288414e-02  4.52125743e-02 -8.12569186e-02 -2.14569196e-02\n",
      " -4.41542752e-02 -2.68476326e-02  2.01974194e-02  2.82993098e-03\n",
      " -1.95011683e-02 -3.45331691e-02  2.26913672e-02  3.78325619e-02\n",
      " -1.02544166e-02 -2.19750125e-03 -8.96744803e-02 -4.50031161e-02\n",
      "  8.09705537e-03 -2.05805413e-02 -2.02998389e-02 -2.09921673e-02\n",
      " -1.79405212e-02  5.81897199e-02 -7.63653219e-03  1.50847603e-02\n",
      "  1.78279755e-34  4.86179553e-02  4.22228537e-02  4.71596606e-02\n",
      "  5.89047521e-02  3.99784409e-02 -5.27071171e-02  1.56906005e-02\n",
      " -5.25098410e-04  1.13652032e-02 -6.56410754e-02 -2.20849253e-02]\n",
      "\n",
      "Sentence: Sentences can be embedded one by one or as a list of strings.\n",
      "Embedding: [ 4.31718118e-02 -5.38701341e-02 -3.78044508e-02  4.27235663e-02\n",
      " -2.35409327e-02  3.44861522e-02  2.89586894e-02  1.92816881e-03\n",
      "  2.41732802e-02 -3.17012183e-02  7.32856020e-02  1.25589697e-02\n",
      "  3.64620797e-02 -2.05251705e-02  2.81973872e-02 -6.87329397e-02\n",
      "  4.22230624e-02  9.31727758e-04  3.54035571e-02  1.41786877e-02\n",
      "  7.83995632e-03  2.31179427e-02 -4.84743109e-03  1.07173743e-02\n",
      "  4.39491775e-03  5.47800167e-03 -3.80338542e-02 -3.05488426e-03\n",
      "  5.72235836e-03 -6.78214058e-02 -4.88007963e-02 -1.45032415e-02\n",
      "  6.68004574e-03 -7.17479661e-02  1.64644939e-06  1.07563986e-02\n",
      " -3.60921919e-02 -2.37057507e-02 -5.22792079e-02  3.46110426e-02\n",
      " -5.42172603e-03  1.62611026e-02  1.96564887e-02  2.25395560e-02\n",
      " -2.25994573e-03  4.06342372e-02  8.17157850e-02  2.48179529e-02\n",
      "  5.31884059e-02  7.82715529e-02 -1.91813204e-02 -1.94087178e-02\n",
      " -2.62805484e-02 -2.44083963e-02  5.49405813e-02  1.90318804e-02\n",
      "  1.60811134e-02 -2.68896241e-02 -8.24691169e-03  7.33443722e-02\n",
      "  1.00123286e-02  2.93315854e-02  3.42867291e-03 -2.13270094e-02\n",
      " -1.62442494e-03 -5.56256715e-03 -7.64880255e-02 -5.85450344e-02\n",
      " -2.82272603e-02  7.51852104e-03  7.11226165e-02  1.95454410e-03\n",
      "  5.45928022e-03  3.22310673e-03  5.12800366e-02 -3.54106277e-02\n",
      " -5.03608696e-02  4.70519699e-02  5.15472749e-03  1.52287148e-02\n",
      " -1.06680952e-02  3.16299014e-02 -9.09038074e-03 -4.01326865e-02\n",
      " -4.35236134e-02 -1.94969494e-02  1.65604707e-02 -4.71168607e-02\n",
      " -3.92091498e-02 -3.07756793e-02 -2.94167344e-02 -4.20826226e-02\n",
      "  2.27074022e-03 -2.78329477e-02  1.69421341e-02  7.74501497e-03\n",
      " -5.23741320e-02 -4.50039543e-02  3.83606032e-02 -4.90787029e-02\n",
      "  5.06618842e-02  1.01614725e-02 -1.25022437e-02 -4.64552734e-03\n",
      " -1.54539663e-02  1.58862695e-02  1.18369451e-02 -3.59232277e-02\n",
      " -7.76226521e-02  3.43358852e-02 -2.14709565e-02 -6.86098784e-02\n",
      " -5.46235405e-02  7.83901513e-02 -3.00703142e-02 -3.37549821e-02\n",
      " -4.04999182e-02  4.80514839e-02  9.53906495e-03  2.31399331e-02\n",
      " -8.16115662e-02 -6.51691249e-03  1.54212872e-02  7.04256967e-02\n",
      " -1.25068799e-02 -2.48266067e-02 -1.71328951e-02  6.13109674e-03\n",
      "  5.44413142e-02 -1.40566267e-02 -6.24516513e-03  3.65787707e-02\n",
      "  7.36229941e-02 -6.05682842e-03 -3.61630097e-02 -1.42203481e-03\n",
      "  4.43165302e-02 -3.14515643e-03  3.18768136e-02 -1.30947651e-02\n",
      " -3.69525328e-02 -4.98034293e-03  1.30017090e-03 -2.05213130e-02\n",
      "  2.06277613e-02  5.93870971e-03 -3.07157054e-03 -3.97512913e-02\n",
      "  4.29889709e-02  6.49802014e-02 -6.76022172e-02  5.41655347e-02\n",
      "  1.52570545e-03 -3.72908488e-02 -4.02426943e-02 -2.28771679e-02\n",
      "  1.31769806e-01  4.87876916e-03  1.39470724e-02  4.92436253e-02\n",
      "  2.49219518e-02 -8.76091979e-03 -5.38766431e-03 -2.65595280e-02\n",
      " -1.19766686e-02 -2.32006926e-02 -2.67433766e-02  5.66916401e-03\n",
      "  2.21721418e-02  4.67294268e-02 -5.78486919e-02  8.22120458e-02\n",
      " -3.36836907e-03  8.09647292e-02  1.41423456e-02  1.02393106e-01\n",
      " -5.76837407e-03 -1.15877306e-02  4.90584895e-02  5.87830096e-02\n",
      "  6.50030151e-02  4.74621765e-02 -2.89464314e-02 -1.76581892e-03\n",
      "  3.32561210e-02  2.91198101e-02  6.03811778e-02  3.73512652e-04\n",
      "  1.06575675e-02 -5.96284494e-02 -7.28601068e-02  2.95080431e-02\n",
      "  9.54460725e-03 -2.71541681e-02 -5.63305095e-02  9.66679829e-04\n",
      " -4.77729067e-02  4.67576720e-02  4.87259869e-03 -6.57519922e-02\n",
      " -1.42248608e-02  3.99872921e-02 -1.09798070e-02  7.68942833e-02\n",
      " -4.00003940e-02  2.96826921e-02  2.81303693e-02 -5.55424429e-02\n",
      "  6.31277217e-03  5.00450544e-02  1.89884342e-02  5.38684018e-02\n",
      " -1.95981227e-02  1.08601050e-02  1.64150894e-02  1.44135728e-02\n",
      "  1.71448644e-02  2.17624567e-02 -4.98863533e-02  1.56105636e-02\n",
      "  4.83735884e-03  1.87053774e-02 -3.18547641e-03  2.66863108e-02\n",
      "  5.55552952e-02 -4.88005690e-02 -3.02928947e-02  2.52110381e-02\n",
      "  1.07264845e-02  1.88270286e-02 -1.50687983e-02  3.43831740e-02\n",
      "  4.15124744e-02  1.37789082e-02 -5.54848239e-02  1.43847717e-02\n",
      " -5.88139817e-02 -6.01675846e-02  2.69856155e-02 -5.46130240e-02\n",
      "  8.14630184e-03 -1.17758615e-02  1.57441869e-02  1.43904844e-03\n",
      " -2.64554638e-02 -4.48877215e-02  4.39732336e-02 -1.06147920e-04\n",
      " -2.25905348e-02  3.00296657e-02  1.97440553e-02  7.44074211e-03\n",
      " -1.93790141e-02  8.09793081e-03  4.34860326e-02 -1.08547727e-04\n",
      " -3.77225690e-02  2.67195776e-02 -4.63158004e-02 -1.53400796e-03\n",
      "  8.05306155e-03 -4.30901535e-02 -2.13848986e-02  1.20185409e-02\n",
      "  8.41403380e-03  2.48269760e-03 -3.09566464e-02 -9.05277506e-02\n",
      " -4.76693846e-02  1.22606456e-02 -1.36467023e-02 -2.63655204e-02\n",
      " -7.65550509e-03  8.72373953e-03  2.65724622e-02  8.40102672e-04\n",
      " -5.55933174e-03 -9.29540582e-03  3.19337584e-02  5.94646558e-02\n",
      "  1.83206126e-02 -7.56547228e-02 -5.59388995e-02 -1.20871421e-02\n",
      " -3.16260904e-02  3.62186618e-02  7.53606856e-03 -6.15654141e-02\n",
      " -2.30458975e-02 -3.51672457e-03  1.23332124e-02 -9.67646390e-03\n",
      "  4.96861115e-02 -8.42256397e-02  1.52396252e-02 -1.82445087e-02\n",
      "  7.70462453e-02  9.28718224e-02  4.03725915e-02  1.11732624e-01\n",
      " -1.03270421e-02 -2.54558660e-02  2.13153679e-02 -1.16184610e-03\n",
      "  2.82594259e-03  5.06966785e-02 -3.13697383e-02 -8.14278610e-03\n",
      "  1.38386954e-02  4.66889478e-02  5.09671681e-02  3.77154425e-02\n",
      " -2.94988900e-02  3.60631645e-02 -2.61162641e-03  2.72181118e-04\n",
      " -6.71807304e-02 -6.54026568e-02 -3.43590640e-02  1.91067588e-02\n",
      "  4.13293876e-02 -1.10970791e-02  4.51952666e-02 -5.93564659e-02\n",
      "  1.06963711e-02 -1.82229765e-02 -5.65814376e-02  1.20387496e-02\n",
      "  4.44774590e-02  1.87049583e-02  1.63809825e-02  5.51151037e-02\n",
      " -2.23332271e-02  2.12861784e-02 -1.20339738e-02  3.26752588e-02\n",
      "  1.47003997e-02 -8.16678163e-03  1.12904012e-02 -3.00620627e-02\n",
      " -2.34345458e-02 -2.68646367e-02 -1.28718186e-03 -7.67190158e-02\n",
      "  2.22606678e-03 -5.89485373e-03  2.63103824e-02  2.07132054e-03\n",
      " -6.91152364e-02 -1.43792890e-02  2.68788580e-02 -3.51540335e-02\n",
      " -2.69612186e-02  2.54715583e-03 -6.48881495e-02  3.18727829e-02\n",
      "  1.70126986e-02 -4.54004854e-02 -1.80615913e-02 -1.61116682e-02\n",
      "  5.70773371e-02 -2.78267078e-03 -6.45586029e-02  7.86598027e-02\n",
      "  2.29075775e-02  6.81839883e-03 -9.11737047e-03 -2.27726344e-02\n",
      " -4.76526357e-02  4.88431379e-02 -2.09891349e-02 -2.43694037e-02\n",
      " -5.01211174e-03  6.70253858e-02  6.91364752e-03  2.25843173e-02\n",
      "  2.51125358e-02 -6.92502130e-03  8.59401375e-03  2.38977112e-02\n",
      "  3.29738334e-02 -1.05310589e-01  1.22094266e-02 -1.22263934e-02\n",
      " -5.73768876e-02  1.84311420e-02  2.97158137e-02 -6.09429628e-02\n",
      " -6.55256286e-02  3.55713069e-02  5.64321876e-03  3.34644970e-03\n",
      " -3.59686539e-02 -8.83413758e-03 -6.97895288e-02  6.89779446e-02\n",
      " -4.88214754e-03  2.23995168e-02 -3.16054076e-02 -7.41184875e-03\n",
      "  3.19351628e-02 -5.18788509e-02  2.11602226e-02 -5.03339954e-02\n",
      "  9.10583418e-03  2.13354453e-02  1.66838448e-02  3.49019580e-02\n",
      " -6.38500527e-02 -6.75627543e-03 -1.27405319e-02 -4.63366769e-02\n",
      " -1.14779556e-02  2.08778717e-02  2.44822148e-02  3.66464001e-03\n",
      " -2.86098407e-03  2.29389686e-02  2.13745870e-02 -3.48900668e-02\n",
      " -3.00387964e-02  4.78870906e-02  5.83370477e-02 -9.70498100e-03\n",
      "  1.38233574e-02 -3.27485651e-02 -8.11417762e-04  9.54227336e-03\n",
      "  1.20401755e-02  1.97230298e-02 -4.74859058e-04 -1.39226271e-02\n",
      " -5.21069989e-02 -1.75592359e-02 -5.41699007e-02 -1.17969932e-02\n",
      " -1.71030387e-02 -3.50194983e-02  3.38661373e-02 -6.76586926e-02\n",
      " -2.27606688e-02  1.95606761e-02  5.50249517e-02  1.22029008e-02\n",
      " -1.75167178e-03  7.22445501e-03  1.16349971e-02 -1.61908362e-02\n",
      " -3.37754749e-02  3.22626568e-02 -2.03813910e-02 -2.33859774e-02\n",
      " -1.29992170e-02 -1.66799221e-02  1.03070429e-02 -1.46030299e-02\n",
      " -7.79069811e-02 -8.25812593e-02 -3.38809527e-02  3.81114371e-02\n",
      "  7.86008965e-03  2.41454970e-02 -2.75715478e-02  1.30867623e-02\n",
      " -7.88598415e-03  1.78651772e-02  5.37323654e-02 -3.01823094e-02\n",
      "  1.69455577e-02  1.19571052e-02  3.52576812e-04  4.90208901e-02\n",
      " -8.57212208e-03  1.71264505e-03  4.83880844e-03 -4.10080925e-02\n",
      " -4.68120091e-02 -2.32563168e-03 -5.16776741e-02  3.10030598e-02\n",
      "  1.60961282e-02 -1.00803711e-02 -3.72487400e-03 -3.53388339e-02\n",
      "  2.95961052e-02  2.89097391e-02 -7.59911090e-02 -5.02980836e-02\n",
      " -2.11783499e-02  3.20462659e-02 -3.84538099e-02  2.45102402e-02\n",
      " -2.04188377e-02  6.02112804e-03 -9.81934555e-03  3.74777876e-02\n",
      "  3.40838172e-02  1.28863687e-02  5.67342378e-02 -8.09703767e-02\n",
      " -8.93603917e-03  1.33352615e-02 -2.51565799e-02  2.58413865e-03\n",
      " -6.51802719e-02  1.34400548e-02 -2.04681568e-02  6.53379923e-03\n",
      "  4.56973538e-03  1.99271236e-02 -6.07339852e-02  1.40692079e-02\n",
      " -5.75334057e-02  9.79796518e-03  3.55392694e-02 -2.45283395e-02\n",
      " -4.73311357e-03 -2.77492646e-02  2.34283060e-02 -8.76287595e-05\n",
      "  7.30442908e-03  1.42028546e-02  4.92807515e-02 -3.16540115e-02\n",
      " -1.34902298e-02  3.08487844e-02  2.80402154e-02 -4.33069021e-02\n",
      " -4.42284532e-02  3.80738750e-02  9.47059089e-05 -4.34896052e-02\n",
      "  1.43868085e-02  2.44334480e-03 -4.84073311e-02  1.08955121e-02\n",
      " -9.87490825e-03  4.59295474e-02  3.96379307e-02 -2.60116849e-02\n",
      "  2.48134118e-02 -5.37148826e-02  5.62824979e-02  8.81363358e-03\n",
      "  5.25077134e-02 -1.47371190e-02 -1.74380951e-02  3.45084704e-02\n",
      "  3.75523195e-02 -4.70167473e-02 -1.94911286e-02  3.82631682e-02\n",
      " -5.67595623e-02 -1.78613549e-03  2.33404357e-02 -5.88216602e-33\n",
      " -4.87187915e-02 -2.76265573e-02 -3.38240564e-02  2.66188122e-02\n",
      " -3.39277163e-02 -8.49195756e-03 -1.91250294e-02  3.00252363e-02\n",
      "  3.40782180e-02  5.11157885e-02 -1.92479752e-02  2.85642333e-02\n",
      "  3.66040356e-02  1.68858375e-02  4.77259196e-02  1.23802302e-02\n",
      "  2.14844141e-02  4.93669882e-04  1.21273743e-02 -5.82143851e-02\n",
      "  1.62954740e-02 -7.14257546e-03  4.80092354e-02  2.51190588e-02\n",
      "  4.60097790e-02 -2.29839869e-02 -2.05696616e-02 -3.22232558e-03\n",
      "  4.00091670e-02  3.52309644e-02 -3.43153961e-02  2.75632646e-03\n",
      " -1.25138452e-02  1.97685380e-02  5.53492457e-03  1.03744514e-01\n",
      "  5.77611895e-03 -5.65426275e-02  4.19559218e-02 -3.78830954e-02\n",
      " -3.93443145e-02 -6.24309704e-02 -2.24395236e-03 -5.46548367e-02\n",
      "  4.56134714e-02 -5.69247408e-03  3.38917263e-02 -1.44448075e-02\n",
      "  2.72109197e-03  1.11190975e-02 -5.00661246e-02 -1.61127243e-02\n",
      "  1.72815204e-03  6.88877180e-02  1.16492221e-02  2.83171386e-02\n",
      "  6.97187381e-03  2.68372297e-02 -7.72087742e-03  2.16828920e-02\n",
      "  1.15183135e-02  8.72833058e-02 -6.27272530e-03 -6.44473583e-02\n",
      " -1.58233792e-02  4.03268225e-02 -1.69728417e-02 -1.61189307e-02\n",
      " -3.75576653e-02  7.02938437e-02 -3.30486447e-02  4.66323905e-02\n",
      "  1.18027413e-02  6.51076064e-02 -1.16979126e-02 -8.28347541e-03\n",
      " -5.46905324e-02 -2.00227071e-02  8.42675916e-04 -8.19525495e-03\n",
      "  2.08357461e-02  1.37454243e-02 -1.29929115e-03 -3.94575149e-02\n",
      " -2.00184453e-02 -1.53721767e-02  1.17272083e-02 -4.40110862e-02\n",
      "  5.39267436e-02 -2.33010203e-02 -2.24211421e-02 -3.65215004e-03\n",
      "  2.92212889e-02  7.56445015e-03 -2.90923659e-02  4.01517563e-02\n",
      " -2.00853720e-02 -1.79865165e-03 -1.26235802e-02  2.51076985e-02\n",
      " -4.69286144e-02 -3.08554210e-02 -3.63375875e-04  6.01792615e-03\n",
      "  3.97508964e-02  1.38547691e-02  2.49774661e-02  1.76975634e-02\n",
      " -9.31573212e-02 -9.83684510e-03  8.44930485e-03 -1.95390787e-02\n",
      " -3.26569006e-02  5.13732061e-03  5.80927311e-03  2.08536685e-02\n",
      " -5.97835658e-03  5.86811826e-02 -1.49496859e-02 -5.72966151e-02\n",
      " -5.98235149e-03  1.95203885e-03  2.72978167e-03  6.07001036e-03\n",
      " -2.00525876e-02 -1.31687261e-02 -4.06228192e-02  5.68997450e-02\n",
      "  4.44969460e-02 -1.24308066e-02  1.96967609e-02  3.80979553e-02\n",
      "  2.30237703e-07  1.10575221e-02  4.79512736e-02  6.18299246e-02\n",
      "  4.40278873e-02  6.17665751e-03  2.58290325e-03  3.38913836e-02\n",
      " -5.32937655e-03 -2.59284023e-02 -1.26144309e-02  2.46495772e-02\n",
      " -1.68766489e-03  1.17908604e-03  2.40442641e-02 -9.77309272e-02\n",
      "  1.97368208e-02 -5.52921817e-02 -6.17424622e-02 -4.87151816e-02\n",
      "  1.11079938e-03  1.18732028e-01  8.13257992e-02  3.32449004e-02\n",
      "  4.38326932e-02 -2.49559265e-02 -3.59626338e-02  1.66318826e-02\n",
      "  5.93766989e-03 -1.43971574e-02  4.46710689e-03 -6.01986647e-02\n",
      " -5.65912053e-02 -8.21543857e-03  5.83057944e-03 -1.69482026e-02\n",
      "  9.58630629e-03  1.46733662e-02  5.05845733e-02  3.06891892e-02\n",
      "  6.60468265e-02 -2.56551988e-02 -2.78858021e-02 -3.19173671e-02\n",
      " -3.39236520e-02  1.49903009e-02 -3.03336550e-02 -6.06490253e-03\n",
      " -4.81771026e-03  1.72137264e-02 -8.23371671e-03  1.55548304e-02\n",
      "  2.69106999e-02  5.44310128e-03 -1.06899347e-02 -7.82139041e-03\n",
      " -4.44506668e-02  2.55874749e-02 -5.74760623e-02 -2.05442011e-02\n",
      " -3.07850000e-02 -1.57855153e-02 -7.07539404e-03 -4.21312787e-02\n",
      "  3.79934348e-02  6.27764389e-02 -7.67790619e-03 -3.18353251e-02\n",
      "  1.99277700e-34  1.04834270e-02 -3.39326337e-02  3.93821113e-02\n",
      "  5.53065278e-02  9.42168664e-03  1.09727848e-02 -4.91940305e-02\n",
      "  2.95023937e-02 -8.85376707e-03 -5.96248023e-02 -2.37825532e-02]\n",
      "\n",
      "Sentence: Embeddings are one of the most powerful concepts in machine learning!\n",
      "Embedding: [-2.98611540e-02 -1.37522593e-02 -4.75401841e-02  2.72127222e-02\n",
      "  3.40054594e-02  3.16465870e-02  4.26963866e-02  3.29792150e-03\n",
      "  4.35717441e-02  2.53837388e-02  3.02528404e-02  3.21130641e-02\n",
      " -3.99913490e-02  1.28761018e-02  6.70220330e-02 -7.92899951e-02\n",
      "  4.68771979e-02  2.40266360e-02 -2.07997616e-02 -1.07433060e-02\n",
      " -1.19410427e-02 -5.39290644e-02  4.21055891e-02  2.23588850e-02\n",
      " -2.98949257e-02  8.35984293e-03  1.58385113e-02 -4.80235331e-02\n",
      "  1.88434380e-03 -1.67521611e-02 -2.15629339e-02 -3.88488062e-02\n",
      "  3.06274686e-02  4.20526303e-02  1.69483405e-06 -1.86928995e-02\n",
      " -1.24558927e-02  1.32128727e-02 -4.89040166e-02  1.34746404e-02\n",
      "  2.28873137e-02  8.81773233e-03  8.64930917e-03 -2.00949758e-02\n",
      " -3.15217599e-02 -2.53433287e-02  7.57319108e-02  3.62446383e-02\n",
      "  1.25290556e-02  3.09694614e-02  4.50758683e-03 -3.50042023e-02\n",
      " -4.42525081e-04 -9.76648927e-03  6.04545400e-02  4.03472185e-02\n",
      "  1.10734319e-02  6.56203507e-03 -5.84601983e-03  3.79781006e-03\n",
      " -4.46915217e-02  1.76405106e-02  2.45917458e-02 -3.60037386e-03\n",
      "  1.02473363e-01  3.73759307e-02  6.13313355e-03 -2.24676374e-02\n",
      "  1.46482410e-02  5.00536561e-02 -2.29907706e-02  1.12924948e-02\n",
      " -3.10552660e-02 -1.49509218e-02 -2.53127469e-03  3.20944712e-02\n",
      " -4.67056111e-02 -4.85887080e-02  2.98306141e-02  6.44215867e-02\n",
      " -3.12613361e-02  3.57407294e-02  4.16526981e-02 -5.52517101e-02\n",
      " -8.74632876e-03 -2.18630731e-02 -1.12744607e-02 -2.14436036e-02\n",
      " -1.32824024e-02 -2.04866026e-02 -1.00576123e-02  3.54763493e-02\n",
      " -7.47601548e-03 -3.70188095e-02  5.77893741e-02 -2.18169205e-02\n",
      "  4.36226651e-03  2.04380527e-02  3.36814933e-02 -4.92800586e-02\n",
      "  4.82794233e-02 -1.81002088e-03 -1.05119161e-02  4.13323082e-02\n",
      " -6.79833218e-02  1.75716169e-02 -4.43412960e-02  9.90840793e-03\n",
      " -3.81809957e-02  1.10827098e-02 -5.07279299e-02 -2.17451416e-02\n",
      " -1.03836246e-02  4.60332260e-02  1.55862151e-02 -4.21366431e-02\n",
      " -2.72146482e-02  3.22818086e-02 -4.24739644e-02  2.71207187e-02\n",
      " -7.41061568e-02  4.20107134e-02  2.02437900e-02  7.31810629e-02\n",
      " -8.97695869e-03 -2.31160112e-02 -3.93559746e-02 -1.46008851e-02\n",
      " -3.30910161e-02  1.12240119e-02  2.58562411e-03 -4.36852081e-03\n",
      "  1.85855553e-02  2.69934572e-02 -1.67214908e-02  3.69570069e-02\n",
      "  4.44489084e-02 -2.21723951e-02  6.72966195e-03  1.22935399e-02\n",
      "  1.71758253e-02 -2.36479379e-03  3.72264124e-02 -2.22871043e-02\n",
      "  2.94603743e-02 -2.33691297e-02  5.38467849e-03 -3.06581408e-02\n",
      " -2.38919966e-02 -2.63614580e-02 -2.01788899e-02  1.11245669e-01\n",
      " -1.99836958e-02 -3.54029872e-02  3.84143591e-02  2.53069215e-02\n",
      "  1.99550688e-02  5.53518161e-02 -1.99332554e-02 -2.16715503e-03\n",
      "  4.91093136e-02 -4.03530821e-02 -1.16977124e-02 -5.33113964e-02\n",
      "  8.29585921e-03 -5.08251674e-02 -2.65504215e-02 -1.53242722e-02\n",
      "  5.78812417e-03  2.46573938e-03 -3.44449431e-02 -1.85132760e-03\n",
      " -3.95730659e-02 -2.71691196e-02  4.93567958e-02  8.38369131e-02\n",
      "  5.43491393e-02  8.22261199e-02  1.23895016e-02 -4.79797134e-03\n",
      "  7.77339679e-04  2.98486482e-02 -1.85585078e-02  5.98795339e-02\n",
      " -6.82789879e-03  9.78154130e-04  2.85485927e-02 -7.64614856e-03\n",
      " -1.86620224e-02 -2.69287713e-02 -2.90332865e-02 -1.37871299e-02\n",
      " -2.57600006e-03 -2.20173988e-02 -1.70821715e-02 -3.81843187e-02\n",
      "  2.21505463e-02 -3.59234512e-02 -1.19439531e-02 -3.18308100e-02\n",
      " -4.80801240e-02  9.77632683e-03 -1.04864815e-03  4.15372290e-02\n",
      " -1.10974545e-02 -4.72829975e-02  1.90984625e-02 -5.31177446e-02\n",
      "  2.11326107e-02 -2.53061438e-03  5.61055280e-02 -1.33795300e-02\n",
      " -5.95856830e-03 -1.20307989e-02  4.63929884e-02 -2.81908922e-02\n",
      "  2.25355309e-02 -2.50470126e-03 -3.52453291e-02  2.55494881e-02\n",
      "  9.10395849e-03  3.25209321e-03  2.55968934e-03 -1.25624100e-02\n",
      " -3.51496451e-02 -4.28945981e-02 -2.32334691e-03  2.41021216e-02\n",
      " -5.16841933e-03  1.68739744e-02  5.52647561e-03  2.36791987e-02\n",
      "  5.65164387e-02 -3.47869061e-02 -6.34517819e-02 -7.45629100e-03\n",
      " -1.78447850e-02  5.35898544e-02  2.67291684e-02 -8.74199867e-02\n",
      "  1.04195541e-02 -4.13972884e-04 -3.04443156e-03  9.14250966e-03\n",
      "  2.91529316e-02 -5.81831895e-02  6.83463663e-02 -4.08618003e-02\n",
      " -9.09789465e-03 -3.40770036e-02  3.52410600e-02 -1.02628144e-02\n",
      " -5.72477118e-04 -2.73457915e-03  1.59635898e-02  4.49073175e-03\n",
      " -2.09051464e-02  3.02769449e-02  2.46119890e-02 -1.44067109e-02\n",
      "  1.73268430e-02  1.99032226e-03  4.23051119e-02 -2.39177272e-02\n",
      " -3.25547755e-02 -1.45939765e-02  3.95100825e-02 -6.04650006e-02\n",
      " -3.02065574e-02  1.67189408e-02 -2.26817504e-02 -2.61954889e-02\n",
      " -5.51320240e-02  1.44908410e-02 -1.99246686e-02  3.99752194e-03\n",
      "  3.12609524e-02 -4.90727909e-02 -9.49667650e-04  5.39497100e-02\n",
      " -9.10079945e-03 -2.69486792e-02 -3.63159217e-02 -1.38437124e-02\n",
      " -4.45621945e-02  5.49358875e-02  2.17589014e-03  2.23446591e-03\n",
      " -5.23017766e-03 -1.47894444e-02  3.60592045e-02  1.45262936e-02\n",
      "  8.39190744e-03 -6.10361435e-02 -7.89949577e-03 -2.98298942e-03\n",
      "  3.56564764e-03  8.33992213e-02 -2.61215251e-02  8.06723088e-02\n",
      "  3.63061880e-03  1.69974435e-02  2.58604269e-02  1.09439623e-03\n",
      " -4.57063243e-02  5.55678718e-02  2.00643484e-02  4.76660915e-02\n",
      " -4.91054133e-02 -1.86080411e-02  3.34404260e-02 -2.57310290e-02\n",
      " -3.16370605e-03  7.21444413e-02 -1.61518995e-02 -1.33934077e-02\n",
      " -6.06294014e-02 -2.82187108e-02 -8.91925395e-03 -2.71166069e-03\n",
      "  8.04913137e-03 -4.95210253e-02  7.89434537e-02  2.76427791e-02\n",
      " -5.42582525e-03 -3.06718377e-03 -4.11826782e-02  1.39172599e-02\n",
      "  3.04253623e-02  1.02856411e-02  1.06679304e-02 -5.56553863e-02\n",
      " -1.75083168e-02  2.03868542e-02  8.43308587e-03  3.82471122e-02\n",
      " -3.89099941e-02 -1.61303487e-02  3.18059288e-02 -7.32970387e-02\n",
      " -1.76502094e-02 -4.79874723e-02 -5.55041954e-02 -5.00749098e-03\n",
      "  4.46778577e-04  3.57333422e-02 -8.24686023e-04 -3.34324278e-02\n",
      " -3.32417190e-02 -2.46460270e-02  2.15331987e-02  3.90856946e-03\n",
      "  2.53470950e-02  6.02989830e-03 -7.81611260e-03  1.23765804e-02\n",
      " -1.71039738e-02  2.68103555e-02  2.83681578e-03 -1.27643887e-02\n",
      "  1.00510873e-01  1.03580868e-02 -3.55143845e-02  1.56616513e-02\n",
      " -9.85949486e-02  4.58441079e-02 -3.15230750e-02 -2.35781185e-02\n",
      " -2.78350227e-02 -7.75873341e-05 -2.82363035e-02 -1.92918219e-02\n",
      "  1.87389143e-02  5.71940914e-02  2.56911926e-02 -3.20030451e-02\n",
      "  1.99074727e-02 -3.15819792e-02 -4.02061380e-02  5.77630773e-02\n",
      "  1.72974411e-02 -5.37013151e-02 -1.25325797e-02 -1.45483920e-02\n",
      " -5.76174483e-02  1.09727560e-02 -2.04727892e-02  2.85541005e-02\n",
      " -5.04399948e-02  4.36991192e-02  1.75710879e-02 -1.02343643e-02\n",
      " -9.69772413e-02 -2.99995206e-02 -2.86679380e-02  2.24937089e-02\n",
      " -1.68121085e-02 -1.43673960e-02 -8.79588258e-03 -1.69043969e-02\n",
      "  2.41557881e-02 -6.53191954e-02 -4.10799831e-02 -2.34058257e-02\n",
      " -6.76064715e-02 -1.55690266e-02  3.62357944e-02  7.83159956e-02\n",
      " -4.97516505e-02 -7.08547309e-02 -5.01180217e-02 -8.56428000e-04\n",
      "  5.44899097e-03  4.34707757e-03  9.88053083e-02 -2.16415208e-02\n",
      " -1.87750962e-02  1.15069197e-02  2.63996515e-02  1.65236033e-02\n",
      " -2.24058013e-02 -4.31826897e-02  1.31803915e-01 -2.97034178e-02\n",
      "  2.65934225e-02 -1.38888629e-02 -1.67003702e-02  3.44145410e-02\n",
      " -8.94355681e-03  6.16001710e-02 -3.42302844e-02  2.46425997e-03\n",
      " -8.14091135e-03  5.80325425e-02  5.24208434e-02 -1.53281102e-02\n",
      "  4.01382931e-02  1.51407095e-02 -3.01462295e-03 -4.97020446e-02\n",
      " -4.24302975e-03  5.77288680e-02  3.17874216e-02  4.74008210e-02\n",
      "  2.95217857e-02 -1.50123285e-02 -2.47945487e-02 -7.11502135e-02\n",
      "  2.06848495e-02  3.11488044e-02 -5.86070726e-03  1.62786990e-02\n",
      " -3.93683501e-02  5.46505712e-02  3.26595455e-02 -1.87021680e-02\n",
      " -9.79863107e-02  4.33779880e-03 -5.58156632e-02 -1.34620816e-02\n",
      "  2.88454220e-02  1.58748273e-02 -3.32564600e-02  1.44418736e-03\n",
      " -5.51108271e-02  8.24674964e-02  2.38845795e-02 -2.04838403e-02\n",
      " -4.78585018e-03  3.78722735e-02 -4.87563349e-02  3.44647169e-02\n",
      "  1.10358391e-02  1.12450207e-02  1.33262929e-02 -3.46375108e-02\n",
      " -6.92221001e-02  7.30118854e-03 -6.57010125e-03  1.73203759e-02\n",
      "  5.23054739e-03  4.48131971e-02  3.89852785e-02 -1.99274272e-02\n",
      " -1.80920269e-02  3.25937979e-02 -2.02027168e-02  4.86261386e-04\n",
      " -8.88759550e-03 -1.91348344e-02  2.50686128e-02  4.74019796e-02\n",
      "  2.18654587e-03 -1.69988368e-02  3.62670906e-02  3.46249738e-03\n",
      "  4.21924517e-03  8.04171041e-02  3.10627315e-02 -1.04944047e-03\n",
      " -3.55466753e-02  4.34837006e-02 -3.06218751e-02 -3.03191636e-02\n",
      " -4.13175449e-02 -1.05258487e-02 -2.35242266e-02 -1.86772272e-02\n",
      "  4.42936691e-03  5.45056574e-02 -6.05017766e-02  2.48422306e-02\n",
      " -3.36967558e-02 -4.54168953e-02 -2.63173096e-02  6.98055327e-03\n",
      "  6.92871213e-02 -2.04491317e-02 -1.96812805e-02 -9.72555764e-03\n",
      " -1.21564800e-02  7.89343659e-03  1.84750487e-03 -6.93651140e-02\n",
      "  2.43357234e-02  4.00609933e-02  3.44013423e-02 -2.84281615e-02\n",
      " -1.09431669e-02  1.38743129e-02 -4.40586824e-03  1.19350827e-03\n",
      " -8.81164894e-02  1.15931034e-02 -2.56350785e-02  5.57525419e-02\n",
      "  1.26946211e-01  5.39565980e-02 -1.41437203e-02  1.27196349e-02\n",
      " -1.32236006e-02 -5.94484508e-02  2.86704246e-02  2.57284753e-02\n",
      " -8.33779760e-03  8.17371299e-04  5.93050988e-03  3.29110324e-02\n",
      "  4.12751958e-02 -5.77967986e-03 -1.71123818e-02  1.06227593e-02\n",
      " -2.19601765e-02 -4.97206636e-02  2.53766142e-02 -5.60257579e-33\n",
      " -1.35397455e-02 -3.77958938e-02 -2.67922739e-03 -3.69747577e-04\n",
      " -1.98267475e-02  5.47055481e-03  6.02687895e-03  1.93069186e-02\n",
      "  3.87982093e-03  2.97698956e-02 -1.88228711e-02  2.20036530e-03\n",
      "  8.17020331e-03  1.61965173e-02  3.17529403e-02 -6.83416100e-03\n",
      "  2.19252426e-02  4.37778304e-04  2.96858996e-02 -2.62557194e-02\n",
      "  6.49379613e-03  3.56025249e-02  1.58607156e-03 -4.76584062e-02\n",
      " -5.26238605e-02  3.78274508e-02  3.54341976e-02 -3.10347453e-02\n",
      "  7.96406157e-03  5.48469909e-02 -3.56443562e-02  9.10138804e-03\n",
      " -9.45986342e-03 -4.63287421e-02 -1.63906645e-02  6.32452369e-02\n",
      " -1.38588063e-02 -5.95724434e-02 -1.57990865e-02  2.01886650e-02\n",
      " -1.98292620e-02 -3.49211693e-02  2.27937754e-02 -5.91622032e-02\n",
      "  4.18854952e-02  1.20734249e-03  5.19158877e-02 -1.88435595e-02\n",
      " -3.12101562e-02  2.34932508e-02 -7.41030797e-02 -2.76589271e-04\n",
      " -1.51720000e-02  6.11713231e-02  1.25065163e-01 -1.28459111e-02\n",
      " -1.12670911e-02  1.51759514e-03 -8.09153691e-02  1.12688811e-02\n",
      " -1.97573751e-02  2.74267718e-02  9.40993708e-03 -9.58757102e-03\n",
      "  2.54849978e-02  6.81658983e-02 -1.83453150e-02 -1.00963935e-01\n",
      " -9.45245381e-03 -5.27012208e-03  1.98684148e-02  9.80847925e-02\n",
      "  3.15633789e-02  5.30422442e-02  3.75123285e-02 -6.64208010e-02\n",
      " -5.92879839e-02 -1.57074314e-02  1.76609289e-02 -5.81073053e-02\n",
      "  2.23230701e-02  1.29869543e-02 -3.30260657e-02  9.96905612e-04\n",
      " -9.87088215e-03 -3.12956199e-02  2.28525582e-03 -4.91250381e-02\n",
      "  1.47693958e-02 -1.83367059e-02 -4.16306145e-02  3.76897044e-02\n",
      "  3.35410275e-02 -7.97111616e-02  4.01299484e-02  1.59071777e-02\n",
      "  5.06084645e-03  4.28807996e-02  2.29760315e-02 -4.13350947e-02\n",
      " -3.10503524e-02 -5.26405275e-02 -4.95404415e-02 -2.94256713e-02\n",
      "  5.94924390e-02 -2.59802677e-02  3.02497391e-02  8.80405121e-03\n",
      " -4.84466888e-02 -2.00851634e-02  9.82179400e-03 -7.89194182e-02\n",
      "  4.52875020e-03 -9.34895687e-03  9.23308637e-03 -3.17361765e-02\n",
      "  2.10833028e-02  6.37121592e-03  3.36347707e-02  3.83614302e-02\n",
      " -4.55527343e-02  1.08124956e-03 -9.83325019e-03  7.70196598e-03\n",
      " -2.87617501e-02 -1.74959805e-02 -4.27813968e-03  2.81287022e-02\n",
      "  4.97340076e-02 -7.45570660e-02 -1.07009169e-02 -7.66053749e-03\n",
      "  2.33968834e-07  1.52483825e-02  8.39613453e-02  3.67243066e-02\n",
      " -3.69249023e-02  3.64751332e-02  4.26422395e-02 -4.39832080e-03\n",
      "  1.78133957e-02 -2.67076604e-02 -7.13905133e-03  5.59975170e-02\n",
      "  3.13966796e-02  2.13442324e-03  3.90371494e-02 -8.78527611e-02\n",
      " -2.21660025e-02 -2.47735269e-02 -1.18189417e-02 -7.89709669e-03\n",
      " -2.08857562e-02  4.30556424e-02  1.07643604e-01  4.40618284e-02\n",
      "  1.47962822e-02  2.44862996e-02 -3.86267975e-02  1.80743504e-02\n",
      " -1.47841265e-03  7.74166882e-02 -4.19566259e-02 -3.80529165e-02\n",
      "  3.61257084e-02  1.59034319e-03  1.95324253e-02 -2.00080276e-02\n",
      "  4.22538556e-02  3.06111202e-02 -3.53689375e-03  5.93103468e-03\n",
      " -2.23223288e-02 -2.07131188e-02 -3.62909306e-03  1.74653716e-02\n",
      " -4.08759192e-02  5.91595061e-02 -5.89100234e-02 -3.96754108e-02\n",
      " -3.33529003e-02  1.02162110e-02  6.97294669e-03  7.70389810e-02\n",
      " -1.86912008e-02 -1.82568487e-02 -2.42318846e-02 -3.40699917e-03\n",
      " -3.60555574e-02  4.33389656e-02 -3.48602720e-02  5.27768359e-02\n",
      "  2.89709363e-02 -4.98461947e-02 -1.94748975e-02  1.16397431e-02\n",
      " -3.04614753e-02  8.04637969e-02  6.56247884e-02 -2.84533128e-02\n",
      "  1.81615312e-34 -4.19157790e-03 -2.57882588e-02  5.17320447e-02\n",
      "  4.94420826e-02  1.32476632e-02 -4.21994440e-02 -1.12458514e-02\n",
      " -2.61519235e-02  5.51129878e-02  2.20024865e-02 -2.51170024e-02]\n",
      "\n",
      "Sentence: Learn to use embeddings well and you'll be well on your way to being an AI engineer.\n",
      "Embedding: [-2.20730957e-02  2.08950453e-02 -6.03005625e-02  8.43943562e-03\n",
      "  4.37651016e-02  1.55070676e-02  4.99907397e-02 -3.03232446e-02\n",
      "  4.94784378e-02  2.35512555e-02  3.29350680e-02  1.53877828e-02\n",
      " -6.68355152e-02  1.11002855e-01  6.92677274e-02 -2.31888462e-02\n",
      "  3.79102714e-02 -4.94146161e-03 -1.57800186e-02 -3.45476195e-02\n",
      " -2.65052970e-02 -2.47879550e-02 -1.86141655e-02  3.00361700e-02\n",
      " -2.81186178e-02 -8.75132717e-03 -3.30773299e-03 -2.06116065e-02\n",
      "  1.03315525e-02 -1.51483146e-02 -3.48330811e-02 -2.63248011e-02\n",
      "  2.06908416e-02  3.79108861e-02  1.81912878e-06 -2.44286563e-03\n",
      " -1.80560455e-03  5.61763532e-03 -2.79870350e-02  1.54702729e-02\n",
      "  3.06456592e-02  3.72600555e-02 -1.55611588e-02  2.54414584e-02\n",
      " -6.42072484e-02  3.16353142e-02  6.63442314e-02  3.80970165e-02\n",
      "  5.57844602e-02  5.31659909e-02 -9.69292037e-03 -3.61423865e-02\n",
      "  3.72435153e-02 -4.67826845e-03  5.14575318e-02  1.00058485e-02\n",
      "  4.90287878e-03  1.41562410e-02  4.95099984e-02  3.32952361e-03\n",
      " -3.21100578e-02  4.42388020e-02  3.27416398e-02 -7.90625066e-03\n",
      "  1.07809782e-01  7.32945278e-02  3.36702503e-02 -4.28345688e-02\n",
      "  1.05965966e-02  2.05653943e-02 -2.02670004e-02  1.04963882e-02\n",
      " -1.97615921e-02 -2.89446743e-05 -2.61862427e-02 -1.85173824e-02\n",
      " -3.44269499e-02 -4.08621468e-02  2.32571885e-02  2.14195698e-02\n",
      "  1.31321419e-02 -3.27211507e-02 -1.91425793e-02 -2.86572240e-02\n",
      " -1.16859078e-02  1.21910488e-02  1.05248308e-02 -3.39585207e-02\n",
      "  3.08909011e-03 -4.44888249e-02  2.65105311e-02  1.09536201e-02\n",
      "  2.51450725e-02 -6.48836792e-03  4.54369001e-03 -2.02785060e-02\n",
      " -1.03216199e-02  2.06590258e-02 -1.65313855e-02 -2.45612264e-02\n",
      "  5.47549166e-02  2.68261358e-02  2.95510665e-02  3.86754647e-02\n",
      " -7.76720345e-02  3.80055495e-02 -2.98364889e-02  7.96885863e-02\n",
      " -3.00943330e-02  7.57846888e-03 -6.89826384e-02 -2.92667076e-02\n",
      " -2.35579740e-02  3.48198228e-02  2.52938475e-02 -4.53817286e-02\n",
      " -1.57938544e-02  4.39031422e-02 -4.04335856e-02  8.32532533e-03\n",
      " -2.84664799e-02  4.94933650e-02  2.41276696e-02  3.02191991e-02\n",
      " -4.99590375e-02 -5.94532900e-02 -3.70175838e-02  1.30330818e-02\n",
      " -3.36468481e-02  3.45589444e-02 -1.44523345e-02  2.57639978e-02\n",
      "  4.61183582e-03  2.21551806e-02 -4.93459217e-03  9.66004804e-02\n",
      " -2.72454298e-03  5.65365714e-04 -3.24247815e-02  1.31681915e-02\n",
      "  4.41607535e-02 -7.03049125e-03  6.84261173e-02 -2.28166282e-02\n",
      " -2.81030685e-03 -4.23883013e-02 -1.33632096e-02 -5.96738644e-02\n",
      " -6.96122879e-03 -2.31901053e-02 -3.78850885e-02  9.80186462e-02\n",
      " -2.21729018e-02 -2.30062678e-02  3.22815068e-02  8.21803417e-03\n",
      " -7.04123173e-03  4.84079123e-02  4.23291400e-02 -2.59715668e-03\n",
      "  1.20495955e-04  1.67414173e-02  2.91197971e-02 -1.28740594e-02\n",
      " -2.41078231e-02 -3.29319686e-02 -3.50290001e-03 -3.19321938e-02\n",
      " -2.64171939e-02  2.30404511e-02  1.11636734e-02 -9.96001158e-03\n",
      " -1.75900944e-02 -2.00274703e-03  1.21595152e-02  4.67823297e-02\n",
      "  5.20882122e-02  7.21171722e-02  1.94978621e-02  1.15072466e-02\n",
      "  5.94164524e-03 -1.47833442e-02 -2.87724510e-02  6.72666281e-02\n",
      " -1.68758556e-02  5.25875436e-03 -3.39737386e-02  5.24596050e-02\n",
      " -2.59793084e-02 -4.41379957e-02  1.47451193e-03 -1.06599256e-02\n",
      " -1.51859401e-02 -1.55874563e-03  1.81505270e-02 -4.85411361e-02\n",
      "  3.67910857e-03 -6.59313053e-02 -1.49418470e-02 -3.23529206e-02\n",
      " -2.79949661e-02  1.71856880e-02 -7.87091628e-03  4.65692356e-02\n",
      "  1.47123272e-02 -7.40439147e-02 -6.52104095e-02 -5.22735268e-02\n",
      " -1.82343014e-02  5.20858914e-02  3.06304842e-02 -2.36037113e-02\n",
      "  2.42384635e-02 -1.83939375e-02 -4.83015087e-03 -2.13386510e-02\n",
      "  1.56583786e-02  9.87340324e-03 -4.25561666e-02  6.00458821e-03\n",
      " -3.14502069e-03  4.51510819e-03 -1.52779999e-03  1.13731809e-02\n",
      " -6.96354136e-02 -3.37257423e-02  1.33406706e-02  4.87290276e-03\n",
      " -7.81493168e-03  4.78049628e-02 -1.59711763e-02  3.14606242e-02\n",
      "  5.15920781e-02 -4.05122563e-02 -5.06461114e-02  9.99933947e-03\n",
      " -2.00729482e-02  4.21552695e-02  3.03182565e-02 -1.00431278e-01\n",
      " -4.12019901e-02  3.43990214e-02  3.29208858e-02  1.07411505e-03\n",
      "  3.70962061e-02 -6.94236904e-02  6.52393624e-02  8.31664540e-03\n",
      "  1.68036167e-02 -2.60705817e-02  8.14494304e-03 -1.48009462e-02\n",
      " -2.65671276e-02  3.29321399e-02 -7.37513136e-03  7.23977620e-03\n",
      " -2.69329343e-02  1.71754658e-02 -2.28083171e-02 -4.75340988e-03\n",
      "  2.88568791e-02  1.30767366e-04  5.44128492e-02 -1.43378833e-02\n",
      "  1.89891458e-02 -1.32732000e-02  4.01177183e-02 -7.29275420e-02\n",
      " -2.41211001e-02  3.16217020e-02 -1.68014765e-02  8.47543683e-03\n",
      " -5.23940511e-02 -1.43882586e-02 -1.46156335e-02  6.39906665e-03\n",
      "  2.15113442e-02 -5.18959984e-02 -4.30576131e-02  2.34075971e-02\n",
      "  2.30270158e-03 -2.48433780e-02 -4.38243188e-02 -2.16570944e-02\n",
      " -6.91595525e-02  1.76770017e-02  2.12068148e-02 -2.20293552e-02\n",
      " -1.06773665e-02  9.57427267e-03  2.21988801e-02  5.51470928e-02\n",
      "  1.03682857e-02 -8.14825147e-02 -7.94706121e-03 -1.85866281e-02\n",
      "  1.20494328e-02  7.51403719e-02 -1.41215976e-02  8.83924663e-02\n",
      "  3.12628299e-02  8.12264252e-03 -2.29444727e-02  3.96010503e-02\n",
      " -2.00167857e-02  9.16027501e-02 -2.06839181e-02  5.84990755e-02\n",
      " -4.32368107e-02 -4.74751461e-03 -9.51895025e-03  5.42950956e-03\n",
      "  1.19160948e-04  6.15377091e-02 -1.68788224e-03 -4.66321260e-02\n",
      " -2.01405026e-02  1.32406373e-02  9.70683247e-03  2.73847245e-02\n",
      "  3.06639746e-02  6.71579409e-03  8.71220976e-02 -1.97373820e-03\n",
      "  8.18296429e-03  5.44368150e-03 -5.76206110e-02  1.34821106e-02\n",
      "  5.06282737e-03 -2.10568868e-02  1.25937024e-02 -5.49779739e-03\n",
      " -1.44645479e-02 -2.92567331e-02  5.53299151e-02 -2.60099359e-02\n",
      " -2.82452046e-03 -2.30902229e-02  8.89708474e-03 -2.61565316e-02\n",
      "  9.08616930e-04 -6.16204254e-02 -7.56419003e-02 -1.05932318e-02\n",
      " -1.19563583e-02  6.71458989e-02 -1.96234584e-02 -5.00934310e-02\n",
      " -3.91228721e-02 -3.07008531e-02  7.18906298e-02  9.29248985e-03\n",
      " -6.34385413e-03  7.86963734e-04 -1.36484150e-02  2.87188552e-02\n",
      "  4.01224494e-02  1.28037632e-02  1.77381169e-02 -4.75976430e-03\n",
      "  5.47173247e-02  1.10807433e-03 -2.25790683e-02 -2.80290050e-03\n",
      " -1.13696091e-01  2.55904626e-02  4.00457910e-04 -4.39810641e-02\n",
      "  1.36319008e-02 -1.54137630e-02 -4.99015078e-02 -2.32889634e-02\n",
      " -1.62988261e-03  3.95835228e-02  1.89040415e-02 -3.02702934e-02\n",
      "  2.71438006e-02  1.05686113e-03 -4.21068706e-02  3.71961519e-02\n",
      "  3.54258418e-02 -6.98274747e-02 -2.20937431e-02 -4.01495844e-02\n",
      " -1.90164540e-02 -2.69835349e-02 -1.51212914e-02  3.33365276e-02\n",
      " -9.74889547e-02  1.73102729e-02  6.21013111e-03 -2.59421929e-03\n",
      " -1.10152952e-01 -6.10186420e-02 -1.36549976e-02 -1.35034844e-02\n",
      " -6.72574118e-02 -4.05122247e-03 -6.64982572e-03  3.86568974e-03\n",
      "  9.43470933e-03 -3.86637002e-02 -1.93593651e-02  1.34933749e-02\n",
      " -4.58106734e-02  6.06737360e-02  6.06379882e-02  4.85596210e-02\n",
      " -4.56089079e-02 -5.71936443e-02 -1.55094964e-02  3.40963341e-02\n",
      "  9.48116591e-04 -9.94347129e-03  2.84657925e-02 -3.29024121e-02\n",
      " -2.83211172e-02  3.19907479e-02  2.61298940e-02 -2.74054687e-02\n",
      " -1.36353029e-02  7.47714657e-03  1.19430281e-01 -4.45807055e-02\n",
      "  1.07672121e-02 -8.69424045e-02 -2.19551306e-02  1.83874872e-02\n",
      " -1.06521687e-02 -1.89243201e-02 -3.06514110e-02 -3.04701887e-02\n",
      " -3.22214998e-02  4.12150845e-02  8.95756856e-03 -2.73179524e-02\n",
      "  9.39993374e-03 -9.57180513e-04 -1.94010325e-02 -4.92622778e-02\n",
      " -9.18887462e-03  4.66894321e-02  5.41893207e-02  2.21609343e-02\n",
      " -2.86351964e-02  5.20295464e-02  2.47589368e-02 -7.14268237e-02\n",
      " -1.26206847e-02  7.35522434e-03  2.13785227e-02  2.93513983e-02\n",
      " -2.57651135e-02  5.20562008e-02 -2.74892170e-02 -3.10242679e-02\n",
      " -9.02880579e-02  6.10371828e-02 -5.22610024e-02  2.13111304e-02\n",
      "  4.41735685e-02  3.23370695e-02  1.75648015e-02 -2.39519831e-02\n",
      " -2.69709546e-02  5.11278436e-02  2.69064624e-02 -4.51932736e-02\n",
      "  2.52652378e-03  2.44934224e-02 -2.89540887e-02  2.79992688e-02\n",
      " -1.36022512e-02 -4.32368331e-02  1.85829792e-02  7.63600547e-05\n",
      "  2.43505579e-03 -3.73319094e-03 -1.72279850e-02  1.01292711e-02\n",
      "  1.98437162e-02 -2.60018315e-02 -3.40175442e-03  1.09126000e-02\n",
      " -4.16363664e-02  3.37032042e-02 -2.81634927e-02  1.79126114e-02\n",
      " -4.53095324e-02 -1.09818801e-02 -2.20827037e-03  1.99102536e-02\n",
      "  3.56372148e-02 -3.11799012e-02  3.78752388e-02 -1.41408900e-02\n",
      " -2.16907598e-02  2.73019578e-02  3.69813503e-03  6.35387599e-02\n",
      "  1.22669069e-02 -6.02270802e-03 -7.60756852e-03 -1.86565071e-02\n",
      " -5.64717175e-03 -2.20046658e-03 -1.31825451e-02  1.67724155e-02\n",
      " -3.77264433e-02  2.97895651e-02 -5.01569398e-02  4.89087924e-02\n",
      " -6.07445017e-02 -8.39419141e-02 -5.09001166e-02  1.81768425e-02\n",
      "  6.66732788e-02 -3.30037554e-03 -2.82402663e-03 -5.35405874e-02\n",
      "  3.90340909e-02  2.19852403e-02  3.13554890e-02 -3.36526856e-02\n",
      "  1.96913704e-02  1.67883243e-02  5.04003130e-02  3.08062439e-03\n",
      " -7.24822457e-04  4.42906879e-02 -4.12960583e-03  4.29328531e-02\n",
      " -6.62552416e-02  1.16060884e-03 -2.81716753e-02  1.56885888e-02\n",
      "  9.78133604e-02  5.53594269e-02 -1.39378663e-02  2.12307107e-02\n",
      " -1.30955363e-02 -6.82027712e-02 -8.09099642e-04  4.99291942e-02\n",
      " -2.69266218e-02 -2.97804140e-02  3.84461991e-02  1.97354667e-02\n",
      "  3.37088332e-02  1.65873878e-02  5.77316666e-03 -3.04897986e-02\n",
      " -1.52511979e-02 -3.56159359e-02 -8.69221706e-03 -5.42296833e-33\n",
      "  3.24373692e-03 -3.46329659e-02  3.58932689e-02  1.83770955e-02\n",
      " -2.17505321e-02 -3.26411687e-02  2.88401078e-03  1.50463739e-02\n",
      " -1.75264641e-03 -1.99418403e-02 -6.10355986e-03  2.23847125e-02\n",
      " -8.78944469e-04  2.48684771e-02  3.39736752e-02  2.75592953e-02\n",
      "  3.37792337e-02  3.98564711e-02  2.55545173e-02  1.83042400e-02\n",
      " -2.92878859e-02  5.18081244e-03  8.37756903e-04 -3.66560258e-02\n",
      " -3.46732624e-02  3.82687077e-02  5.50823612e-03 -4.35187258e-02\n",
      "  2.44077928e-02  3.54167521e-02 -2.13442016e-02  2.86623873e-02\n",
      " -2.65387847e-04  3.73409316e-02 -8.68168194e-03  3.04789864e-03\n",
      " -2.71682218e-02 -3.85088101e-02 -6.12388812e-02 -2.00844067e-03\n",
      " -1.22079989e-02 -8.67197588e-02  3.75362020e-03 -1.77707914e-02\n",
      "  8.32479354e-03 -1.69167984e-02  7.02404156e-02  3.32233906e-02\n",
      "  4.34313193e-02  1.47016868e-02 -1.25546902e-01  1.50866397e-02\n",
      " -5.43164276e-02 -1.79148465e-03  4.99600768e-02 -1.53786289e-02\n",
      "  3.32683511e-02 -3.07708774e-02 -1.83897093e-02  9.45797656e-03\n",
      " -4.60290946e-02 -2.03867583e-03  2.62428839e-02 -5.00789285e-02\n",
      "  2.01835986e-02  6.08982816e-02 -2.01180615e-02 -2.60054320e-02\n",
      "  1.05925603e-02 -3.31153870e-02  1.62595306e-02  7.77862221e-02\n",
      " -1.90728332e-03 -5.62888850e-03  1.43715935e-02 -4.06833366e-02\n",
      " -5.14970794e-02  1.66241502e-04 -3.33057554e-03  1.44689120e-02\n",
      "  4.24916740e-04  3.04453168e-02 -1.83636770e-02  1.51184713e-03\n",
      "  2.99861431e-02 -3.68001908e-02  8.35627876e-03 -3.31025310e-02\n",
      "  2.66911890e-02  5.47830714e-03 -1.80524383e-02  2.42577288e-02\n",
      "  5.72708528e-03 -5.93372397e-02  1.04358457e-01 -9.87924635e-03\n",
      " -1.36105586e-02  5.79998530e-02  2.50108615e-02  2.89337393e-02\n",
      " -3.20521668e-02 -3.40233333e-02 -3.41698900e-02 -2.76981108e-02\n",
      "  6.47003204e-02  1.50797917e-02 -1.61925461e-02  3.03266048e-02\n",
      " -2.67188121e-02 -3.67774293e-02 -2.27845553e-02 -5.36433645e-02\n",
      "  1.90499928e-02 -3.42502929e-02  1.32688414e-02 -5.41319139e-03\n",
      "  7.49741681e-03 -7.37027847e-04 -3.08569390e-02  3.82288359e-02\n",
      " -2.08311453e-02 -3.43155265e-02  5.60240075e-03  1.44999875e-02\n",
      " -3.76364440e-02 -5.11782467e-02 -3.51075567e-02  1.71868391e-02\n",
      "  1.50721762e-02 -9.62026045e-02 -1.53545132e-02  1.58376433e-02\n",
      "  2.42940956e-07 -5.88804670e-03  7.68795535e-02  5.86063527e-02\n",
      "  2.21233014e-02 -2.36690920e-02  5.25274053e-02  1.48661332e-02\n",
      "  7.34176347e-03 -4.98915929e-03  4.37413827e-02 -1.28331706e-02\n",
      "  3.37342359e-02 -1.10814786e-02 -1.33937988e-02 -7.80063942e-02\n",
      " -1.36330780e-02  1.94749143e-02  1.91748934e-03 -3.00251786e-02\n",
      "  1.02715785e-04  9.54533666e-02  1.19653940e-01  3.73371802e-02\n",
      "  4.25127801e-03  2.05129944e-02 -3.85414697e-02 -1.90614574e-02\n",
      "  5.88793121e-02  6.81264624e-02 -3.12595814e-02 -6.50440827e-02\n",
      "  2.48045046e-02  3.90050292e-04  7.54762068e-02 -3.46076265e-02\n",
      "  1.32949362e-02  4.14005592e-02  3.07569150e-02  5.50350081e-03\n",
      " -1.53082295e-03  2.75993422e-02  6.46028342e-03  1.05398018e-02\n",
      " -3.09298765e-02  4.60232385e-02 -3.64921875e-02 -1.39540322e-02\n",
      " -3.53720933e-02  7.97829067e-04  1.40632614e-02  1.80258788e-02\n",
      " -1.43368887e-02  2.19210796e-03 -3.96873504e-02 -1.17282020e-02\n",
      " -4.45220396e-02  8.05772282e-03 -4.04861197e-02  3.56148817e-02\n",
      "  5.12852669e-02 -6.64038733e-02 -5.32594919e-02  8.92901048e-03\n",
      "  1.56424474e-02  1.02110915e-01  8.10773019e-03 -4.03856346e-03\n",
      "  2.02352605e-34 -1.38294147e-02 -1.17623480e-02  1.51006505e-02\n",
      "  8.25896561e-02  2.39228364e-02 -1.10377958e-02  3.65655567e-03\n",
      " -7.44783459e-03  2.94554997e-02  3.52995377e-03 -6.10421635e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Requires !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=device) # GPU will be *much* faster than CPU\n",
    "\n",
    "# Create a list of sentences to turn into numbers\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
    "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
    "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
    "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! That's a lot of numbers.\n",
    "\n",
    "How about we do just once sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yo! How cool are embeddings?\n",
      "Embedding:\n",
      "[-1.97447371e-02 -4.51087672e-03 -4.98482818e-03  6.55444786e-02\n",
      " -9.87671968e-03  2.72835474e-02  3.66426148e-02 -3.30222631e-03\n",
      "  8.50079395e-03  8.24952312e-03 -2.28497069e-02  4.02430184e-02\n",
      " -5.75200431e-02  6.33692816e-02  4.43207808e-02 -4.49507311e-02\n",
      "  1.25284391e-02 -2.52012126e-02 -3.55292000e-02  1.29558947e-02\n",
      "  8.67024343e-03 -1.92917529e-02  3.55632883e-03  1.89505927e-02\n",
      " -1.47128357e-02 -9.39846691e-03  7.64171407e-03  9.62190703e-03\n",
      " -5.98927820e-03 -3.90169770e-02 -5.47824651e-02 -5.67457685e-03\n",
      "  1.11645246e-02  4.08067517e-02  1.76319088e-06  9.15296096e-03\n",
      " -8.77259579e-03  2.39382498e-02 -2.32784376e-02  8.04999471e-02\n",
      "  3.19176950e-02  5.12595847e-03 -1.47708384e-02 -1.62524451e-02\n",
      " -6.03213347e-02 -4.35689725e-02  4.51211818e-02 -1.79053638e-02\n",
      "  2.63366848e-02 -3.47866938e-02 -8.89172871e-03 -5.47675118e-02\n",
      " -1.24373101e-02 -2.38606650e-02  8.33496675e-02  5.71242347e-02\n",
      "  1.13328705e-02 -1.49594918e-02  9.20378566e-02  2.72709057e-02\n",
      " -1.42186023e-02  1.91209074e-02  1.49963284e-02 -3.12198736e-02\n",
      "  8.99579823e-02  4.51188721e-02  2.58020535e-02 -5.51744085e-03\n",
      "  1.15909819e-02  4.72100638e-02 -1.51018659e-02  1.70818362e-02\n",
      " -7.22598424e-03  3.45763117e-02 -8.76468979e-03  5.22016846e-02\n",
      " -6.49008751e-02 -4.31378856e-02  6.36964440e-02  4.02881317e-02\n",
      " -1.99043173e-02  5.39064873e-03  1.28820743e-02 -4.81255278e-02\n",
      "  4.58801389e-02 -2.17094738e-02  1.89203266e-02 -3.46344709e-02\n",
      " -1.66457742e-02  7.65169691e-03 -2.26693247e-02 -1.96454376e-02\n",
      "  1.87632423e-02  1.01383002e-02  6.85413182e-02 -5.39851421e-03\n",
      " -3.38230073e-03  4.08413298e-02  4.98623662e-02 -1.16485842e-02\n",
      "  8.91739056e-02  4.02785726e-02 -3.64716467e-03  4.37758416e-02\n",
      " -2.96079386e-02 -5.53753367e-03 -2.00208947e-02 -2.01983433e-02\n",
      "  4.59848978e-02  2.29337681e-02 -5.37305102e-02 -3.19279172e-02\n",
      "  1.37546693e-03  6.25036508e-02 -2.18308959e-02 -6.43255562e-02\n",
      " -2.24791579e-02  3.31955142e-02 -3.12837251e-02  5.17936200e-02\n",
      " -2.84002926e-02  2.55067647e-02  3.36493254e-02  7.50667453e-02\n",
      " -4.46478510e-03 -4.87705655e-02 -7.35218972e-02 -5.46353087e-02\n",
      "  8.88534263e-03  2.95796879e-02 -9.95699037e-03 -6.32764865e-03\n",
      "  4.46259491e-02 -1.58483963e-02 -1.71330217e-02  3.36602293e-02\n",
      " -1.57672877e-03 -5.45971729e-02  2.91161537e-02 -2.80596316e-02\n",
      "  2.96793431e-02  5.12153655e-02  1.48766320e-02 -4.76489142e-02\n",
      "  1.26052275e-02  1.49845146e-03  1.33206844e-02 -2.82468852e-02\n",
      " -3.29254828e-02 -8.53570085e-03 -5.27607650e-02  7.29350224e-02\n",
      " -6.41821325e-02 -2.51786341e-03 -9.02636070e-03 -1.10471249e-03\n",
      "  1.57514531e-02  4.30823900e-02  1.12269511e-02 -3.54585350e-02\n",
      "  4.95163649e-02  1.21271489e-02  1.66342116e-03 -5.06924931e-03\n",
      " -1.11001870e-02 -8.66917986e-03 -3.26440260e-02 -3.98021825e-02\n",
      " -2.05971301e-02  1.09074237e-02 -6.62529394e-02  3.71706784e-02\n",
      " -3.74916382e-02 -3.24731655e-02  5.85899986e-02  8.48080888e-02\n",
      "  3.92412394e-02  3.15814093e-02  3.78386900e-02 -1.35472454e-02\n",
      "  5.95062636e-02  2.58904900e-02 -1.31900180e-02  6.30590096e-02\n",
      "  3.27136852e-02  6.92140358e-03 -1.42607102e-02  7.76677206e-02\n",
      " -1.16103450e-02 -3.66427563e-02 -2.83837467e-02  2.72280164e-02\n",
      "  2.49365345e-02 -4.22295649e-03 -3.63100879e-02 -2.04887576e-02\n",
      "  3.98861021e-02 -2.64727622e-02  4.41382686e-03 -5.19635156e-02\n",
      "  1.71468873e-05  4.81283925e-02  2.04450376e-02  9.84970629e-02\n",
      "  3.68267931e-02  1.53405089e-02  7.50963460e-04 -3.38638611e-02\n",
      " -2.69872546e-02  4.72445525e-02  4.56702448e-02 -3.49246040e-02\n",
      " -1.18770497e-02  3.45576694e-03 -6.32300787e-03 -4.78412248e-02\n",
      "  1.84098780e-02 -2.23157369e-02 -3.70728150e-02  5.87340072e-02\n",
      "  6.22729678e-03 -1.46716097e-02  7.29223788e-02  2.21958896e-03\n",
      " -6.53119162e-02  3.51679549e-02 -1.54901585e-02  6.01421259e-02\n",
      " -9.41007119e-03  2.81196684e-02 -1.12651512e-02  5.24172909e-04\n",
      "  1.01888604e-01 -5.69957457e-02 -3.52360345e-02 -5.20474790e-03\n",
      " -8.46636295e-03  1.39209125e-02  1.80780515e-02 -1.10493965e-01\n",
      "  5.13117164e-02 -4.36432324e-02  2.84142476e-02  9.55939200e-03\n",
      "  4.28096429e-02 -3.95833291e-02  5.25828861e-02  1.92814711e-02\n",
      "  3.44888004e-03 -1.76870953e-02  3.85699086e-02  6.92509534e-03\n",
      " -3.59440334e-02 -2.63613388e-02 -4.96693421e-03  4.24525589e-02\n",
      " -4.22463790e-02  3.45897046e-03  3.55866812e-02 -1.68202017e-02\n",
      "  3.54331173e-02  4.52796696e-03  6.46285946e-03 -2.17710752e-02\n",
      " -2.50033531e-02  1.41418306e-02  1.51257934e-02 -2.99570151e-02\n",
      " -3.94227467e-02  1.87821817e-02 -1.68783788e-03 -9.83500620e-04\n",
      " -3.26321535e-02  5.06565673e-03 -8.90459586e-03 -1.55095225e-02\n",
      "  1.87758040e-02 -4.52473015e-02 -1.72956903e-02  3.50973345e-02\n",
      "  1.33018224e-02  1.00633120e-02 -4.36593629e-02 -1.68619119e-02\n",
      " -1.91048272e-02  6.35489225e-02  8.08324199e-03 -1.02533204e-02\n",
      " -4.53624642e-03 -4.60835882e-02 -1.64704472e-02 -6.24687830e-03\n",
      "  2.58868616e-02 -6.39064088e-02 -7.82395899e-03 -2.36076172e-02\n",
      "  2.74617691e-02  5.80535531e-02 -3.40748802e-02  6.46012425e-02\n",
      "  2.00063176e-02 -2.14935616e-02  1.69360936e-02 -5.54065872e-03\n",
      " -2.40397062e-02  3.09443902e-02 -2.34443345e-03  3.02589908e-02\n",
      " -4.57217991e-02  2.00641770e-02 -2.57116854e-02 -1.13377755e-03\n",
      " -3.57524902e-02  6.92953393e-02  2.80841487e-03  3.58742103e-02\n",
      " -1.52722839e-02 -3.41523103e-02  1.80922933e-02  1.65400151e-02\n",
      "  1.31705580e-02 -6.36675721e-03  5.49303666e-02  8.47316626e-03\n",
      " -4.26077098e-02  2.17085443e-02 -4.89023812e-02  1.18936070e-04\n",
      "  5.16286381e-02  7.59205373e-04  1.59222856e-02 -1.61300171e-02\n",
      "  1.44981565e-02  2.19509043e-02  3.02651413e-02 -3.44151668e-02\n",
      " -4.80380394e-02 -3.71690914e-02  4.68194596e-02 -3.46219130e-02\n",
      "  4.74836968e-04 -4.34820354e-02 -1.80124994e-02 -6.44845739e-02\n",
      " -2.66967770e-02  3.63660827e-02 -3.76219116e-02 -1.64600946e-02\n",
      "  2.20248979e-02  2.15990847e-04  3.64510268e-02 -2.76135374e-02\n",
      " -5.87059418e-03  6.97318232e-03 -1.25864777e-03  2.12773476e-02\n",
      "  6.21467037e-03 -3.57214026e-02 -5.09367287e-02  2.85553224e-02\n",
      "  6.48821816e-02  3.45731527e-02 -2.57280655e-02  4.52550827e-03\n",
      " -4.63606082e-02  3.32225524e-02  1.69977953e-03 -1.29354959e-02\n",
      " -3.03734466e-02  1.23609519e-02 -3.17966013e-04  1.66232120e-02\n",
      "  1.04892114e-02  1.71540733e-02  1.88860614e-02 -3.62256989e-02\n",
      "  4.65737022e-02  2.17129719e-02  4.97536622e-02  3.03067602e-02\n",
      "  1.59917306e-03 -6.30024523e-02 -6.34591002e-03  1.07298816e-04\n",
      " -5.56746498e-03  2.37264615e-02 -8.38234834e-03  5.38897142e-02\n",
      " -9.08976570e-02 -1.37359817e-02  1.18454294e-02  3.37265967e-03\n",
      " -2.81855203e-02  1.56335987e-03  2.22415179e-02  6.21024519e-02\n",
      " -8.68120939e-02 -4.40634228e-03 -1.63995549e-02  1.69665236e-02\n",
      " -1.34548284e-02  3.00701056e-03 -2.14618146e-02 -2.09503621e-02\n",
      " -1.39878243e-02 -1.23850219e-02  5.39979674e-02  6.03615195e-02\n",
      "  2.52982434e-02 -1.29661411e-01 -1.08081631e-01 -4.15774761e-03\n",
      " -7.20267836e-03  2.75885332e-02  4.87622134e-02 -2.95971390e-02\n",
      " -4.32554558e-02  2.75214799e-02  1.35718593e-02  3.87700237e-02\n",
      "  2.42039952e-02 -2.70842277e-02  8.59166235e-02 -1.98402684e-02\n",
      " -2.26343628e-02 -6.24927692e-02 -1.56844743e-02  4.11566608e-02\n",
      "  1.66952554e-02  7.97291398e-02 -3.24839316e-02  1.46564015e-03\n",
      " -3.27905975e-02  6.44815490e-02  2.09739227e-02 -7.56984800e-02\n",
      " -1.31797243e-03  2.24046269e-03 -6.60838326e-03 -6.84252381e-02\n",
      " -5.36858337e-03  6.55135512e-02  5.45569556e-03  1.58993043e-02\n",
      " -2.18052007e-02  2.16419296e-03  4.72959224e-03 -7.25654811e-02\n",
      " -1.59350857e-02 -1.05622699e-02  2.70786528e-02  1.93771033e-03\n",
      " -4.45122458e-02  2.89783217e-02  2.43083276e-02 -1.73885711e-02\n",
      " -3.80669311e-02 -3.06799207e-02 -3.24778296e-02 -4.33341716e-04\n",
      "  2.55846214e-02  2.70478521e-02 -1.72465370e-04 -4.93692467e-04\n",
      " -7.12094083e-02  5.69768362e-02  6.61400855e-02 -3.87267917e-02\n",
      " -1.30683696e-02  1.00663295e-02 -2.17740219e-02  1.92212686e-02\n",
      "  7.66692730e-03 -3.86652909e-02 -1.66109335e-02 -3.41468304e-02\n",
      " -1.04186023e-02  1.75906252e-02 -1.23776235e-02 -1.68433897e-02\n",
      " -2.40113195e-02  4.70196595e-03  4.88457037e-03  4.73663509e-02\n",
      "  4.34111804e-02 -8.08339473e-03 -2.48272289e-02 -1.93977933e-02\n",
      " -3.16525698e-02 -1.56418402e-02 -7.79946195e-03  1.28887808e-02\n",
      "  2.61943564e-02  3.65830143e-03  5.79228215e-02  5.43151759e-02\n",
      " -5.05587049e-02  1.78921968e-03 -2.45471001e-02 -2.47596391e-02\n",
      "  3.60353058e-03  1.94152705e-02 -4.23823074e-02 -1.86907090e-02\n",
      "  2.32946295e-02 -3.17982920e-02 -2.60645561e-02 -5.40359505e-03\n",
      " -3.82070318e-02  2.21719667e-02  1.33360727e-02  5.58054373e-02\n",
      " -3.57717015e-02 -3.54791656e-02  1.27723310e-02  6.80177808e-02\n",
      "  5.37152179e-02  2.54151486e-02 -1.16638895e-02 -1.07512372e-02\n",
      " -9.74427536e-03  7.20506068e-03  9.21904854e-03 -4.73685116e-02\n",
      " -3.89395864e-03  3.11453305e-02  3.62331942e-02 -1.65903009e-02\n",
      " -3.63394320e-02  1.95635092e-02 -2.15059351e-02 -7.04772770e-03\n",
      "  9.13181063e-03 -4.05358411e-02 -3.67075503e-02  1.16995983e-01\n",
      "  1.17913827e-01  8.00503418e-02 -1.61983352e-02 -2.00732797e-02\n",
      " -5.54061346e-02 -7.22410828e-02  2.14557499e-02 -4.46436199e-04\n",
      " -1.42903151e-02  8.35544523e-03  3.34207192e-02  1.42891435e-02\n",
      "  4.62512709e-02 -3.53420228e-02  1.68673676e-02 -2.99744098e-03\n",
      " -5.44997305e-02 -4.80719805e-02  9.47536435e-04 -6.29721654e-33\n",
      " -2.30286289e-02 -2.51127500e-02 -5.35219349e-02 -2.09470000e-02\n",
      " -6.79715816e-03 -4.64015789e-02 -4.49629873e-03  1.65114831e-02\n",
      " -1.12677682e-02  1.33013660e-02 -1.72552820e-02 -1.96653139e-02\n",
      "  5.53234667e-03  1.02775842e-02  9.47326305e-04 -2.24022716e-02\n",
      "  5.30364849e-02  7.77773699e-03 -9.48471576e-03  2.25515813e-02\n",
      " -4.34491271e-03  2.25208774e-02  1.98086388e-02 -7.57428557e-02\n",
      " -4.36679786e-03  2.50829961e-02  2.59393286e-02 -3.07076536e-02\n",
      "  7.04764798e-02  8.63500908e-02 -7.75880665e-02  1.59991570e-02\n",
      " -5.04692271e-02  4.88355197e-02  3.74994474e-03 -6.12941396e-04\n",
      " -3.87277715e-02 -2.32235696e-02 -3.63983139e-02 -5.07026538e-03\n",
      "  1.10517787e-02 -3.26515548e-02  3.68386917e-02 -4.54949588e-02\n",
      " -1.18534302e-03  1.92691863e-03  2.18783822e-02  2.71093175e-02\n",
      " -4.06263657e-02  6.99159727e-02 -7.33281597e-02 -8.15292168e-03\n",
      " -1.42555786e-02  3.78028443e-03  1.20974280e-01 -6.68213218e-02\n",
      "  3.05051934e-02  1.24480715e-02 -4.59294096e-02  1.03873126e-02\n",
      " -3.97978500e-02 -1.33042308e-02 -1.59402359e-02 -4.29347157e-02\n",
      "  4.05275337e-02  7.07074180e-02 -4.50929366e-02 -3.62473577e-02\n",
      " -1.87588912e-02  1.60928164e-02  2.12657284e-02  6.70026168e-02\n",
      "  3.25864404e-02  1.51125854e-02  3.20371874e-02 -1.35436114e-02\n",
      "  2.31780615e-02 -1.13125397e-02  1.23796295e-02 -3.73517238e-02\n",
      "  1.55545736e-03  2.15824302e-02 -3.49442028e-02 -2.97690220e-02\n",
      "  2.32397728e-02 -1.25702638e-02 -1.09432824e-02 -8.87969360e-02\n",
      " -2.20183618e-02 -1.18422993e-02 -5.71083724e-02  3.91809419e-02\n",
      " -1.98827349e-02 -5.59270605e-02  7.60346837e-03  2.23641973e-02\n",
      " -1.86267011e-02  3.79805528e-02 -8.79608502e-04 -5.26199527e-02\n",
      "  2.05063354e-03  1.72815379e-02 -4.84029129e-02 -1.87740922e-02\n",
      "  8.28984383e-08  2.06594802e-02  3.03574335e-02  5.71858278e-03\n",
      " -5.33938445e-02 -2.46520769e-02  1.80341639e-02 -3.39978114e-02\n",
      "  3.46321431e-05 -6.40035272e-02  2.50049457e-02 -2.04111990e-02\n",
      " -2.72042933e-03 -3.55961099e-02  2.71922909e-02  6.48940578e-02\n",
      "  9.83469421e-04 -4.38491069e-02 -4.45296802e-02 -7.44882086e-03\n",
      "  1.15205375e-02 -2.91254767e-03 -2.15495322e-02  2.84249149e-03\n",
      "  4.29399237e-02 -6.09040298e-02 -7.86323566e-03 -3.90124274e-03\n",
      "  2.47718305e-07  7.75847293e-04  7.47736618e-02  1.99314533e-03\n",
      " -6.07220735e-03  3.69210690e-02  2.78421137e-02 -5.64900376e-02\n",
      "  1.61058959e-02 -9.50817857e-03 -2.60854512e-03 -2.45737974e-02\n",
      "  1.91390831e-02  5.08195981e-02  2.61258800e-02 -1.03838056e-01\n",
      " -3.05815786e-02 -3.53344306e-02 -4.07036841e-02 -2.19842121e-02\n",
      " -2.24092044e-02  5.05567938e-02  7.22607374e-02  5.54789826e-02\n",
      "  4.89434414e-02  3.37950746e-03 -6.84760362e-02  7.10319355e-03\n",
      "  3.15666921e-03  4.78091352e-02 -7.19796121e-02 -3.30301784e-02\n",
      "  3.19159292e-02  1.76428538e-03 -4.62790579e-02 -1.96379777e-02\n",
      "  1.67493820e-02  4.73603792e-02 -2.09441446e-02  7.10238237e-03\n",
      "  4.53146026e-02 -4.76523302e-02 -4.74880971e-02  1.00799389e-02\n",
      " -8.39594901e-02  3.36929895e-02 -3.72189395e-02  1.19432276e-02\n",
      " -3.16896513e-02 -1.29724876e-03 -1.55541366e-02  1.81728341e-02\n",
      " -1.49368811e-02 -1.70671511e-02 -4.19716649e-02  3.94656742e-03\n",
      " -2.24301685e-02  2.07292121e-02 -4.61415388e-02  8.50213040e-03\n",
      " -2.56865025e-02 -1.65337995e-02 -1.51847182e-02 -1.00041861e-02\n",
      "  2.19642427e-02  2.61104070e-02  7.31359422e-02 -1.83709431e-02\n",
      "  1.93979435e-34 -7.27935741e-03  5.96491341e-03  4.44311090e-02\n",
      "  4.14822660e-02  1.12917349e-02 -1.93217825e-02  4.41878401e-02\n",
      " -8.93786643e-03  3.61120030e-02 -5.52126467e-02 -2.89572421e-02]\n",
      "Embedding size: (768,)\n"
     ]
    }
   ],
   "source": [
    "single_sentence = \"Yo! How cool are embeddings?\"\n",
    "single_embedding = embedding_model.encode(single_sentence)\n",
    "print(f\"Sentence: {single_sentence}\")\n",
    "print(f\"Embedding:\\n{single_embedding}\")\n",
    "print(f\"Embedding size: {single_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We've now got a way to numerically represent each of our chunks.\n",
    "\n",
    "Our embedding has a shape of `(768,)` meaning it's a vector of 768 numbers which represent our text in high-dimensional space, too many for a human to comprehend but machines love high-dimensional space.\n",
    "\n",
    "> **Note:** No matter the size of the text input to our `all-mpnet-base-v2` model, it will be turned into an embedding size of `(768,)`. This value is fixed. So whether a sentence is 1 token long or 1000 tokens long, it will be truncated/padded with zeros to size 384 and then turned into an embedding vector of size `(768,)`. Of course, other embedding models may have different input/output shapes.\n",
    "\n",
    "How about we add an embedding field to each of our chunk items?\n",
    "\n",
    "Let's start by trying to create embeddings on the CPU, we'll time it with the `%%time` magic to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52c6a9fa9c048e7a0c3ab5691b4e13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 10s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define minimum token length\n",
    "min_token_length = 30\n",
    "\n",
    "# Filter for chunks over minimum token length\n",
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "\n",
    "# Use GPU (CUDA) for faster embedding generation\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "embedding_model.to(device)\n",
    "\n",
    "# Create embeddings one by one on GPU\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok not too bad... but this would take a *really* long time if we had a larger dataset.\n",
    "\n",
    "Now let's see how long it takes to create the embeddings with a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using device for batch processing: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a8e8a681864f85880da52dfd6b6c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 10s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use GPU (CUDA) for ultra-fast embedding generation\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üöÄ Using device for batch processing: {device}\")\n",
    "embedding_model.to(device)\n",
    "\n",
    "# Create embeddings in batch mode on GPU\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! Looks like the embeddings get created much faster (~10x faster on my machine) on the GPU!\n",
    "\n",
    "You'll likely notice this trend with many of your deep learning workflows. If you have access to a GPU, especially a NVIDIA GPU, you should use one if you can.\n",
    "\n",
    "But what if I told you we could go faster again?\n",
    "\n",
    "You see many modern models can handle batched predictions.\n",
    "\n",
    "This means computing on multiple samples at once.\n",
    "\n",
    "Those are the types of operations where a GPU flourishes!\n",
    "\n",
    "We can perform batched operations by turning our target text samples into a single list and then passing that list to our embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn text chunks into a single list\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 56.3 s\n",
      "Wall time: 55.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0150, -0.0734, -0.0258,  ...,  0.0078,  0.0746, -0.0331],\n",
       "        [ 0.0519, -0.0117, -0.0101,  ...,  0.0246,  0.0807, -0.0401],\n",
       "        [-0.0173, -0.0161, -0.0399,  ...,  0.0185, -0.0056, -0.0263],\n",
       "        ...,\n",
       "        [-0.0119,  0.0339, -0.0302,  ..., -0.0410,  0.0659, -0.0230],\n",
       "        [ 0.0352, -0.0473, -0.0407,  ..., -0.0297,  0.0201,  0.0024],\n",
       "        [ 0.0559, -0.0232, -0.0363,  ..., -0.0474,  0.0339, -0.0148]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Embed all texts in batches\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
    "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
    "\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's what I'm talking about!\n",
    "\n",
    "A ~4x improvement (on my GPU) in speed thanks to batched operations.\n",
    "\n",
    "So the tip here is to use a GPU when you can and use batched operations if you can too.\n",
    "\n",
    "Now let's save our chunks and their embeddings so we could import them later if we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save embeddings to file\n",
    "\n",
    "Since creating embeddings can be a timely process (not so much for our case but it can be for more larger datasets), let's turn our `pages_and_chunks_over_min_token_len` list of dictionaries into a DataFrame and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can make sure it imports nicely by loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>About the Author Best-selling author Herbert S...</td>\n",
       "      <td>924</td>\n",
       "      <td>141</td>\n",
       "      <td>231.00</td>\n",
       "      <td>[ 1.49854198e-02 -7.34082162e-02 -2.57711969e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danny Coward has worked on all editions of the...</td>\n",
       "      <td>783</td>\n",
       "      <td>130</td>\n",
       "      <td>195.75</td>\n",
       "      <td>[ 5.19161113e-02 -1.17350183e-02 -1.01365112e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Complete Reference Herbert Schildt New Yor...</td>\n",
       "      <td>174</td>\n",
       "      <td>25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>[-1.72504783e-02 -1.60598643e-02 -3.99433635e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Copyright ¬© 2014 by McGraw-Hill Education (Pub...</td>\n",
       "      <td>1343</td>\n",
       "      <td>206</td>\n",
       "      <td>335.75</td>\n",
       "      <td>[ 2.77911909e-02 -5.24213836e-02 -5.01611009e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Information has been obtained by McGraw-Hill E...</td>\n",
       "      <td>1555</td>\n",
       "      <td>245</td>\n",
       "      <td>388.75</td>\n",
       "      <td>[ 3.23652029e-02 -4.66272198e-02 -3.77070270e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            2  About the Author Best-selling author Herbert S...   \n",
       "1            2  Danny Coward has worked on all editions of the...   \n",
       "2            3  The Complete Reference Herbert Schildt New Yor...   \n",
       "3            4  Copyright ¬© 2014 by McGraw-Hill Education (Pub...   \n",
       "4            4  Information has been obtained by McGraw-Hill E...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               924               141             231.00   \n",
       "1               783               130             195.75   \n",
       "2               174                25              43.50   \n",
       "3              1343               206             335.75   \n",
       "4              1555               245             388.75   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 1.49854198e-02 -7.34082162e-02 -2.57711969e-...  \n",
       "1  [ 5.19161113e-02 -1.17350183e-02 -1.01365112e-...  \n",
       "2  [-1.72504783e-02 -1.60598643e-02 -3.99433635e-...  \n",
       "3  [ 2.77911909e-02 -5.24213836e-02 -5.01611009e-...  \n",
       "4  [ 3.23652029e-02 -4.66272198e-02 -3.77070270e-...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and embedding questions\n",
    "\n",
    "> **Which embedding model should I use?**\n",
    "\n",
    "This depends on many factors. My best advice is to experiment, experiment, experiment! \n",
    "\n",
    "If you want the model to run locally, you'll have to make sure it's feasible to run on your own hardware. \n",
    "\n",
    "A good place to see how different models perform on a wide range of embedding tasks is the [Hugging Face Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard).\n",
    "\n",
    "> **What other forms of text chunking/splitting are there?**\n",
    "\n",
    "There are a fair few options here too. We've kept it simple with groups of sentences.\n",
    "\n",
    "For more, [Pinecone has a great guide on different kinds of chunking](https://www.pinecone.io/learn/chunking-strategies/) including for different kinds of data such as markdown and LaTeX.\n",
    "\n",
    "Libraries such as [LangChain also have a good amount of in-built text splitting options](https://python.langchain.com/docs/modules/data_connection/document_transformers/).\n",
    "\n",
    "> **What should I think about when creating my embeddings?**\n",
    "\n",
    "Our model turns text inputs up to 384 tokens long in embedding vectors of size 768.\n",
    "\n",
    "Generally, the larger the vector size, the more information that gets encoded into the embedding (however, this is not always the case, as smaller, better models can outperform larger ones).\n",
    "\n",
    "Though with larger vector sizes comes larger storage and compute requirements.\n",
    "\n",
    "Our model is also relatively small (420MB) in size compared to larger models that are available.\n",
    "\n",
    "Larger models may result in better performance but will also require more compute.\n",
    "\n",
    "So some things to think about:\n",
    "* Size of input - If you need to embed longer sequences, choose a model with a larger input capacity.\n",
    "* Size of embedding vector - Larger is generally a better representation but requires more compute/storage.\n",
    "* Size of model - Larger models generally result in better embeddings but require more compute power/time to run.\n",
    "* Open or closed - Open models allow you to run them on your own hardware whereas closed models can be easier to setup but require an API call to get embeddings.\n",
    "\n",
    "> **Where should I store my embeddings?**\n",
    "\n",
    "If you've got a relatively small dataset, for example, under 100,000 examples (this number is rough and only based on first hand experience), `np.array` or `torch.tensor` can work just fine as your dataset.\n",
    "\n",
    "But if you've got a production system and want to work with 100,000+ embeddings, you may want to look into a [vector database]( https://en.wikipedia.org/wiki/Vector_database) (these have become very popular lately and there are many offerings).\n",
    "\n",
    "### Document Ingestion and Embedding Creation Extensions\n",
    "\n",
    "One major extension to the workflow above would to functionize it.\n",
    "\n",
    "Or turn it into a script.\n",
    "\n",
    "As in, take all the functionality we've created and package it into a single process (e.g. go from document -> embeddings file).\n",
    "\n",
    "So you could input a document on one end and have embeddings come out the other end. The hardest part of this is knowing what kind of preprocessing your text may need before it's turned into embeddings. Cleaner text generally means better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG - Search and Answer\n",
    "\n",
    "We discussed RAG briefly in the beginning but let's quickly recap.\n",
    "\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "\n",
    "Which is another way of saying \"given a query, search for relevant resources and answer based on those resources\".\n",
    "\n",
    "Let's breakdown each step:\n",
    "* **Retrieval** - Get relevant resources given a query. For example, if the query is \"what are the macronutrients?\" the ideal results will contain information about protein, carbohydrates and fats (and possibly alcohol) rather than information about which tractors are the best for farming (though that is also cool information).\n",
    "* **Augmentation** - LLMs are capable of generating text given a prompt. However, this generated text is designed to *look* right. And it often has some correct information, however, they are prone to hallucination (generating a result that *looks* like legit text but is factually wrong). In augmentation, we pass relevant information into the prompt and get an LLM to use that relevant information as the basis of its generation.\n",
    "* **Generation** - This is where the LLM will generate a response that has been flavoured/augmented with the retrieved resources. In turn, this not only gives us a potentially more correct answer, it also gives us resources to investigate more (since we know which resources went into the prompt).\n",
    "\n",
    "The whole idea of RAG is to get an LLM to be more factually correct based on your own input as well as have a reference to where the generated output may have come from.\n",
    "\n",
    "This is an incredibly helpful tool.\n",
    "\n",
    "Let's say you had 1000s of customer support documents.\n",
    "\n",
    "You could use RAG to generate direct answers to questions with links to relevant documentation.\n",
    "\n",
    "Or you were an insurance company with large chains of claims emails.\n",
    "\n",
    "You could use RAG to answer questions about the emails with sources.\n",
    "\n",
    "One helpful analogy is to think of LLMs as calculators for words.\n",
    "\n",
    "With good inputs, the LLM can sort them into helpful outputs.\n",
    "\n",
    "How? \n",
    "\n",
    "It starts with better search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search\n",
    "\n",
    "Similarity search or semantic search or vector search is the idea of searching on *vibe*.\n",
    "\n",
    "If this sounds like woo, woo. It's not.\n",
    "\n",
    "Perhaps searching via *meaning* is a better analogy.\n",
    "\n",
    "With keyword search, you are trying to match the string \"apple\" with the string \"apple\".\n",
    "\n",
    "Whereas with similarity/semantic search, you may want to search \"macronutrients functions\".\n",
    "\n",
    "And get back results that don't necessarily contain the words \"macronutrients functions\" but get back pieces of text that match that meaning.\n",
    "\n",
    "> **Example:** Using similarity search on our textbook data with the query \"macronutrients function\" returns a paragraph that starts with: \n",
    ">\n",
    ">*There are three classes of macronutrients: carbohydrates, lipids, and proteins. These can be metabolically processed into cellular energy. The energy from macronutrients comes from their chemical bonds. This chemical energy is converted into cellular energy that is then utilized to perform work, allowing our bodies to conduct their basic functions.*\n",
    "> \n",
    "> as the first result. How cool!\n",
    "\n",
    "If you've ever used Google, you know this kind of workflow.\n",
    "\n",
    "But now we'd like to perform that across our own data.\n",
    "\n",
    "Let's import our embeddings we created earlier (tk -link to embedding file) and prepare them for use by turning them into a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2677, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>About the Author Best-selling author Herbert S...</td>\n",
       "      <td>924</td>\n",
       "      <td>141</td>\n",
       "      <td>231.00</td>\n",
       "      <td>[0.0149854198, -0.0734082162, -0.0257711969, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danny Coward has worked on all editions of the...</td>\n",
       "      <td>783</td>\n",
       "      <td>130</td>\n",
       "      <td>195.75</td>\n",
       "      <td>[0.0519161113, -0.0117350183, -0.0101365112, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Complete Reference Herbert Schildt New Yor...</td>\n",
       "      <td>174</td>\n",
       "      <td>25</td>\n",
       "      <td>43.50</td>\n",
       "      <td>[-0.0172504783, -0.0160598643, -0.0399433635, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Copyright ¬© 2014 by McGraw-Hill Education (Pub...</td>\n",
       "      <td>1343</td>\n",
       "      <td>206</td>\n",
       "      <td>335.75</td>\n",
       "      <td>[0.0277911909, -0.0524213836, -0.0501611009, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Information has been obtained by McGraw-Hill E...</td>\n",
       "      <td>1555</td>\n",
       "      <td>245</td>\n",
       "      <td>388.75</td>\n",
       "      <td>[0.0323652029, -0.0466272198, -0.037707027, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            2  About the Author Best-selling author Herbert S...   \n",
       "1            2  Danny Coward has worked on all editions of the...   \n",
       "2            3  The Complete Reference Herbert Schildt New Yor...   \n",
       "3            4  Copyright ¬© 2014 by McGraw-Hill Education (Pub...   \n",
       "4            4  Information has been obtained by McGraw-Hill E...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               924               141             231.00   \n",
       "1               783               130             195.75   \n",
       "2               174                25              43.50   \n",
       "3              1343               206             335.75   \n",
       "4              1555               245             388.75   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0149854198, -0.0734082162, -0.0257711969, 0...  \n",
       "1  [0.0519161113, -0.0117350183, -0.0101365112, -...  \n",
       "2  [-0.0172504783, -0.0160598643, -0.0399433635, ...  \n",
       "3  [0.0277911909, -0.0524213836, -0.0501611009, -...  \n",
       "4  [0.0323652029, -0.0466272198, -0.037707027, -0...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4985e-02, -7.3408e-02, -2.5771e-02,  7.4829e-03, -2.4946e-02,\n",
       "        -3.8898e-02, -2.0713e-03, -6.0827e-04, -1.2047e-03, -5.3840e-03,\n",
       "         5.4796e-02,  4.3897e-02, -4.2186e-03,  2.2586e-02, -2.7512e-02,\n",
       "        -8.4513e-02,  7.7895e-02, -6.4456e-03, -6.0749e-02,  1.2598e-02,\n",
       "        -9.9165e-03,  4.3364e-03, -9.4753e-03,  5.8562e-02, -2.5537e-03,\n",
       "        -6.4259e-02, -1.1210e-02,  1.3678e-02,  7.3151e-03, -2.5102e-03,\n",
       "        -1.4733e-02,  2.0469e-02,  4.4513e-03,  2.8734e-02,  2.7498e-06,\n",
       "        -2.2993e-02, -2.7370e-03,  3.9228e-02,  3.1972e-02,  1.2928e-01,\n",
       "         3.0824e-02,  5.7807e-02, -1.5843e-02,  9.3927e-04,  4.7829e-03,\n",
       "         1.1563e-02,  5.0151e-02, -2.1391e-02,  6.3028e-02,  3.1962e-03,\n",
       "         2.3737e-02,  1.6948e-02, -7.6335e-03,  4.2421e-02, -2.6216e-02,\n",
       "        -7.4337e-03,  4.6518e-04,  3.8885e-02,  7.9682e-02,  1.6107e-02,\n",
       "        -2.5198e-02, -3.4476e-02, -5.7022e-03, -2.0304e-02,  9.3294e-02,\n",
       "        -8.9609e-03, -4.2601e-02,  1.6416e-02,  2.3120e-02, -3.7196e-03,\n",
       "         3.9295e-02, -5.2443e-02,  1.2975e-02,  4.1945e-02, -4.5065e-02,\n",
       "         2.1703e-02, -7.6827e-03, -2.4545e-02, -7.0392e-03, -3.6317e-02,\n",
       "        -9.7567e-03, -4.5590e-02, -4.7661e-02, -4.0158e-02,  1.9969e-02,\n",
       "         9.3664e-02, -1.3797e-02, -1.6183e-03, -5.5062e-02,  2.8673e-03,\n",
       "         4.0531e-02, -7.5142e-02,  2.0323e-02,  2.7886e-02,  3.9181e-02,\n",
       "        -1.9629e-02, -8.3530e-03, -4.0192e-02,  1.7357e-02, -6.3204e-02,\n",
       "        -2.3054e-02,  1.0173e-02,  4.6683e-02, -1.1099e-02,  3.0194e-02,\n",
       "         3.2005e-03, -2.5504e-02, -3.4756e-03, -7.7623e-03,  9.2531e-02,\n",
       "        -1.0836e-02, -1.6131e-02, -3.9816e-02,  5.2000e-02,  5.0415e-02,\n",
       "         1.5448e-02, -7.3552e-02,  5.0997e-02,  1.1489e-02,  2.5372e-02,\n",
       "        -3.3700e-02, -1.3755e-02,  1.9766e-02,  3.2775e-02,  2.0974e-02,\n",
       "        -2.5777e-02, -3.4260e-02, -4.3434e-02, -1.3392e-02, -2.3197e-02,\n",
       "         8.5713e-03, -8.1616e-04, -2.8701e-02,  1.5264e-02, -3.5541e-02,\n",
       "         7.7594e-02, -2.8726e-02,  4.0670e-02, -3.3647e-03, -2.2668e-02,\n",
       "         2.3977e-02,  1.0853e-02, -1.9500e-03, -8.4190e-02, -1.4214e-02,\n",
       "        -2.5252e-03,  5.5188e-02,  4.7752e-02, -1.7672e-02,  9.1175e-03,\n",
       "         2.0816e-02,  3.5589e-02,  2.1569e-03,  3.7853e-02,  1.2730e-02,\n",
       "         2.2211e-02,  2.1951e-02,  1.5222e-02, -4.6251e-02, -6.3228e-03,\n",
       "         2.1061e-02, -6.5543e-02,  8.1121e-02, -2.0205e-02, -6.8944e-02,\n",
       "        -4.3700e-02,  2.6230e-02,  2.1213e-02,  1.5704e-02, -2.9467e-02,\n",
       "        -7.1629e-02,  2.5854e-02, -4.2238e-02,  5.9278e-02, -2.9425e-02,\n",
       "         2.5322e-02, -1.2494e-02,  5.7833e-02,  4.4588e-02,  6.6135e-02,\n",
       "         5.0262e-02, -3.8474e-03, -1.9772e-02,  8.0845e-02, -3.5690e-02,\n",
       "        -1.5678e-02, -9.9514e-02,  3.8355e-02,  1.8783e-02, -8.1493e-04,\n",
       "        -2.4545e-02,  2.1562e-02, -3.3808e-02, -2.6790e-02,  3.1693e-02,\n",
       "        -3.6985e-03,  1.7172e-02,  9.4332e-03,  1.3753e-02, -4.5568e-02,\n",
       "        -5.8627e-02, -1.4296e-02,  9.2354e-03,  2.5344e-02,  1.3669e-03,\n",
       "        -5.0745e-02,  2.0553e-02, -9.0982e-03,  1.3613e-02, -4.1293e-02,\n",
       "         9.1596e-02, -1.6594e-03, -2.1565e-02, -4.1792e-03,  2.9967e-03,\n",
       "         3.1199e-02,  8.0419e-03,  1.1155e-01, -1.4788e-02,  1.4957e-03,\n",
       "        -2.1801e-04,  2.2424e-02, -1.7184e-02, -1.2740e-02,  4.4423e-02,\n",
       "        -6.2143e-02, -2.1673e-02,  1.9353e-02, -1.8082e-02,  1.9022e-03,\n",
       "        -7.6537e-02,  1.0852e-02,  4.2217e-02,  4.6131e-02,  1.3497e-02,\n",
       "        -7.1382e-03,  1.3555e-02,  6.2568e-02,  5.4176e-03, -6.8190e-02,\n",
       "         2.0961e-02,  1.3679e-02, -1.1354e-03, -2.1070e-02,  7.1246e-02,\n",
       "         3.7862e-02,  3.4816e-02, -1.8352e-02,  4.7257e-02, -7.2232e-02,\n",
       "        -4.3072e-02,  1.1186e-02, -8.7117e-03,  4.5308e-02,  1.1853e-02,\n",
       "         1.1891e-03, -3.7209e-02,  3.7689e-02, -4.9419e-02, -5.9400e-02,\n",
       "         9.1308e-02, -5.4804e-02,  3.3071e-02,  7.5228e-03,  6.4609e-02,\n",
       "         3.0831e-02,  1.4744e-03, -5.4120e-02, -4.5821e-02, -1.3568e-02,\n",
       "         2.5402e-03, -5.1065e-03, -1.9421e-02,  1.1897e-02, -1.7349e-03,\n",
       "         4.1045e-02,  5.4247e-02, -3.5856e-02, -4.8967e-02, -1.7060e-02,\n",
       "        -3.2093e-02, -5.7484e-02,  8.5954e-03, -2.5716e-02, -2.7992e-02,\n",
       "         6.3336e-03,  4.1726e-03, -1.0923e-01, -8.5824e-02,  5.4936e-02,\n",
       "        -2.8341e-02, -7.6288e-03, -1.1668e-02, -2.1637e-02,  9.0116e-03,\n",
       "        -3.1153e-02, -1.8714e-02,  6.0820e-02, -6.1413e-02,  5.5103e-02,\n",
       "         2.0177e-02, -8.7921e-03, -2.4699e-02,  3.6816e-04,  3.1277e-02,\n",
       "        -3.1723e-02,  7.4169e-02, -4.2509e-03,  2.4020e-02,  1.2014e-02,\n",
       "        -2.7621e-02, -2.9954e-02,  5.4591e-03, -2.5015e-02,  1.3317e-02,\n",
       "         5.2680e-02, -2.1435e-02, -2.6514e-02, -3.8782e-02,  1.2926e-02,\n",
       "        -3.3531e-02, -3.9985e-02,  5.4160e-02, -2.9958e-02, -1.4021e-02,\n",
       "        -3.6253e-02, -2.8208e-02, -3.4582e-02,  2.6389e-03, -6.3471e-03,\n",
       "         1.3859e-02,  3.2661e-02, -5.6920e-02,  5.1498e-02,  5.7810e-02,\n",
       "         3.7641e-02, -1.9382e-02, -5.0233e-03, -4.7304e-03, -1.4885e-02,\n",
       "        -1.6719e-02, -3.1359e-02, -1.4328e-02,  5.4426e-02,  6.4599e-03,\n",
       "        -3.7412e-02,  1.2568e-02, -6.3482e-03,  1.9141e-02, -2.8845e-02,\n",
       "         6.4904e-02, -2.5533e-03,  9.4615e-04, -1.2955e-02,  1.6163e-03,\n",
       "        -7.7335e-02, -5.2017e-02, -2.4311e-02, -5.3867e-02,  7.9421e-03,\n",
       "         3.5647e-02,  1.6827e-02,  2.5722e-02, -2.7218e-02, -3.9750e-02,\n",
       "        -8.7735e-03,  8.3902e-02, -4.4082e-02, -5.1228e-02,  1.4726e-02,\n",
       "         5.9905e-02, -4.7241e-02, -2.9422e-02,  1.9633e-03,  1.9820e-02,\n",
       "        -1.4410e-02,  1.8901e-02, -3.9983e-02,  1.3847e-02,  5.9278e-02,\n",
       "         5.6255e-02, -5.6216e-02,  3.7381e-02, -2.3058e-02,  2.5471e-02,\n",
       "        -2.6737e-02,  1.9859e-02,  7.5692e-03, -4.3632e-02,  2.8224e-02,\n",
       "         5.1046e-03, -8.4238e-02, -1.5847e-02, -2.3761e-02, -4.8956e-02,\n",
       "         9.5412e-03, -1.7547e-02,  6.0846e-02, -1.4363e-02,  3.3198e-02,\n",
       "         2.2472e-02, -2.4658e-02,  2.1328e-02,  6.6042e-04,  3.1147e-02,\n",
       "        -1.6595e-02,  5.1198e-02,  3.9469e-02, -3.4543e-02,  4.6543e-02,\n",
       "         4.4880e-02, -2.1799e-03,  1.6594e-02, -6.0061e-02, -1.6195e-02,\n",
       "        -1.4605e-02, -3.3715e-02,  4.9276e-03, -1.8302e-02,  5.8489e-03,\n",
       "         1.3355e-02,  5.6258e-02,  2.6300e-02,  5.4059e-03,  8.2502e-03,\n",
       "        -5.1805e-02,  4.3616e-03,  8.5166e-03, -5.3221e-02, -3.2083e-02,\n",
       "         2.2894e-02, -1.8498e-02, -8.6930e-02, -4.7494e-02, -1.6696e-02,\n",
       "        -3.0897e-02, -9.1090e-02, -3.2197e-02, -2.2495e-02, -1.0409e-02,\n",
       "         3.3398e-02,  5.6562e-03,  4.6087e-02,  3.2108e-02, -1.6257e-02,\n",
       "         3.8821e-02, -2.5474e-03, -7.8080e-02, -5.0873e-02, -5.1856e-03,\n",
       "         3.4313e-02,  1.7355e-02,  1.8828e-02,  2.1971e-03,  2.9542e-02,\n",
       "        -1.7906e-02, -5.1333e-02,  4.3271e-02, -6.4576e-02, -1.8973e-02,\n",
       "         9.8732e-02,  3.5012e-02, -6.3614e-02, -2.2947e-02,  1.7288e-02,\n",
       "        -1.3085e-01,  1.1612e-02,  4.0800e-03,  3.2499e-02, -3.3896e-02,\n",
       "        -2.6578e-02,  3.9236e-02, -1.5334e-02,  7.9028e-03, -1.8728e-02,\n",
       "         7.9688e-03, -5.4739e-02, -1.4806e-02, -4.4524e-03, -1.4379e-02,\n",
       "         6.3394e-02, -2.5161e-02,  3.4237e-02, -3.8842e-02,  2.5555e-02,\n",
       "        -5.0452e-03, -3.9838e-02, -2.3753e-02, -5.7066e-02,  5.7527e-02,\n",
       "        -5.4824e-02,  6.1110e-03,  3.6539e-03,  3.7115e-02, -4.1127e-03,\n",
       "         8.1898e-02,  4.0731e-02,  7.8906e-02, -4.1285e-02,  4.3645e-02,\n",
       "         2.1932e-02,  3.2840e-02,  7.9698e-03, -3.0583e-03,  7.4194e-04,\n",
       "         2.4498e-02,  5.0181e-03,  9.6831e-03,  1.9442e-04,  2.9519e-02,\n",
       "        -9.8194e-04, -4.3802e-02, -4.0038e-02, -7.1848e-02,  1.4378e-02,\n",
       "         6.5798e-02,  3.8191e-02, -7.5351e-03, -6.0218e-03, -5.6951e-02,\n",
       "         2.2421e-02, -4.0946e-02,  5.3153e-02, -2.9368e-02, -4.9378e-03,\n",
       "        -4.1816e-02,  3.1588e-02,  1.2995e-02, -2.7631e-02,  6.4071e-02,\n",
       "        -9.2493e-03, -6.2918e-02, -2.6750e-02, -6.4582e-02, -1.2072e-02,\n",
       "         1.5873e-02,  2.4277e-02,  4.0492e-02,  2.6741e-02, -2.5067e-02,\n",
       "        -3.2867e-02, -5.5635e-02, -4.0426e-02,  3.2816e-02,  9.0152e-02,\n",
       "         5.5045e-03,  3.5742e-02,  3.7184e-02,  1.8605e-02,  4.1378e-04,\n",
       "         8.1518e-03, -1.0525e-02, -2.4035e-02, -1.9894e-03,  2.9758e-02,\n",
       "        -6.4900e-33, -4.4588e-02, -1.2206e-02,  6.7949e-03,  4.0955e-02,\n",
       "        -2.1122e-02, -4.2786e-02,  1.2895e-02,  5.0729e-02, -1.9760e-02,\n",
       "        -9.5442e-03,  2.4442e-03,  1.2831e-02,  1.7848e-02, -2.8485e-02,\n",
       "        -2.5987e-02,  4.3103e-02, -9.0880e-03,  9.1473e-03, -2.2159e-02,\n",
       "        -3.8228e-02,  1.7809e-02,  1.2167e-02,  5.4930e-02,  6.6674e-03,\n",
       "         1.9953e-02, -3.5032e-02,  1.7536e-02, -2.3058e-02, -9.7779e-03,\n",
       "        -1.7641e-02,  2.8654e-02,  2.5001e-02, -2.9143e-02, -1.1297e-02,\n",
       "        -9.1320e-03,  2.5274e-02, -7.0270e-02, -3.8259e-02,  1.1220e-03,\n",
       "         5.6019e-02,  4.1181e-02, -4.4769e-02, -1.4372e-02, -1.9038e-02,\n",
       "        -4.2474e-02,  1.5217e-02,  5.2437e-04,  9.0636e-03, -3.9672e-02,\n",
       "        -4.1453e-02, -4.6084e-02, -2.7686e-02, -4.4464e-02,  2.7306e-02,\n",
       "         2.3031e-02, -2.2149e-02, -3.7043e-02, -6.4562e-02,  4.4480e-02,\n",
       "         2.8477e-02,  2.8959e-02,  1.8224e-02,  2.9735e-02, -4.8513e-02,\n",
       "         2.4434e-02, -1.6676e-02,  4.4714e-02,  2.2910e-02, -2.3490e-02,\n",
       "         1.1378e-02,  1.2056e-02,  2.9663e-02, -1.8144e-02, -1.1484e-02,\n",
       "         3.9234e-02, -5.3376e-02,  9.8440e-03, -4.5933e-04,  1.7374e-02,\n",
       "        -2.3318e-02, -5.3026e-02, -4.6180e-03, -3.0460e-02, -3.4943e-02,\n",
       "         7.1856e-03,  1.3864e-02,  6.0226e-03, -1.7630e-02,  2.1762e-02,\n",
       "        -4.1077e-02,  6.6570e-03,  1.5883e-02, -2.5176e-02, -1.4916e-02,\n",
       "        -1.9934e-02,  7.5211e-03, -1.4161e-02,  3.8687e-02, -2.4369e-02,\n",
       "         3.5631e-02, -8.6019e-03, -1.7206e-03, -4.6746e-02, -7.8074e-03,\n",
       "         4.9073e-02, -2.3091e-02, -2.5008e-02,  7.2543e-04, -3.4527e-02,\n",
       "         3.1161e-02,  1.8818e-02, -2.6495e-02, -1.3042e-02,  3.1242e-02,\n",
       "         2.0807e-02, -1.0612e-02,  4.3651e-02,  3.7342e-02,  2.7139e-02,\n",
       "        -7.6614e-02, -3.9187e-02, -7.8695e-03,  1.2408e-02,  1.1616e-02,\n",
       "         1.5827e-02, -4.8155e-03, -2.4903e-02, -1.1277e-02,  3.0135e-02,\n",
       "         5.3139e-03, -2.6041e-02,  1.9066e-02,  3.4191e-07,  1.9358e-02,\n",
       "         3.5761e-02,  3.7167e-02,  1.8195e-02, -1.1936e-02, -1.7462e-02,\n",
       "         1.2763e-03,  5.3381e-02,  2.9057e-02,  9.3837e-03, -3.8704e-02,\n",
       "        -6.1303e-04,  1.1048e-02, -6.9742e-02, -4.2566e-02, -2.2621e-02,\n",
       "         1.0517e-02,  9.7326e-03, -2.2742e-02, -2.8082e-02,  5.8031e-02,\n",
       "        -3.7045e-02,  2.6423e-02,  2.1675e-02,  4.6216e-03,  1.2092e-02,\n",
       "         1.7861e-02, -1.4522e-03,  5.6631e-02,  3.2192e-02, -1.5313e-02,\n",
       "        -3.5802e-03,  1.5823e-02,  8.2652e-03, -3.0042e-02, -3.8165e-02,\n",
       "         4.9237e-02,  7.5716e-02,  2.1445e-02,  4.9454e-02,  3.6802e-02,\n",
       "        -3.4372e-02, -3.3260e-02,  5.5735e-03,  5.2743e-02,  8.6737e-03,\n",
       "        -6.8030e-03,  7.2001e-02, -7.0492e-02, -1.1346e-02, -2.3788e-02,\n",
       "         6.2961e-03,  4.0146e-02,  4.5297e-02, -1.8846e-02, -5.6177e-03,\n",
       "        -2.9673e-02,  5.4165e-02, -3.4639e-02,  4.6640e-02, -3.3744e-02,\n",
       "        -5.5005e-02,  7.8024e-03, -1.6438e-02,  3.9179e-02, -2.4684e-02,\n",
       "        -5.6206e-03,  3.8590e-34,  1.1239e-02, -4.0236e-02,  5.2027e-02,\n",
       "         2.1549e-02, -4.6262e-02, -5.4540e-03, -8.6157e-03,  7.7766e-03,\n",
       "         7.8483e-03,  7.4626e-02, -3.3081e-02], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!\n",
    "\n",
    "Now let's prepare another instance of our embedding model. Not because we have to but because we'd like to make it so you can start the notebook from the cell above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbaa07224a840d88302299cee1bc324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=device) # choose the device to load the model to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding model ready!\n",
    "\n",
    "Time to perform a semantic search.\n",
    "\n",
    "Let's say you were studying the macronutrients.\n",
    "\n",
    "And wanted to search your textbook for \"macronutrients functions\".\n",
    "\n",
    "Well, we can do so with the following steps:\n",
    "1. Define a query string (e.g. `\"macronutrients functions\"`) - note: this could be anything, specific or not.\n",
    "2. Turn the query string in an embedding with same model we used to embed our text chunks.\n",
    "3. Perform a [dot product](https://pytorch.org/docs/stable/generated/torch.dot.html) or [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) function between the text embeddings and the query embedding (we'll get to what these are shortly) to get similarity scores.\n",
    "4. Sort the results from step 3 in descending order (a higher score means more similarity in the eyes of the model) and use these values to inspect the texts. \n",
    "\n",
    "Easy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: macronutrients functions\n",
      "Time take to get scores on 2677 embeddings: 0.35969 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.2459, 0.2258, 0.2185, 0.2105, 0.2094], device='cuda:0'),\n",
       "indices=tensor([2497, 1314, 2302, 2518, 1257], device='cuda:0'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define the query\n",
    "# Note: This could be anything. But since we're working with a nutrition textbook, we'll stick with nutrition-based queries.\n",
    "query = \"macronutrients functions\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 2. Embed the query to the same numerical space as the text examples \n",
    "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# 3. Get similarity scores with the dot product (we'll time this for fun)\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# 4. Get the top-k results (we'll keep this to 5)\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah!! Now that was fast!\n",
    "\n",
    "~0.00008 seconds to perform a dot product comparison across 1680 embeddings on my machine (NVIDIA RTX 4090 GPU).\n",
    "\n",
    "GPUs are optimized for these kinds of operations.\n",
    "\n",
    "So even if you we're to increase our embeddings by 100x (1680 -> 168,000), an exhaustive dot product operation would happen in ~0.008 seconds (assuming linear scaling).\n",
    "\n",
    "Heck, let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([267700, 768])\n",
      "Time take to get scores on 267700 embeddings: 0.20452 seconds.\n"
     ]
    }
   ],
   "source": [
    "larger_embeddings = torch.randn(100*embeddings.shape[0], 768).to(device)\n",
    "print(f\"Embeddings shape: {larger_embeddings.shape}\")\n",
    "\n",
    "# Perform dot product across 168,000 embeddings\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=larger_embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(larger_embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. That's quick!\n",
    "\n",
    "That means we can get pretty far by just storing our embeddings in `torch.tensor` for now.\n",
    "\n",
    "However, for *much* larger datasets, we'd likely look at a dedicated vector database/indexing libraries such as [Faiss](https://github.com/facebookresearch/faiss).\n",
    "\n",
    "Let's check the results of our original similarity search.\n",
    "\n",
    "[`torch.topk`](https://pytorch.org/docs/stable/generated/torch.topk.html) returns a tuple of values (scores) and indicies for those scores.\n",
    "\n",
    "The indicies relate to which indicies in the `embeddings` tensor have what scores in relation to the query embedding (higher is better).\n",
    "\n",
    "We can use those indicies to map back to our text chunks.\n",
    "\n",
    "First, we'll define a small helper function to print out wrapped text (so it doesn't print a whole text chunk as a single line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text \n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop through the `top_results_dot_product` tuple and match up the scores and indicies and then use those indicies to index on our `pages_and_chunks` variable to get the relevant text chunk.\n",
    "\n",
    "Sounds like a lot but we can do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'macronutrients functions'\n",
      "\n",
      "Results:\n",
      "Score: 0.2459\n",
      "Text:\n",
      "This element can be either a selection linked to some program action, such as\n",
      "Save or Close, or it can cause a submenu to be displayed. MenuItem defines the\n",
      "following three constructors. MenuItem(¬†) MenuItem(String name) MenuItem(String\n",
      "name, Node image) The first creates an empty menu item. The second lets you\n",
      "specify the name of the item, and the third enables you to include an image.\n",
      "Page number: 1208\n",
      "\n",
      "\n",
      "Score: 0.2258\n",
      "Text:\n",
      "It also describes various options, such as justification, minimum field width,\n",
      "and precision. Format Specifier Conversion Applied %g %G Uses %e or %f, based on\n",
      "the value being formatted and the precision %o Octal integer %n Inserts a\n",
      "newline character %s %S String %t %T Time and date %x %X Integer hexadecimal %%\n",
      "Inserts a % sign Table 19-13‚ÄÉ The Format Specifiers (continued)\n",
      "Page number: 642\n",
      "\n",
      "\n",
      "Score: 0.2185\n",
      "Text:\n",
      "These are used to specify the upper-left corner of the popup menu when it is\n",
      "displayed. The isPopupTrigger(¬†) method returns true if the mouse event\n",
      "represents a popup trigger and false otherwise. You will use this method to\n",
      "determine when to pop up the menu. To obtain a reference to the component that\n",
      "generated the mouse event, call getComponent(¬†).\n",
      "Page number: 1118\n",
      "\n",
      "\n",
      "Score: 0.2105\n",
      "Text:\n",
      "Chapter 36‚ÄÉ  Introducing JavaFX Menus‚ÄÉ ‚ÄÇ 1185 Part IV After making the\n",
      "substitution, the check menu items in the Colors submenu look like those shown\n",
      "here: Here is how the radio menu items in the Priority submenu now look: Create\n",
      "a Context Menu A popular alternative or addition to the menu bar is the popup\n",
      "menu, which in JavaFX is referred to as a context menu. Typically, a context\n",
      "menu is activated by clicking the right mouse button when over a control. Popup\n",
      "menus are supported in JavaFX by the ContextMenu class. The direct superclass of\n",
      "ContextMenu is PopupControl. An indirect superclass of ContextMenu is\n",
      "javafx.stage. PopupWindow, which supplies much of its basic functionality.\n",
      "Page number: 1219\n",
      "\n",
      "\n",
      "Score: 0.2094\n",
      "Text:\n",
      "super T,          Optional<U>> mapFunc) Applies the mapping function specified\n",
      "by mapFunc to the invoking object if that object contains a value and returns\n",
      "the result. Returns an empty object otherwise. T get(¬†) Returns the value in the\n",
      "invoking object. However, if no value is present, NoSuchElementException is\n",
      "thrown.int hashCode(¬†) Returns a hashcode for the invoking object.void\n",
      "ifPresent(   Consumer<?super T> func) Calls func if a value is present in the\n",
      "invoking object, passing the object to func. If no value is present, no action\n",
      "occurs.boolean isPresent(¬†) Returns true if the invoking object contains a\n",
      "value. Returns false if no value is present.\n",
      "Page number: 618\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indicies from torch.topk\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "    print(\"Text:\")\n",
    "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "    # Print the page number too so we can reference the textbook further (and check the results)\n",
    "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first result looks to have nailed it!\n",
    "\n",
    "We get a very relevant answer to our query `\"macronutrients functions\"` even though its quite vague.\n",
    "\n",
    "That's the power of semantic search!\n",
    "\n",
    "And even better, if we wanted to inspect the result further, we get the page number where the text appears.\n",
    "\n",
    "How about we check the page to verify?\n",
    "\n",
    "We can do so by loading the page number containing the highest result (page 5 but really page 5 + 41 since our PDF page numbers start on page 41)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "no such file: 'human-nutrition-text.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_20016\\983245753.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m fitz\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Open PDF and load target page\u001b[39;00m\n\u001b[32m      4\u001b[39m pdf_path = \u001b[33m\"human-nutrition-text.pdf\"\u001b[39m \u001b[38;5;66;03m# requires PDF to be downloaded\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m doc = fitz.open(pdf_path)\n\u001b[32m      6\u001b[39m page = doc.load_page(\u001b[32m5\u001b[39m + \u001b[32m41\u001b[39m) \u001b[38;5;66;03m# number of page (our doc starts page numbers on page 41)\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Get the image of the page\u001b[39;00m\n",
      "\u001b[32md:\\Study Stuff\\RAG model\\Implementation Locally\\venv_py312\\Lib\\site-packages\\pymupdf\\__init__.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[39m\n\u001b[32m   3061\u001b[39m                     self.page_count2 = extra.page_count_pdf\n\u001b[32m   3062\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3063\u001b[39m                     self.page_count2 = extra.page_count_fz\n\u001b[32m   3064\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3065\u001b[39m             JM_mupdf_show_errors = JM_mupdf_show_errors_old\n",
      "\u001b[31mFileNotFoundError\u001b[39m: no such file: 'human-nutrition-text.pdf'"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "# Open PDF and load target page\n",
    "pdf_path = \"human-nutrition-text.pdf\" # requires PDF to be downloaded\n",
    "doc = fitz.open(pdf_path)\n",
    "page = doc.load_page(5 + 41) # number of page (our doc starts page numbers on page 41)\n",
    "\n",
    "# Get the image of the page\n",
    "img = page.get_pixmap(dpi=300)\n",
    "\n",
    "# Optional: save the image\n",
    "#img.save(\"output_filename.png\")\n",
    "doc.close()\n",
    "\n",
    "# Convert the Pixmap to a numpy array\n",
    "img_array = np.frombuffer(img.samples_mv, \n",
    "                          dtype=np.uint8).reshape((img.h, img.w, img.n))\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(13, 10))\n",
    "plt.imshow(img_array)\n",
    "plt.title(f\"Query: '{query}' | Most relevant page:\")\n",
    "plt.axis('off') # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!\n",
    "\n",
    "Now we can do extra research if we'd like.\n",
    "\n",
    "We could repeat this workflow for any kind of query we'd like on our textbook.\n",
    "\n",
    "And it would also work for other datatypes too.\n",
    "\n",
    "We could use semantic search on customer support documents.\n",
    "\n",
    "Or email threads.\n",
    "\n",
    "Or company plans.\n",
    "\n",
    "Or our old journal entries.\n",
    "\n",
    "Almost anything!\n",
    "\n",
    "The workflow is the same:\n",
    "\n",
    "`ingest documents -> split into chunks -> embed chunks -> make a query -> embed the query -> compare query embedding to chunk embeddings`\n",
    "\n",
    "And we get relevant resources *along with* the source they came from!\n",
    "\n",
    "That's the **retrieval** part of Retrieval Augmented Generation (RAG).\n",
    "\n",
    "Before we get to the next two steps, let's take a small aside and discuss similarity measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity measures: dot product and cosine similarity \n",
    "\n",
    "Let's talk similarity measures between vectors.\n",
    "\n",
    "Specifically, embedding vectors which are representations of data with magnitude and direction in high dimensional space (our embedding vectors have 768 dimensions).\n",
    "\n",
    "Two of the most common you'll across are the dot product and cosine similarity.\n",
    "\n",
    "They are quite similar.\n",
    "\n",
    "The main difference is that cosine similarity has a normalization step.\n",
    "\n",
    "| Similarity measure | Description | Code |\n",
    "| ----- | ----- | ----- |\n",
    "| [Dot Product](https://en.wikipedia.org/wiki/Dot_product) | - Measure of magnitude and direction between two vectors<br>- Vectors that are aligned in direction and magnitude have a higher positive value<br>- Vectors that are opposite in direction and magnitude have a higher negative value | [`torch.dot`](https://pytorch.org/docs/stable/generated/torch.dot.html), [`np.dot`](https://numpy.org/doc/stable/reference/generated/numpy.dot.html), [`sentence_transformers.util.dot_score`](https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.dot_score) | \n",
    "| [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) | - Vectors get normalized by magnitude/[Euclidean norm](https://en.wikipedia.org/wiki/Norm_(mathematics))/L2 norm so they have unit length and are compared more so on direction<br>- Vectors that are aligned in direction have a value close to 1<br>- Vectors that are opposite in direction have a value close to -1 | [`torch.nn.functional.cosine_similarity`](https://pytorch.org/docs/stable/generated/torch.nn.functional.cosine_similarity.html), [`1 - scipy.spatial.distance.cosine`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html) (subtract the distance from 1 for similarity measure), [`sentence_transformers.util.cos_sim`](https://www.sbert.net/docs/package_reference/util.html#sentence_transformers.util.cos_sim) |\n",
    "\n",
    "For text similarity, you generally want to use cosine similarity as you are after the semantic measurements (direction) rather than magnitude. \n",
    "\n",
    "In our case, our embedding model `all-mpnet-base-v2` outputs normalized outputs (see the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#usage-huggingface-transformers) for more on this) so dot product and cosine similarity return the same results. However, dot product is faster due to not need to perform a normalize step.\n",
    "\n",
    "To make things bit more concrete, let's make simple dot product and cosine similarity functions and view their results on different vectors.\n",
    "\n",
    "> **Note:** Similarity measures between vectors and embeddings can be used on any kind of embeddings, not just text embeddings. For example, you could measure image embedding similarity or audio embedding similarity. Or with text and image models like [CLIP](https://github.com/mlfoundations/open_clip), you can measure the similarity between text and image embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product between vector1 and vector2: tensor(14., device='cuda:0')\n",
      "Dot product between vector1 and vector3: tensor(32., device='cuda:0')\n",
      "Dot product between vector1 and vector4: tensor(-14., device='cuda:0')\n",
      "Cosine similarity between vector1 and vector2: tensor(1.0000, device='cuda:0')\n",
      "Cosine similarity between vector1 and vector3: tensor(0.9746, device='cuda:0')\n",
      "Cosine similarity between vector1 and vector4: tensor(-1.0000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def dot_product(vector1, vector2):\n",
    "    return torch.dot(vector1, vector2)\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = torch.dot(vector1, vector2)\n",
    "\n",
    "    # Get Euclidean/L2 norm of each vector (removes the magnitude, keeps direction)\n",
    "    norm_vector1 = torch.sqrt(torch.sum(vector1**2))\n",
    "    norm_vector2 = torch.sqrt(torch.sum(vector2**2))\n",
    "\n",
    "    return dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "# Example tensors\n",
    "vector1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "vector2 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "vector3 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
    "vector4 = torch.tensor([-1, -2, -3], dtype=torch.float32)\n",
    "\n",
    "# Calculate dot product\n",
    "print(\"Dot product between vector1 and vector2:\", dot_product(vector1, vector2))\n",
    "print(\"Dot product between vector1 and vector3:\", dot_product(vector1, vector3))\n",
    "print(\"Dot product between vector1 and vector4:\", dot_product(vector1, vector4))\n",
    "\n",
    "# Calculate cosine similarity\n",
    "print(\"Cosine similarity between vector1 and vector2:\", cosine_similarity(vector1, vector2))\n",
    "print(\"Cosine similarity between vector1 and vector3:\", cosine_similarity(vector1, vector3))\n",
    "print(\"Cosine similarity between vector1 and vector4:\", cosine_similarity(vector1, vector4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice for both dot product and cosine similarity the comparisons of `vector1` and `vector2` are the opposite of `vector1` and `vector4`.\n",
    "\n",
    "Comparing `vector1` and `vector2` both equations return positive values (14 for dot product and 1.0 for cosine similarity). \n",
    "\n",
    "But comparing `vector1` and `vector4` the result is in the negative direction.\n",
    "\n",
    "This makes sense because `vector4` is the negative version of `vector1`.\n",
    "\n",
    "Whereas comparing `vector1` and `vector3` shows a different outcome.\n",
    "\n",
    "For the dot product, the value is positive and larger then the comparison of two exactly the same vectors (32 vs 14).\n",
    "\n",
    "However, for the cosine similarity, thanks to the normalization step, comparing `vector1` and `vector3` results in a postive value close to 1 but not exactly 1.\n",
    "\n",
    "It is because of this that when comparing text embeddings, cosine similarity is generally favoured as it measures the difference in direction of a pair of vectors rather than difference in magnitude.\n",
    "\n",
    "And it is this difference in direction that is more generally considered to capture the semantic meaning/vibe of the text.\n",
    "\n",
    "The good news is that as mentioned before, the outputs of our embedding model `all-mpnet-base-v2` are already normalized.\n",
    "\n",
    "So we can continue using the dot product (cosine similarity is dot product + normalization).\n",
    "\n",
    "With similarity measures explained, let's functionize our semantic search steps from above so we can repeat them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionizing our semantic search pipeline\n",
    "\n",
    "Let's put all of the steps from above for semantic search into a function or two so we can repeat the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=5,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, \n",
    "                                   convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    end_time = timer()\n",
    "\n",
    "    if print_time:\n",
    "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices\n",
    "\n",
    "def print_top_results_and_scores(query: str,\n",
    "                                 embeddings: torch.tensor,\n",
    "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
    "                                 n_resources_to_return: int=5):\n",
    "    \"\"\"\n",
    "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
    "\n",
    "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
    "    \"\"\"\n",
    "    \n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings,\n",
    "                                                  n_resources_to_return=n_resources_to_return)\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(\"Results:\")\n",
    "    # Loop through zipped together scores and indicies\n",
    "    for score, index in zip(scores, indices):\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
    "        # Print the page number too so we can reference the textbook further and check the results\n",
    "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Now let's test our functions out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 2677 embeddings: 0.00017 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1634, 0.1496, 0.1478, 0.1430, 0.1426], device='cuda:0'),\n",
       " tensor([1970, 1963, 1972, 1971, 1681], device='cuda:0'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"symptoms of pellagra\"\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time taken to get scores on 2677 embeddings: 0.00012 seconds.\n",
      "Query: symptoms of pellagra\n",
      "\n",
      "Results:\n",
      "Score: 0.1634\n",
      "import java.util.concurrent.*; // Extend MyPhaser to allow only a specific\n",
      "number of phases // to be executed.class MyPhaser extends Phaser {  int\n",
      "numPhases;  MyPhaser(int parties, int phaseCount) {   super(parties);\n",
      "numPhases = phaseCount - 1;  }  // Override onAdvance() to execute the specified\n",
      "// number of phases.protected boolean onAdvance(int p, int regParties) {   //\n",
      "This println() statement is for illustration only.// Normally, onAdvance() will\n",
      "not display output. System.out.println(\"Phase \" + p + \" completed.\\n\");   // If\n",
      "all phases have completed, return true   if(p == numPhases || regParties == 0)\n",
      "return true;   // Otherwise, return false.return false;  } } class PhaserDemo2 {\n",
      "public static void main(String args[]) {   MyPhaser phsr = new MyPhaser(1, 4);\n",
      "System.out.println(\"Starting\\n\");   new MyThread(phsr, \"A\");   new\n",
      "MyThread(phsr, \"B\");   new MyThread(phsr, \"C\");   // Wait for the specified\n",
      "number of phases to complete.while(!phsr.isTerminated()) {\n",
      "Page number: 968\n",
      "\n",
      "\n",
      "Score: 0.1496\n",
      "932‚ÄÉ ‚ÄÇ PART II‚ÄÉ  The Java Library   // Deregister the main\n",
      "thread.phsr.arriveAndDeregister();   if(phsr.isTerminated())\n",
      "System.out.println(\"The Phaser is terminated\");  } } // A thread of execution\n",
      "that uses a Phaser.class MyThread implements Runnable {  Phaser phsr;  String\n",
      "name;  MyThread(Phaser p, String n) {   phsr = p;   name = n;   phsr.register();\n",
      "new Thread(this).start();  }  public void run() {     System.out.println(\"Thread\n",
      "\" + name + \" Beginning Phase One\");   phsr.arriveAndAwaitAdvance(); // Signal\n",
      "arrival.// Pause a bit to prevent jumbled output. This is for illustration   //\n",
      "only. It is not required for the proper operation of the phaser.try {\n",
      "Thread.sleep(10);   } catch(InterruptedException e) {    System.out.println(e);\n",
      "}   System.out.println(\"Thread \" + name + \" Beginning Phase Two\");\n",
      "phsr.arriveAndAwaitAdvance(); // Signal arrival.// Pause a bit to prevent\n",
      "jumbled output. This is for illustration   // only. It is not required for the\n",
      "proper operation of the phaser.\n",
      "Page number: 966\n",
      "\n",
      "\n",
      "Score: 0.1478\n",
      "936‚ÄÉ ‚ÄÇ PART II‚ÄÉ  The Java Library  Thread C Beginning Phase 3  Thread B\n",
      "Beginning Phase 3  Thread A Beginning Phase 3  Phase 3 completed. The Phaser is\n",
      "terminated Inside main( ), one instance of Phaser is created. It is passed 4 as\n",
      "an argument, which means that it will execute four phases and then stop. Next,\n",
      "three threads are created and then the following loop is entered: // Wait for\n",
      "the specified number of phases to complete.while(!phsr.isTerminated()) {\n",
      "phsr.arriveAndAwaitAdvance(); } This loop simply calls arriveAndAwaitAdvance( )\n",
      "until the phaser is terminated. The phaser won‚Äôt terminate until the specified\n",
      "number of phases have been executed. In this case, the loop continues to execute\n",
      "until four phases have run. Next, notice that the threads also call\n",
      "arriveAndAwaitAdvance( ) within a loop that runs until the phaser is terminated.\n",
      "This means that they will execute until the specified number of phases has been\n",
      "completed. Now, look closely at the code for onAdvance( ).\n",
      "Page number: 970\n",
      "\n",
      "\n",
      "Score: 0.1430\n",
      "Chapter 28‚ÄÉ  The Concurrency Utilities‚ÄÉ ‚ÄÇ 935 Part II\n",
      "phsr.arriveAndAwaitAdvance();   }   System.out.println(\"The Phaser is\n",
      "terminated\");  } } // A thread of execution that uses a Phaser.class MyThread\n",
      "implements Runnable {  Phaser phsr;  String name;  MyThread(Phaser p, String n)\n",
      "{   phsr = p;   name = n;   phsr.register();   new Thread(this).start();  }\n",
      "public void run() {   while(!phsr.isTerminated()) {\n",
      "System.out.println(\"Thread \" + name + \" Beginning Phase \" +\n",
      "phsr.getPhase());    phsr.arriveAndAwaitAdvance();    // Pause a bit to prevent\n",
      "jumbled output. This is for illustration    // only. It is not required for the\n",
      "proper operation of the phaser.try {     Thread.sleep(10);    }\n",
      "catch(InterruptedException e) {     System.out.println(e);    }   }  } } The\n",
      "output from the program is shown here:  Starting   Thread B Beginning Phase 0\n",
      "Thread A Beginning Phase 0  Thread C Beginning Phase 0  Phase 0 completed.\n",
      "Thread A Beginning Phase 1  Thread B Beginning Phase 1  Thread C Beginning Phase\n",
      "1  Phase 1 completed. Thread C Beginning Phase 2  Thread B Beginning Phase 2\n",
      "Thread A Beginning Phase 2  Phase 2 completed.\n",
      "Page number: 969\n",
      "\n",
      "\n",
      "Score: 0.1426\n",
      "KeyEvent Generated when input is received from the keyboard. MouseEvent\n",
      "Generated when the mouse is dragged, moved, clicked, pressed, or released; also\n",
      "generated when the mouse enters or exits a component. MouseWheelEvent Generated\n",
      "when the mouse wheel is moved. TextEvent Generated when the value of a text area\n",
      "or text field is changed. WindowEvent Generated when a window is activated,\n",
      "closed, deactivated, deiconified, iconified, opened, or quit.\n",
      "Page number: 806\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the texts of the top scores\n",
    "print_top_results_and_scores(query=query,\n",
    "                             embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search/vector search extensions \n",
    "\n",
    "We've covered an exmaple of using embedding vector search to find relevant results based on a query.\n",
    "\n",
    "However, you could also add to this pipeline with traditional keyword search.\n",
    "\n",
    "Many modern search systems use keyword and vector search in tandem.\n",
    "\n",
    "Our dataset is small and allows for an exhaustive search (comparing the query to *every* possible result) but if you start to work with large scale datasets with hundred of thousands, millions or even billions of vectors, you'll want to implement an index.\n",
    "\n",
    "You can think of an index as sorting your embeddings before you search through them.\n",
    "\n",
    "So it narrows down the search space.\n",
    "\n",
    "For example, it would be inefficient to search every word in the dictionary to find the word \"duck\", instead you'd go straight to the letter D, perhaps even straight to the back half of the letter D, find words close to \"duck\" before finding it.\n",
    "\n",
    "That's how an index can help search through many examples without comprimising too much on speed or quality (for more on this, check out [nearest neighbour search](https://en.wikipedia.org/wiki/Nearest_neighbor_search)).\n",
    "\n",
    "One of the most popular indexing libraries is [Faiss](https://github.com/facebookresearch/faiss). \n",
    "\n",
    "Faiss is open-source and was originally created by Facebook to deal with internet-scale vectors and implements many algorithms such as [HNSW](https://arxiv.org/abs/1603.09320) (Hierarchical Naviganle Small Worlds)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting an LLM for local generation\n",
    "\n",
    "We're got our retrieval pipeline ready, let's now get the generation side of things happening.\n",
    "\n",
    "To perform generation, we're going to use a Large Language Model (LLM).\n",
    "\n",
    "LLMs are designed to generate an output given an input.\n",
    "\n",
    "In our case, we want our LLM to generate and output of text given a input of text.\n",
    "\n",
    "And more specifically, we want the output of text to be generated based on the context of relevant information to the query.\n",
    "\n",
    "The input to an LLM is often referred to as a prompt.\n",
    "\n",
    "We'll augment our prompt with a query as well as context from our textbook related to that query.\n",
    "\n",
    "> **Which LLM should I use?**\n",
    "\n",
    "There are many LLMs available.\n",
    "\n",
    "Two of the main questions to ask from this is:\n",
    "1. Do I want it to run locally? \n",
    "2. If yes, how much compute power can I dedicate?\n",
    "\n",
    "If you're after the absolute best performance, you'll likely want to use an API (not running locally) such as GPT-4 or Claude 3. However, this comes with the tradeoff of sending your data away and then awaiting a response.\n",
    "\n",
    "For our case, since we want to set up a local pipeline and run it on our own GPU, we'd answer \"yes\" to the first question and then the second question will depend on what hardware we have available.\n",
    "\n",
    "To find open-source LLMs, one great resource is the [Hugging Face open LLM leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).\n",
    "\n",
    "The leaderboard compares many of the latest and greatest LLMs on various benchmarks.\n",
    "\n",
    "Another great resource is [TheBloke on Hugging Face](https://huggingface.co/TheBloke), an account which provides an extensive range of quantized (models that have been made smaller) LLMs.\n",
    "\n",
    "A rule of thumb for LLMs (and deep learning models in general) is that the higher the number of parameters, the better the model performs. \n",
    "\n",
    "It may be tempting to go for the largest size model (e.g. a 70B parameter model rather than a 7B parameter model) but a larger size model may not be able to run on your available hardware.\n",
    "\n",
    "The following table gives an insight into how much GPU memory you'll need to load an LLM with different sizes and different levels of [numerical precision](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "They are based on the fact that 1 float32 value (e.g. `0.69420`) requires 4 bytes of memory and 1GB is approximately 1,000,000,000 (one billion) bytes.\n",
    "\n",
    "| Model Size (Billion Parameters) | Float32 VRAM (GB) | Float16 VRAM (GB) | 8-bit VRAM (GB) | 4-bit VRAM (GB) |\n",
    "|-----|-----|-----|-----|-----|\n",
    "| 1B                              | ~4                | ~2                | ~1              | ~0.5            |\n",
    "| 7B (e.g., [Llama 2 7B](https://huggingface.co/meta-llama/Llama-2-7b), [Gemma 7B](https://huggingface.co/google/gemma-7b-it), [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1))             | ~28               | ~14               | ~7              | ~3.5            |\n",
    "| 10B                             | ~40               | ~20               | ~10             | ~5              |\n",
    "| 70B (e.g, Llama 2 70B)          | ~280              | ~140              | ~70             | ~35             |\n",
    "| 100B                            | ~400              | ~200              | ~100            | ~50             |\n",
    "| 175B                            | ~700              | ~350              | ~175            | ~87.5           |\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Note:** Loading a model in a lower precision (e.g. 8-bit instead of float16) generally lowers performance. Lower precision can help to reduce computing requirements, however sometimes the performance degradation in terms of model output can be substantial. Finding the right speed/performance tradeoff will often require many experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking local GPU memory availability\n",
    "\n",
    "Let's find out what hardware we've got available and see what kind of model(s) we'll be able to load.\n",
    "\n",
    "> **Note:** You can also check this with the `!nvidia-smi` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 4 GB\n"
     ]
    }
   ],
   "source": [
    "# Get GPU available memory\n",
    "import torch\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok wonderful!\n",
    "\n",
    "I'm running this notebook with a NVIDIA RTX 3050, so I've got 4 of VRAM available.\n",
    "\n",
    "However, this may be different on your end.\n",
    "\n",
    "Looking at the table above, it seems we can run a ~7-10B parameter model in float16 precision pretty comfortably.\n",
    "\n",
    "But we could also run a smaller one if we'd like.\n",
    "\n",
    "Let's try out the recently released (at the time of writing, March 2024) LLM from Google, [Gemma](https://huggingface.co/blog/gemma).\n",
    "\n",
    "Specifically, we'll use the `gemma-7b-it` version which stands for Gemma 7B Instruction-Tuned.\n",
    "\n",
    "Instruction tuning is the process of tuning a raw language model to follow instructions.\n",
    "\n",
    "These are the kind of models you'll find in most chat-based assistants such as ChatGPT, Gemini or Claude.\n",
    "\n",
    "The following table shows different amounts of GPU memory requirements for different verions of the Gemma LLMs with varying levels of precision.\n",
    "\n",
    "| Model             | Precision | Min-Memory (Bytes) | Min-Memory (MB) | Min-Memory (GB) | Recommended Memory (GB) | Hugging Face ID |\n",
    "|-------------------|-----------|----------------|-------------|-------------| ----- | ----- |\n",
    "| [Gemma 2B](https://huggingface.co/google/gemma-2b-it)          | 4-bit     | 2,106,749,952  | 2009.15     | 1.96        | ~5.0 | [`gemma-2b`](https://huggingface.co/google/gemma-2b) or [`gemma-2b-it`](https://huggingface.co/google/gemma-2b-it) for instruction tuned version | \n",
    "| Gemma 2B          | Float16   | 5,079,453,696  | 4844.14     | 4.73        | ~8.0 | Same as above |\n",
    "| [Gemma 7B](https://huggingface.co/google/gemma-7b-it)          | 4-bit     | 5,515,859,968  | 5260.33     | 5.14        | ~8.0 | [`gemma-7b`](https://huggingface.co/google/gemma-7b) or [`gemma-7b-it`](https://huggingface.co/google/gemma-7b-it) for instruction tuned version |\n",
    "| Gemma 7B          | Float16   | 17,142,470,656 | 16348.33    | 15.97       | ~19 | Same as above |\n",
    "\n",
    "> **Note:** `gemma-7b-it` means \"instruction tuned\", as in, a base LLM (`gemma-7b`) has been fine-tuned to follow instructions, similar to [`Mistral-7B-v0.1`](https://huggingface.co/mistralai/Mistral-7B-v0.1) and [`Mistral-7B-Instruct-v0.1`](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1).\n",
    "> \n",
    "> There are also further quantized and smaller variants of Gemma (and other LLMs) available in various formats such as GGUF. You can see many of these on [TheBloke account on Hugging Face](https://huggingface.co/TheBloke).\n",
    "> \n",
    "> The version of LLM you choose to use will be largely based on project requirements and experimentation.\n",
    "\n",
    "Based on the table above, let's write a simple if/else statement which recommends which Gemma variant we should look into using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your available GPU memory is 4GB, you may not have enough memory to run a Gemma LLM locally without quantization.\n",
      "use_quantization_config set to: False\n",
      "model_id set to: None\n"
     ]
    }
   ],
   "source": [
    "# Note: the following is Gemma focused, however, there are more and more LLMs of the 2B and 7B size appearing for local use.\n",
    "# Initialize defaults to avoid NameError if a branch doesn't set them\n",
    "use_quantization_config = False\n",
    "model_id = None\n",
    "\n",
    "if gpu_memory_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
    "elif gpu_memory_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading an LLM locally\n",
    "\n",
    "Alright! Looks like `gemma-7b-it` it is (for my local machine with an RTX 4090, change the `model_id` and `use_quantization_config` values to suit your needs)! \n",
    "\n",
    "There are plenty of examples of how to load the model on the `gemma-7b-it` [Hugging Face model card](https://huggingface.co/google/gemma-7b-it).\n",
    "\n",
    "Good news is, the Hugging Face [`transformers`](https://huggingface.co/docs/transformers/) library has all the tools we need.\n",
    "\n",
    "To load our LLM, we're going to need a few things:\n",
    "1. A quantization config (optional) - This will determine whether or not we load the model in 4bit precision for lower memory usage. The we can create this with the [`transformers.BitsAndBytesConfig`](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/quantization#transformers.BitsAndBytesConfig) class (requires installing the [`bitsandbytes` library](https://github.com/TimDettmers/bitsandbytes)).\n",
    "2. A model ID - This is the reference Hugging Face model ID which will determine which tokenizer and model gets used. For example `gemma-7b-it`.\n",
    "3. A tokenzier - This is what will turn our raw text into tokens ready for the model. We can create it using the [`transformers.AutoTokenzier.from_pretrained`](https://huggingface.co/docs/transformers/v4.38.2/en/model_doc/auto#transformers.AutoTokenizer) method and passing it our model ID.\n",
    "4. An LLM model - Again, using our model ID we can load a specific LLM model. To do so we can use the [`transformers.AutoModelForCausalLM.from_pretrained`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM.from_pretrained) method and passing it our model ID as well as other various parameters.\n",
    "\n",
    "As a bonus, we'll check if [Flash Attention 2](https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2) is available using `transformers.utils.is_flash_attn_2_available()`. Flash Attention 2 speeds up the attention mechanism in Transformer architecture models (which is what many modern LLMs are based on, including Gemma). So if it's available and the model is supported (not all models support Flash Attention 2), we'll use it. If it's not available, you can install it by following the instructions on the [GitHub repo](https://github.com/Dao-AILab/flash-attention). \n",
    "\n",
    "> **Note:** Flash Attention 2 currently works on NVIDIA GPUs with a compute capability score of 8.0+ (Ampere, Ada Lovelace, Hopper architectures). We can check our GPU compute capability score with [`torch.cuda.get_device_capability(0)`](https://pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html). \n",
    "\n",
    "> **Note:** To get access to the Gemma models, you will have to [agree to the terms & conditions](https://huggingface.co/google/gemma-7b-it) on the Gemma model page on Hugging Face. You will then have to authorize your local machine via the [Hugging Face CLI/Hugging Face Hub `login()` function](https://huggingface.co/docs/huggingface_hub/en/quick-start#authentication). Once you've done this, you'll be able to download the models. If you're using Google Colab, you can add a [Hugging Face token](https://huggingface.co/docs/hub/en/security-tokens) to the \"Secrets\" tab.\n",
    ">\n",
    "> Downloading an LLM locally can take a fair bit of time depending on your internet connection. Gemma 7B is about a 16GB download and Gemma 2B is about a 6GB download.\n",
    "\n",
    "Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Study Stuff\\RAG model\\Implementation Locally\\venv_py312\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1+cu121, but you have torch 2.10.0 which is incompatible.\n",
      "torchvision 0.20.1+cu121 requires torch==2.5.1+cu121, but you have torch 2.10.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "GPU memory: 4.29 GB\n",
      "\n",
      "Loading model: google/flan-t5-small\n",
      "Loading tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ba1d7eb9c74d9380ddfcef8c2d76c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study Stuff\\RAG model\\Implementation Locally\\venv_py312\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kaushik Maslekar\\.cache\\huggingface\\hub\\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23b9650342a4dc0bd90c04f71a8c9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72720a5542e412d9e8c62e4038866eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c6adf8b5cc4577916cdfd09f158348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b182055037458d89e58f6582e7c51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b324d01424542d0a199e21ca5e7c87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2c176c775c468681131571e35f1c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41e60e7132c4530aeb9f892295548f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Model loaded and moved to cuda\n"
     ]
    }
   ],
   "source": [
    "# First install required packages\n",
    "!pip install -q bitsandbytes accelerate transformers torch --upgrade\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  # Changed to Seq2SeqLM for T5\n",
    "\n",
    "# Print versions for debugging\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"No GPU available, using CPU\")\n",
    "\n",
    "# Use a smaller model that's more likely to work\n",
    "model_id = \"google/flan-t5-small\"  # This is a smaller model that should work even with limited GPU memory\n",
    "print(f\"\\nLoading model: {model_id}\")\n",
    "\n",
    "try:\n",
    "    # 1. Load tokenizer\n",
    "    print(\"Loading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "    # 2. Load model with basic settings\n",
    "    print(\"Loading model...\")\n",
    "    llm_model = AutoModelForSeq2SeqLM.from_pretrained(  # Changed to Seq2SeqLM\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # 3. Move to device\n",
    "    llm_model = llm_model.to(device)\n",
    "    print(f\"Success! Model loaded and moved to {device}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError loading model: {str(e)}\")\n",
    "    \n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"\\nGPU out of memory error. Try:\")\n",
    "        print(\"1. Use a smaller model\")\n",
    "        print(\"2. Free up GPU memory\")\n",
    "        print(\"3. Use CPU instead\")\n",
    "    \n",
    "    elif \"authentication\" in str(e).lower():\n",
    "        print(\"\\nAuthentication error. You need to:\")\n",
    "        print(\"1. Run: huggingface-cli login\")\n",
    "        print(\"2. Or set HUGGING_FACE_TOKEN environment variable\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got an LLM!\n",
    "\n",
    "Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, ok a bunch of layers ranging from embedding layers to attention layers (see the `GemmaFlashAttention2` layers!) to MLP and normalization layers.\n",
    "\n",
    "The good news is that we don't have to know too much about these to use the model.\n",
    "\n",
    "How about we get the number of parameters in our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76961152"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_num_params(model: torch.nn.Module):\n",
    "    return sum([param.numel() for param in model.parameters()])\n",
    "\n",
    "get_model_num_params(llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, turns out that Gemma 7B is really Gemma 8.5B.\n",
    "\n",
    "It pays to do your own investigations!\n",
    "\n",
    "How about we get the models memory requirements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_mem_bytes': 170699520, 'model_mem_mb': 162.79, 'model_mem_gb': 0.16}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_mem_size(model: torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Get how much memory a PyTorch model takes up.\n",
    "\n",
    "    See: https://discuss.pytorch.org/t/gpu-memory-that-model-uses/56822\n",
    "    \"\"\"\n",
    "    # Get model parameters and buffer sizes\n",
    "    mem_params = sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
    "    mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
    "\n",
    "    # Calculate various model sizes\n",
    "    model_mem_bytes = mem_params + mem_buffers # in bytes\n",
    "    model_mem_mb = model_mem_bytes / (1024**2) # in megabytes\n",
    "    model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
    "\n",
    "    return {\"model_mem_bytes\": model_mem_bytes,\n",
    "            \"model_mem_mb\": round(model_mem_mb, 2),\n",
    "            \"model_mem_gb\": round(model_mem_gb, 2)}\n",
    "\n",
    "get_model_mem_size(llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, looks like this model takes up 15.97GB of space on the GPU.\n",
    "\n",
    "Plus a little more for the forward pass (due to all the calculations happening between the layers).\n",
    "\n",
    "Hence why I rounded it up to be ~19GB in the table above.\n",
    "\n",
    "Now let's get to the fun part, generating some text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text with our LLM\n",
    "\n",
    "We can generate text with our LLM `model` instance by calling the [`generate()` method](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig) (this method has plenty of options to pass into it alongside the text) on it and passing it a tokenized input.\n",
    "\n",
    "The tokenized input comes from passing a string of text to our `tokenizer`.\n",
    "\n",
    "It's important to note that you should use a tokenizer that has been paired with a model.\n",
    "\n",
    "Otherwise if you try to use a different tokenizer and then pass those inputs to a model, you will likely get errors/strange results.\n",
    "\n",
    "For some LLMs, there's a specific template you should pass to them for ideal outputs.\n",
    "\n",
    "For example, the `gemma-7b-it` model has been trained in a dialogue fashion (instruction tuning).\n",
    "\n",
    "In this case, our `tokenizer` has a [`apply_chat_template()` method](https://huggingface.co/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.apply_chat_template) which can prepare our input text in the right format for the model.\n",
    "\n",
    "Let's try it out.\n",
    "\n",
    "> **Note:** The following demo has been modified from the Hugging Face model card for [Gemma 7B](https://huggingface.co/google/gemma-7b-it). Many similar demos of usage are available on the model cards of similar models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "What are the macronutrients, and what roles do they play in the human body?\n",
      "\n",
      "Prompt:\n",
      "answer: What are the macronutrients, and what roles do they play in the human body?\n"
     ]
    }
   ],
   "source": [
    "# Define the input text\n",
    "input_text = \"What are the macronutrients, and what roles do they play in the human body?\"\n",
    "print(f\"Input text:\\n{input_text}\")\n",
    "\n",
    "# For T5 models, we can use the input text directly\n",
    "# Optionally, we can add a task prefix to help guide the model\n",
    "prompt = f\"answer: {input_text}\"\n",
    "print(f\"\\nPrompt:\\n{prompt}\")\n",
    "\n",
    "# Tokenize the input\n",
    "model_inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the scaffolding around our input text, this is the kind of turn-by-turn instruction tuning our model has gone through.\n",
    "\n",
    "Our next step is to tokenize this formatted text and pass it to our model's `generate()` method.\n",
    "\n",
    "We'll make sure our tokenized text is on the same device as our model (GPU) using `to(\"cuda\")`.\n",
    "\n",
    "Let's generate some text! \n",
    "\n",
    "We'll time it for fun with the `%%time` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input (tokenized):\n",
      "{'input_ids': tensor([[ 1525,    10,   363,    33,     8, 11663,  8631,   295,     7,     6,\n",
      "            11,   125,  6270,   103,    79,   577,    16,     8,   936,   643,\n",
      "            58,     1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n",
      "\n",
      "Model output (tokens):\n",
      "tensor([   0,    3, 8631,  295,    7,    1], device='cuda:0')\n",
      "\n",
      "CPU times: total: 406 ms\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
    "\n",
    "# Generate outputs passed on the tokenized input\n",
    "# See generate docs: https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/text_generation#transformers.GenerationConfig \n",
    "outputs = llm_model.generate(**input_ids,\n",
    "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
    "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! We just generated some text on our local GPU!\n",
    "\n",
    "Well not just yet...\n",
    "\n",
    "Our LLM accepts tokens in and sends tokens back out.\n",
    "\n",
    "We can conver the output tokens to text using [`tokenizer.decode()`](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer.decode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output (decoded):\n",
      "<pad> nutrients</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode the output tokens to text\n",
    "outputs_decoded = tokenizer.decode(outputs[0])\n",
    "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! That looks like a pretty good answer.\n",
    "\n",
    "But notice how the output contains the prompt text as well?\n",
    "\n",
    "How about we do a little formatting to replace the prompt in the output text?\n",
    "\n",
    "> **Note:** `\"<bos>\"` and `\"<eos>\"` are special tokens to denote \"beginning of sentence\" and \"end of sentence\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: What are the macronutrients, and what roles do they play in the human body?\n",
      "\n",
      "Output text:\n",
      "<pad> nutrients</s>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input text: {input_text}\\n\")\n",
    "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How cool is that!\n",
    "\n",
    "We just officially generated text from an LLM running locally.\n",
    "\n",
    "So we've covered the R (retrieval) and G (generation) of RAG.\n",
    "\n",
    "How about we check out the last step?\n",
    "\n",
    "Augmentation.\n",
    "\n",
    "First, let's put together a list of queries we can try out with our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nutrition-style questions generated with GPT4\n",
    "gpt4_questions = [\n",
    "    \"What are the macronutrients, and what roles do they play in the human body?\",\n",
    "    \"How do vitamins and minerals differ in their roles and importance for health?\",\n",
    "    \"Describe the process of digestion and absorption of nutrients in the human body.\",\n",
    "    \"What role does fibre play in digestion? Name five fibre containing foods.\",\n",
    "    \"Explain the concept of energy balance and its importance in weight management.\"\n",
    "]\n",
    "\n",
    "# Manually created question list\n",
    "manual_questions = [\n",
    "    \"How often should infants be breastfed?\",\n",
    "    \"What are symptoms of pellagra?\",\n",
    "    \"How does saliva help with digestion?\",\n",
    "    \"What is the RDI for protein per day?\",\n",
    "    \"water soluble vitamins\"\n",
    "]\n",
    "\n",
    "query_list = gpt4_questions + manual_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's check if our `retrieve_relevant_resources()` function works with our list of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What role does fibre play in digestion? Name five fibre containing foods.\n",
      "[INFO] Time taken to get scores on 2677 embeddings: 0.00013 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.1573, 0.1559, 0.1558, 0.1553, 0.1534], device='cuda:0'),\n",
       " tensor([2100, 1432, 1461, 1739, 1467], device='cuda:0'))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "query = random.choice(query_list)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Get just the scores and indices of top related results\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                              embeddings=embeddings)\n",
    "scores, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful!\n",
    "\n",
    "Let's augment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting our prompt with context items\n",
    "\n",
    "What we'd like to do with augmentation is take the results from our search for relevant resources and put them into the prompt that we pass to our LLM.\n",
    "\n",
    "In essence, we start with a base prompt and update it with context text.\n",
    "\n",
    "Let's write a function called `prompt_formatter` that takes in a query and our list of context items (in our case it'll be select indices from our list of dictionaries inside `pages_and_chunks`) and then formats the query with text from the context items.\n",
    "\n",
    "We'll apply the dialogue and chat template to our prompt before returning it as well.\n",
    "\n",
    "> **Note:** The process of augmenting or changing a prompt to an LLM is known as prompt engineering. And the best way to do it is an active area of research. For a comprehensive guide on different prompt engineering techniques, I'd recommend the Prompt Engineering Guide ([promptingguide.ai](https://www.promptingguide.ai/)), [Brex's Prompt Engineering Guide](https://github.com/brexhq/prompt-engineering) and the paper [Prompt Design and Engineering: Introduction and Advanced Models](https://arxiv.org/abs/2401.14423)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, \n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "    # Create a base prompt with examples to help the model\n",
    "    # Note: this is very customizable, I've chosen to use 3 examples of the answer style we'd like.\n",
    "    # We could also write this in a txt file and import it in if we wanted.\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "\\nExample 1:\n",
    "Query: What are the fat-soluble vitamins?\n",
    "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
    "\\nExample 2:\n",
    "Query: What are the causes of type 2 diabetes?\n",
    "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
    "\\nExample 3:\n",
    "Query: What is the importance of hydration for physical performance?\n",
    "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good! Let's try our function out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query...\n",
      "\n",
      "Generated prompt:\n",
      "Use the following pieces of context to answer the question. If you cannot find \n",
      "the answer in the context, say \"I don't have enough information to answer that.\"\n",
      "\n",
      "Context 1:\n",
      "{'page_number': 1027, 'sentence_chunk': 'Chapter 30\\u2003  Regular Expressions and Other Packages\\u2003 \\u2002 993 Part II Regular Expression Processing The java.util.regex package supports regular expression processing. As the term is used here, a regular expression is a string of characters that describes a character sequence. This general description, called a pattern, can then be used to find matches in other character sequences. Regular expressions can specify wildcard characters, sets of characters, and various quantifiers. Thus, you can specify a regular expression that represents a general form that can match several different specific character sequences. There are two classes that support regular expression processing: Pattern and Matcher. These classes work together. Use Pattern to define a regular expression. Match the pattern against another sequence using Matcher. Package Primary Function java.security.acl Manages access control lists.', 'chunk_char_count': 907, 'chunk_word_count': 129, 'chunk_token_count': 226.75, 'embedding': array([ 4.06230129e-02,  2.92480644e-02, -1.91196539e-02,  3.56013887e-02,\n",
      "       -5.15845455e-02, -2.17457134e-02,  2.66885720e-02,  4.16576453e-02,\n",
      "       -9.46061872e-03, -3.78687903e-02,  4.82591279e-02, -1.73232853e-02,\n",
      "        2.31258851e-02,  3.82320397e-02, -1.45362830e-02, -3.93920802e-02,\n",
      "        4.56015915e-02,  1.42768156e-02,  7.32384296e-03,  2.84178499e-02,\n",
      "       -1.41214987e-03,  2.11248342e-02,  2.34987997e-02,  5.71913980e-02,\n",
      "       -2.14873590e-02,  5.55237122e-02,  1.59405507e-02, -6.20759539e-02,\n",
      "       -1.80645252e-03, -1.00873165e-01,  3.19874473e-02, -1.76481530e-02,\n",
      "        1.48235112e-02, -3.85631211e-02,  1.91081313e-06, -4.07741517e-02,\n",
      "       -3.97751071e-02,  2.56940387e-02, -4.66785440e-03,  5.61248735e-02,\n",
      "       -4.16693017e-02,  5.20331413e-02, -3.49083580e-02,  1.91780813e-02,\n",
      "        3.45288776e-02,  1.55337639e-02,  5.57846725e-02,  3.28897461e-02,\n",
      "        5.10302074e-02,  4.00091335e-02,  2.13798322e-03, -3.20082754e-02,\n",
      "        1.48796421e-02,  1.96236651e-02,  6.73464909e-02, -4.94202375e-02,\n",
      "        1.03398398e-01,  2.55657709e-03,  3.17346863e-02,  4.42422042e-03,\n",
      "       -1.03831303e-03, -7.26942271e-02, -4.28739823e-02, -5.09531843e-03,\n",
      "       -3.16535011e-02, -6.80385977e-02, -2.21133288e-02, -2.01487932e-02,\n",
      "        1.72234494e-02,  6.31059986e-03,  4.01170962e-02,  1.03567354e-02,\n",
      "        7.40579050e-03,  5.46834394e-02,  3.48485610e-03, -4.90964903e-03,\n",
      "        1.25329457e-02, -5.66731812e-03,  1.31525071e-02, -1.11712646e-02,\n",
      "        2.85012256e-02,  5.28568365e-02, -1.48207406e-02, -1.40755186e-02,\n",
      "       -3.49931419e-02,  3.36820409e-02,  3.44275646e-02, -4.05423753e-02,\n",
      "       -5.28646708e-02, -6.01002239e-02, -4.46827114e-02, -1.06772602e-01,\n",
      "        3.77805494e-02,  2.60394532e-02,  8.34607705e-02,  6.88782055e-03,\n",
      "       -3.46398503e-02, -3.23517397e-02,  5.44421114e-02,  3.31372805e-02,\n",
      "       -2.62163356e-02,  6.06711879e-02, -9.90912085e-04, -2.96607916e-03,\n",
      "       -1.78584680e-02, -2.00612415e-02,  1.82970483e-02,  7.52073899e-03,\n",
      "        5.50609343e-02,  6.91651329e-02,  1.37975421e-02, -1.04865897e-02,\n",
      "       -3.93665247e-02,  1.93103477e-02,  2.09072027e-02,  1.95452943e-02,\n",
      "       -4.91019972e-02,  2.94715483e-02, -3.73440795e-02,  4.14884742e-03,\n",
      "       -3.29070427e-02, -3.02023273e-02,  5.20173460e-02,  1.38911419e-02,\n",
      "       -1.82675514e-02, -8.18564072e-02, -7.48026604e-03, -1.20605780e-02,\n",
      "        8.03998671e-03, -4.39107679e-02,  3.14990319e-02, -1.42769869e-02,\n",
      "        4.16212939e-02,  4.01485618e-03, -2.36758962e-03,  3.69788557e-02,\n",
      "        3.54533717e-02, -2.27478929e-02, -1.47474213e-02,  1.88994803e-03,\n",
      "        4.51090597e-02,  2.38235872e-02, -4.40119952e-02, -2.02776734e-02,\n",
      "       -7.64152482e-02, -2.63511017e-02, -1.32447360e-02, -3.67570668e-03,\n",
      "        2.07140055e-02,  9.11583286e-03,  1.40663367e-02,  2.35639494e-02,\n",
      "        5.57555677e-03, -2.21344293e-03,  1.27004087e-02,  2.61177868e-02,\n",
      "       -7.85531069e-04, -9.12152752e-02, -4.15355079e-02, -1.66470781e-02,\n",
      "        3.28172743e-02, -5.17635420e-02,  6.52980581e-02,  1.31512876e-03,\n",
      "       -5.16291596e-02, -8.62929448e-02, -3.87347154e-02,  3.56788114e-02,\n",
      "        2.58372109e-02, -4.47461084e-02, -5.30879945e-02,  1.26395123e-02,\n",
      "       -5.66740036e-02, -2.37451103e-02, -5.95191419e-02,  1.26564443e-01,\n",
      "        9.08197276e-03,  4.17926721e-02,  4.15914841e-02,  5.27801923e-02,\n",
      "       -2.04886869e-02,  4.28236043e-03,  1.64167751e-02, -2.33022999e-02,\n",
      "       -5.30135185e-02, -3.12280860e-02, -5.57368137e-02,  4.84333448e-02,\n",
      "        1.46112256e-02, -3.03746387e-02, -1.33860065e-02,  1.57203656e-02,\n",
      "       -3.57641801e-02, -8.71360395e-03, -2.34593078e-02, -2.16959994e-02,\n",
      "       -2.56986134e-02, -1.23673687e-02, -2.37093717e-02, -2.46474240e-02,\n",
      "       -1.86449476e-02, -3.34710553e-02,  3.31325457e-02,  7.44330510e-02,\n",
      "        3.82136703e-02, -5.87523356e-02,  2.40218658e-02,  4.26158868e-02,\n",
      "       -7.86763132e-02, -5.07613160e-02,  6.88096043e-03,  1.08102700e-02,\n",
      "        2.50239298e-03, -5.97770587e-02, -2.44686063e-02,  6.11738861e-02,\n",
      "        2.66403835e-02,  3.50376777e-02, -4.31394055e-02, -2.42987387e-02,\n",
      "        3.07439901e-02,  3.99023443e-02, -6.78323861e-03,  3.24740782e-02,\n",
      "        3.71702574e-02, -8.95488858e-02, -3.07730921e-02,  1.86697450e-02,\n",
      "       -5.37025696e-03, -3.95263843e-02,  1.25457961e-02,  3.45285535e-02,\n",
      "        2.38085128e-02,  2.55847331e-02,  1.26485182e-02,  2.43729837e-02,\n",
      "        2.45018005e-02,  5.15440442e-02,  4.17286269e-02, -3.75567116e-02,\n",
      "       -2.45835111e-02,  4.44472469e-02,  2.61467565e-02, -1.48825292e-02,\n",
      "        6.27466589e-02,  1.54762808e-02,  1.74887180e-02, -1.41921258e-02,\n",
      "        1.83713883e-02, -3.65193784e-02,  2.71775629e-02, -2.24760249e-02,\n",
      "       -3.41262706e-02,  3.23910415e-02, -1.28025319e-02, -8.96162912e-03,\n",
      "       -6.42752126e-02,  3.48476507e-02, -6.51881984e-03, -2.33361833e-02,\n",
      "        7.89637677e-03, -5.23785837e-02, -2.50698105e-02,  1.19629465e-02,\n",
      "        5.64398430e-03,  2.65558790e-02, -3.28893512e-02,  6.14746213e-02,\n",
      "       -1.02993511e-02,  1.01418560e-02,  4.14195471e-02,  1.50092982e-03,\n",
      "        2.55568232e-02, -4.14099842e-02,  6.53316919e-03,  1.50875831e-02,\n",
      "       -1.22430623e-02,  2.63497736e-02, -2.65366603e-02,  1.26994019e-02,\n",
      "        1.30336238e-02, -9.41910818e-02, -3.51984724e-02, -1.96751244e-02,\n",
      "       -3.83733101e-02,  1.87915470e-02,  8.22847523e-03, -8.66026729e-02,\n",
      "       -5.42594492e-02,  2.06525121e-02,  1.27274469e-02,  4.18039002e-02,\n",
      "       -3.99433030e-03, -1.75053608e-02, -1.81624629e-02, -2.10632123e-02,\n",
      "       -3.91630530e-02,  3.53531353e-02,  2.39157211e-02,  2.71008676e-03,\n",
      "        1.12918634e-02, -3.33563872e-02, -8.39654077e-03, -2.13933233e-02,\n",
      "        3.43379416e-02,  2.15117820e-02,  1.33942002e-02, -1.21067911e-02,\n",
      "        7.96029791e-02,  4.79382882e-03, -3.11953239e-02, -1.73177123e-02,\n",
      "        5.17368643e-03, -9.45589039e-03,  4.26184461e-02,  2.04073042e-02,\n",
      "       -3.07269185e-03, -5.63939363e-02, -5.50015718e-02,  5.92869706e-02,\n",
      "        9.41480976e-03,  6.59842696e-03,  2.94769760e-02, -8.45936406e-03,\n",
      "        2.30075307e-02, -5.49286380e-02,  1.52717074e-02,  1.26269716e-03,\n",
      "        1.08189113e-03, -6.53064577e-04,  5.94323780e-03,  6.14132509e-02,\n",
      "       -7.39524886e-02,  7.42945895e-02,  1.61499660e-02,  1.08828442e-02,\n",
      "       -1.98767800e-02, -1.98998079e-02,  4.16416582e-03, -2.79141720e-02,\n",
      "       -8.94638430e-03,  2.78203096e-02, -5.43659888e-02, -2.11743917e-02,\n",
      "        2.82136258e-02,  5.89895947e-03,  7.09943939e-03,  2.25836560e-02,\n",
      "       -4.77742106e-02,  3.75700444e-02, -1.29979411e-02, -2.12701112e-02,\n",
      "        6.98023941e-04,  3.17994389e-04, -1.33669777e-02, -1.36517286e-02,\n",
      "       -1.44255124e-02, -2.17752829e-02, -2.44607124e-02,  4.44767624e-02,\n",
      "       -6.53126976e-03,  2.33189855e-02, -3.23416553e-02, -4.15871590e-02,\n",
      "        1.74964219e-02, -1.99298579e-02,  4.48081978e-02, -8.36123452e-02,\n",
      "        4.96568047e-02,  6.65595159e-02, -3.25085223e-02, -3.93720977e-02,\n",
      "        3.57366614e-02,  3.97071987e-02,  1.59696955e-03,  8.76410306e-03,\n",
      "        2.14370973e-02, -2.41819788e-02, -2.58161481e-02,  2.39173956e-02,\n",
      "        1.15741398e-02, -8.20745155e-02,  6.04276285e-02, -1.54173849e-02,\n",
      "       -4.96558063e-02,  1.54511770e-03,  1.65844616e-02,  2.44928664e-03,\n",
      "       -2.82293651e-02, -4.07834630e-03, -8.46422743e-03, -6.60535321e-02,\n",
      "       -4.31415737e-02,  1.80953331e-02,  3.82165872e-02,  3.27357240e-02,\n",
      "       -1.02764263e-03,  5.50484285e-02,  2.13148408e-02, -2.81682308e-03,\n",
      "        2.07127873e-02, -6.40278906e-02, -4.40092646e-02,  5.24267778e-02,\n",
      "       -2.60751899e-02, -1.38472915e-02,  5.33926673e-02,  2.27249376e-02,\n",
      "       -1.88755374e-02, -4.03030366e-02,  3.43478005e-03, -9.25418362e-03,\n",
      "        2.78639831e-02, -1.79752279e-02, -8.41102749e-03,  1.94015913e-02,\n",
      "       -1.19187981e-02,  1.56412143e-02,  7.88788684e-03, -4.44813296e-02,\n",
      "        3.17521347e-03,  6.18974753e-02,  4.84181568e-02,  3.23785320e-02,\n",
      "        5.42936139e-02, -3.27088423e-02,  1.19443247e-02, -1.10839736e-02,\n",
      "       -2.64115371e-02,  8.78847577e-03,  2.82806940e-02, -3.10715102e-02,\n",
      "       -4.46898155e-02,  2.63527241e-02, -8.52830186e-02, -7.30016176e-03,\n",
      "       -8.81462246e-02, -4.41161767e-02, -3.00968420e-02, -5.07040955e-02,\n",
      "        4.74198088e-02,  1.49754910e-02,  4.84622568e-02,  1.61514357e-02,\n",
      "       -3.83131094e-02,  1.35706812e-02, -2.40338058e-03, -5.25993155e-03,\n",
      "       -2.73589008e-02, -1.82975996e-02,  2.10595801e-02, -7.37046171e-03,\n",
      "        2.19320375e-02, -7.48680755e-02,  4.29695435e-02, -7.92216696e-03,\n",
      "       -3.36362831e-02,  4.88903709e-02, -6.62413538e-02,  1.52289530e-03,\n",
      "        4.14936915e-02,  2.14612000e-02, -4.83020991e-02, -2.21829284e-02,\n",
      "       -1.94050893e-02, -1.26038820e-01, -3.17553692e-02,  9.20868479e-03,\n",
      "       -3.66053507e-02,  1.18029397e-03, -6.03826866e-02,  2.12459844e-02,\n",
      "       -4.36313599e-02,  4.87930030e-02,  3.64496931e-02, -3.19266282e-02,\n",
      "       -2.14368794e-02, -2.36947704e-02, -3.37895043e-02,  4.85961549e-02,\n",
      "        6.77149072e-02, -1.94560103e-02, -2.58252397e-03,  6.01904504e-02,\n",
      "        4.86416444e-02, -2.49939095e-02, -2.09937673e-02, -1.61109224e-03,\n",
      "        2.78713442e-02,  2.91934796e-02, -2.75209751e-02,  3.12866680e-02,\n",
      "        1.27086639e-02, -2.41207071e-02, -2.95740534e-02,  3.44953313e-02,\n",
      "        1.76163185e-02,  5.58567010e-02,  1.88233480e-02,  5.70216440e-02,\n",
      "        1.37421582e-02,  4.69198590e-03,  2.91549694e-02, -3.65105458e-02,\n",
      "       -1.97935402e-02,  5.40715642e-03, -8.71380232e-03, -1.50055892e-03,\n",
      "       -4.05213609e-02,  5.28714471e-02, -3.63254808e-02, -3.07804085e-02,\n",
      "       -1.42149711e-02,  1.77772623e-02,  1.48267532e-02,  1.50700780e-02,\n",
      "        3.38848010e-02, -5.04978234e-03, -4.11121771e-02, -8.60149879e-03,\n",
      "        8.08532070e-03, -6.19063852e-03, -1.08535355e-03, -3.26593816e-02,\n",
      "        4.40800888e-03, -3.45858047e-03,  3.39802429e-02, -2.05651652e-02,\n",
      "       -6.56759590e-02,  2.39027999e-02, -1.42862070e-02,  5.54616861e-02,\n",
      "        7.93073513e-03, -5.08398861e-02, -2.82776393e-02,  1.06498683e-02,\n",
      "        3.43301371e-02,  7.91050345e-02, -5.21651376e-03, -4.29953933e-02,\n",
      "        9.14696604e-03,  1.34402150e-02,  1.96144544e-02,  3.66891883e-02,\n",
      "        5.09125628e-02,  4.07112688e-02, -2.71494035e-02,  2.35382933e-02,\n",
      "        2.26205792e-02, -2.75106598e-02,  3.16972937e-03,  2.47681029e-02,\n",
      "       -2.66123395e-02,  2.25050598e-02,  2.11760718e-02, -5.91817398e-33,\n",
      "        1.45906527e-02, -3.86987925e-02, -5.96535974e-04,  3.01443040e-02,\n",
      "        9.77610983e-03, -3.14765377e-04,  5.35638211e-03, -2.89777247e-03,\n",
      "        5.19088935e-03, -2.83479486e-02,  3.53214704e-02,  8.15390050e-03,\n",
      "        1.37084806e-02, -2.60122214e-02,  3.92572396e-03,  4.12276350e-02,\n",
      "        2.50056759e-03,  4.49250005e-02,  7.06975441e-03, -8.78890604e-02,\n",
      "        1.30531108e-02,  3.53832939e-03,  5.46950810e-02,  1.03615895e-02,\n",
      "        2.98182503e-03, -4.48582843e-02, -1.06637727e-03, -6.02240898e-02,\n",
      "       -2.04561725e-02,  4.24844101e-02,  9.39502008e-03,  3.34647222e-04,\n",
      "       -1.96243078e-02,  6.21281117e-02, -3.98354009e-02,  3.24300528e-02,\n",
      "       -4.48456518e-02, -3.34245265e-02, -1.31271565e-02, -1.73147582e-02,\n",
      "        5.95063269e-02, -3.96368019e-02, -2.19078013e-03,  1.16548315e-02,\n",
      "       -4.74555716e-02,  4.11626883e-02,  2.02452075e-02, -4.21797410e-02,\n",
      "        1.11260666e-02,  1.78729407e-02, -4.77878936e-02,  1.28038432e-02,\n",
      "       -2.45512016e-02,  3.08454409e-02,  2.36789882e-02,  8.67835153e-03,\n",
      "        3.34205329e-02, -9.55662224e-03,  6.41460642e-02,  3.32209319e-02,\n",
      "        2.02954076e-02,  4.07879278e-02, -2.83203889e-02,  1.94576606e-02,\n",
      "        4.04221984e-03, -1.94925349e-02, -6.33672401e-02, -3.26468460e-02,\n",
      "       -3.43035394e-03,  3.74353714e-02, -3.15757617e-02,  8.93464014e-02,\n",
      "       -1.47225335e-03, -8.27817060e-03,  1.14619009e-01, -7.05121085e-02,\n",
      "       -1.01360129e-02,  8.47885311e-02,  2.45645605e-02,  1.70512367e-02,\n",
      "       -2.57014614e-02,  4.30146120e-02, -1.72309056e-02,  9.30209178e-03,\n",
      "        2.85654347e-02,  4.68287505e-02, -1.45776728e-02,  1.27297528e-02,\n",
      "        1.76272374e-02, -2.45618541e-02, -3.33430362e-03,  1.06596775e-01,\n",
      "       -7.86945038e-03, -3.91063914e-02, -1.24126114e-02,  3.10864430e-02,\n",
      "       -1.26916617e-02, -4.98606861e-02, -4.33986150e-02, -2.70953681e-02,\n",
      "       -1.30503802e-02, -2.90597770e-02,  2.82600708e-02, -5.53130172e-02,\n",
      "        5.97576192e-03, -5.68917729e-02, -6.10827319e-02, -2.56911898e-03,\n",
      "       -8.23501721e-02, -1.13107730e-02,  1.74274761e-02,  2.40023993e-02,\n",
      "       -1.02961250e-03, -4.48702322e-03,  2.04066578e-02, -2.34565120e-02,\n",
      "        3.52012739e-02, -2.85588596e-02,  1.06679518e-02, -8.53267908e-02,\n",
      "       -1.77235436e-02,  4.88260835e-02,  1.62445847e-02,  2.44313478e-03,\n",
      "       -2.75463331e-02, -2.24533565e-02, -1.24189090e-02,  7.37497071e-03,\n",
      "        4.70714681e-02,  6.44825073e-03, -2.90438137e-03,  9.97547153e-03,\n",
      "        2.64292652e-07,  1.60059389e-02,  3.45397852e-02,  6.62984028e-02,\n",
      "       -3.94916013e-02, -1.06910188e-02, -2.25337651e-02,  3.28470692e-02,\n",
      "       -2.97713839e-03, -3.63897868e-02,  3.02072018e-02,  1.81814749e-02,\n",
      "       -5.81454597e-02, -1.86200887e-02, -5.36160506e-02,  1.66324284e-02,\n",
      "        2.65336093e-02, -2.13875324e-02, -5.30585311e-02, -2.28110347e-02,\n",
      "        1.22795869e-02,  9.31680873e-02, -1.48088727e-02, -1.97455082e-02,\n",
      "       -2.35400791e-03,  1.10627133e-02, -1.13026425e-02,  2.41920445e-03,\n",
      "        1.17413858e-02,  6.80778036e-03,  4.63247448e-02,  7.77130155e-03,\n",
      "       -3.39614376e-02,  4.54388931e-02,  4.15109470e-03, -7.47358706e-03,\n",
      "        2.92221960e-02,  1.47452811e-02,  6.30581081e-02,  2.99932007e-02,\n",
      "        6.20944016e-02, -2.66821329e-02,  1.46245826e-02, -3.03972978e-02,\n",
      "        4.66290936e-02, -6.01519877e-03,  7.84455910e-02, -2.75791157e-02,\n",
      "       -5.77714145e-02, -5.62261529e-02, -2.08620802e-02, -3.57904471e-02,\n",
      "        9.55784414e-03, -1.57666001e-02,  3.94634530e-02,  8.48291349e-03,\n",
      "       -2.26139147e-02, -1.27444090e-02, -3.03732194e-02, -1.59252007e-02,\n",
      "       -3.85404564e-02, -5.88811412e-02,  2.48132627e-02, -8.89918022e-03,\n",
      "        3.61576304e-02,  3.89493220e-02,  7.47648925e-02, -9.73303337e-03,\n",
      "        2.88685227e-34, -1.89828221e-02, -6.66795224e-02, -3.22691984e-02,\n",
      "        3.79261784e-02,  3.48780677e-02,  2.78739482e-02, -6.67377189e-02,\n",
      "        6.12988137e-02, -1.86376907e-02, -3.65285226e-03, -2.47669648e-02])}\n",
      "\n",
      "Context 2:\n",
      "{'page_number': 702, 'sentence_chunk': '668\\u2003 \\u2002 PART II\\u2003  The Java Library DataOutputStream supports all of the methods defined by its superclasses. However, it is the methods defined by the DataOutput interface, which it implements, that make it interesting. DataOutput defines methods that convert values of a primitive type into a byte sequence and then writes it to the underlying stream. Here is a sampling of these methods: final void writeDouble(double value) throws IOException final void writeBoolean(boolean value) throws IOException final void writeInt(int value) throws IOException Here, value is the value written to the stream. DataInputStream is the complement of DataOuputStream. It extends FilterInputStream, which extends InputStream. In addition to implementing the DataInput interface, DataInputStream also implements AutoCloseable and Closeable. Here is its only constructor: DataInputStream(InputStream inputStream) Here, inputStream specifies the input stream from which data will be read. When a DataInputStream is closed (by calling close( )), the underlying stream specified by inputStream is also closed automatically. Like DataOutputStream, DataInputStream supports all of the methods of its superclasses, but it is the methods defined by the DataInput interface that make it unique.', 'chunk_char_count': 1270, 'chunk_word_count': 179, 'chunk_token_count': 317.5, 'embedding': array([-1.31309573e-02,  1.50825763e-02, -6.65557617e-03,  1.09376777e-02,\n",
      "       -5.12203611e-02, -2.46764831e-02, -5.90461912e-03,  3.38580944e-02,\n",
      "       -4.51624729e-02, -3.38091003e-03,  7.25657539e-03,  8.57128017e-03,\n",
      "        1.83465779e-02,  3.18681449e-02,  5.74780535e-03, -6.31311387e-02,\n",
      "        4.03989851e-02, -2.99066026e-03, -4.20052074e-02,  1.71002429e-02,\n",
      "       -1.12751760e-02, -3.55131850e-02,  2.95582619e-02, -4.24609259e-02,\n",
      "        7.52875209e-02, -2.04192251e-02, -3.25703360e-02, -4.97927517e-03,\n",
      "       -6.63001314e-02, -1.27506722e-02,  6.34637708e-03,  2.53356285e-02,\n",
      "       -2.54267128e-03,  2.10777204e-02,  2.11189376e-06,  1.17881354e-02,\n",
      "        2.47194730e-02,  1.32874920e-04, -4.34859730e-02,  5.81033640e-02,\n",
      "       -3.97873893e-02, -7.80050457e-03,  3.87900919e-02,  1.71379745e-02,\n",
      "        4.96558324e-02,  7.19509553e-03,  5.37199713e-02, -3.09995543e-02,\n",
      "        7.82742947e-02, -2.10009958e-03, -4.88762790e-03, -7.07248086e-03,\n",
      "        3.08488496e-02,  1.77775025e-02,  4.60772030e-03,  6.31476194e-02,\n",
      "        1.75758302e-02,  1.32550159e-02,  3.35051082e-02,  2.71839462e-02,\n",
      "       -3.89052518e-02, -6.57298565e-02, -1.56707186e-02, -2.23724749e-02,\n",
      "        2.91068275e-02, -3.79813388e-02, -1.30531136e-02, -3.68347466e-02,\n",
      "        5.00267837e-03,  2.21351665e-02, -3.82582075e-03, -1.09940227e-02,\n",
      "       -2.15518810e-02,  1.67633349e-03, -3.88771668e-02, -5.53118996e-02,\n",
      "        3.69747691e-02, -2.99380943e-02,  2.53520366e-02,  7.96952378e-03,\n",
      "        1.07580889e-02,  8.04081336e-02, -2.70104706e-02, -1.63989402e-02,\n",
      "       -1.65083669e-02, -9.70685109e-03,  2.07888819e-02,  2.37074364e-02,\n",
      "       -4.33461331e-02,  1.46069366e-03,  5.21453377e-03, -6.32620007e-02,\n",
      "        1.23832328e-02,  1.35119939e-02,  3.70004289e-02, -2.02527009e-02,\n",
      "       -1.56976022e-02,  1.43455183e-02,  2.24357918e-02, -2.64662690e-02,\n",
      "        6.48848787e-02,  3.67460363e-02,  5.56127951e-02,  3.01944558e-02,\n",
      "        6.27136454e-02, -6.79982677e-02, -3.05737462e-02, -3.88948880e-02,\n",
      "        1.49723003e-02,  4.55336124e-02,  3.25674936e-02, -3.20589542e-02,\n",
      "        9.62352287e-03,  9.79815200e-02,  4.82115485e-02,  4.68922034e-03,\n",
      "       -2.05285698e-02,  5.23686297e-02, -2.51135789e-03, -1.05304914e-02,\n",
      "       -5.89054339e-02, -4.11220454e-02,  6.88034575e-04, -1.77307595e-02,\n",
      "        1.84448529e-03, -4.45357151e-03, -6.18638657e-03, -7.84272328e-03,\n",
      "        6.36531133e-03, -4.81685996e-02,  1.52629334e-02, -1.38422353e-02,\n",
      "        1.51708256e-02, -1.41770458e-02,  1.64484382e-02, -2.28508394e-02,\n",
      "        3.45476484e-03,  2.02141441e-02, -3.85795720e-02,  1.64641291e-02,\n",
      "        4.90401424e-02, -3.20428796e-02, -2.63039470e-02, -4.86692134e-03,\n",
      "       -5.58265448e-02,  1.08806994e-02, -1.20687264e-03,  1.46847861e-02,\n",
      "       -5.74121159e-03,  1.94537342e-02,  2.02205814e-02, -1.87861675e-03,\n",
      "        6.57697162e-03,  4.69923392e-02,  1.28306681e-02,  5.58556914e-02,\n",
      "        1.40237045e-02,  4.46764100e-03, -6.40826393e-03, -6.61121532e-02,\n",
      "        3.23644443e-03, -6.87337518e-02,  6.26220182e-02,  2.15307046e-02,\n",
      "       -3.31580057e-03, -1.58410799e-02, -5.95075637e-02,  3.12239509e-02,\n",
      "       -6.70902431e-02, -6.08944483e-02, -3.05076931e-02,  2.98216641e-02,\n",
      "        6.68533659e-03,  1.08333826e-02, -8.27677827e-03,  4.23005074e-02,\n",
      "        3.22088413e-02,  5.82090430e-02, -2.69065667e-02,  3.01021449e-02,\n",
      "        4.82360907e-02,  3.82569246e-02,  3.88012081e-02,  6.19875081e-02,\n",
      "        4.04258445e-02,  9.85481218e-03,  1.63591318e-02, -2.91339122e-03,\n",
      "       -4.52948436e-02, -3.52808535e-02, -2.54578684e-02,  3.34760360e-02,\n",
      "       -3.97146642e-02, -2.59112492e-02,  1.07353181e-03,  4.97010257e-03,\n",
      "        1.68322008e-02, -1.46505423e-02, -4.47029285e-02, -3.81922573e-02,\n",
      "       -2.62941699e-03, -1.44278491e-02,  2.96279676e-02,  3.54152396e-02,\n",
      "       -2.46682651e-02, -4.81361151e-02,  4.02726308e-02, -1.39293552e-03,\n",
      "        1.64543372e-02, -3.13713886e-02,  4.32146899e-02, -2.44884822e-03,\n",
      "       -3.89847264e-04, -1.19595490e-02,  2.63366252e-02,  6.82543293e-02,\n",
      "        1.60091799e-02,  1.35002248e-02, -5.60814589e-02,  2.21142340e-02,\n",
      "        1.11721577e-02,  4.15848190e-04, -2.61040069e-02, -2.39935182e-02,\n",
      "        3.39160413e-02, -2.19131298e-02,  1.53545002e-02,  1.88233182e-02,\n",
      "        1.64941400e-02, -2.13605482e-02,  1.16126006e-02,  1.80910807e-02,\n",
      "        2.95089707e-02, -5.15855663e-03,  1.93790589e-02,  1.27878506e-02,\n",
      "        1.10829137e-02,  8.98801908e-02, -2.33766437e-02, -3.05705611e-02,\n",
      "        2.11202144e-03,  7.23045468e-02, -9.85803362e-03, -2.88395360e-02,\n",
      "        1.08496156e-02,  2.16864701e-02,  2.60158312e-02, -3.51634696e-02,\n",
      "        2.38933861e-02, -3.61505561e-02, -1.78019442e-02,  4.66644689e-02,\n",
      "       -3.09011433e-02,  7.60034611e-03,  2.63768267e-02, -3.38567211e-03,\n",
      "       -1.90138295e-02,  2.74559800e-02,  9.60598979e-03, -7.69857094e-02,\n",
      "        6.14357144e-02, -4.75279503e-02, -2.65261810e-02,  3.88621129e-02,\n",
      "        1.17695374e-04, -2.66862810e-02, -3.68422316e-03,  6.82281479e-02,\n",
      "        4.26728949e-02,  3.16473161e-04,  7.91653320e-02,  2.35701799e-02,\n",
      "        5.86758815e-02,  8.44259281e-03,  4.18060459e-03, -8.89585353e-04,\n",
      "       -3.17957741e-03,  4.26080860e-02,  1.44529073e-02,  7.90368989e-02,\n",
      "        8.25322606e-03,  1.82956830e-02,  3.58060561e-02, -4.50024344e-02,\n",
      "        5.78195648e-03,  3.60688493e-02, -1.56180235e-02, -7.95800686e-02,\n",
      "       -2.50393953e-02,  1.54928593e-02, -1.10200103e-02, -5.91945776e-04,\n",
      "        2.05337256e-03, -2.04996243e-02, -2.95197591e-02, -5.18721193e-02,\n",
      "       -6.92540333e-02,  8.79842043e-03,  1.81997102e-02, -5.27080800e-03,\n",
      "       -4.39535044e-02,  4.01021950e-02,  4.28525954e-02, -1.47206914e-02,\n",
      "       -8.82788375e-03,  8.96855164e-03,  7.08804131e-02,  5.44284396e-02,\n",
      "       -2.20840634e-03, -3.21882330e-02, -6.20059855e-02, -5.02947345e-02,\n",
      "        3.67979221e-02, -2.59740814e-03,  2.80845761e-02,  2.43081897e-02,\n",
      "       -1.07896486e-02, -9.54162404e-02, -1.39251072e-03,  7.85604492e-03,\n",
      "       -3.67291830e-02, -2.54519489e-02,  3.35793896e-03,  3.25760879e-02,\n",
      "       -8.81204475e-03,  2.09678188e-02,  2.48900745e-02, -1.99997574e-02,\n",
      "        7.85430521e-02,  4.97194426e-03,  7.61590339e-03, -1.33891460e-02,\n",
      "       -6.36704192e-02,  2.98113432e-02,  4.03549932e-02,  3.23352367e-02,\n",
      "       -5.39097227e-02, -1.18522430e-02, -2.28177551e-02, -4.25204709e-02,\n",
      "       -2.94807106e-02, -2.38345284e-02, -2.57445015e-02,  7.00486265e-03,\n",
      "        1.12318397e-01, -3.74793299e-02, -1.04754679e-02,  1.45110488e-02,\n",
      "        3.49092036e-02,  3.90731776e-03, -1.22773014e-02, -2.01062486e-02,\n",
      "        1.24357827e-02, -2.18150653e-02,  2.45915744e-02,  2.45142073e-05,\n",
      "       -6.21046983e-02, -3.12447753e-02, -3.64564508e-02,  5.46412878e-02,\n",
      "        4.83283587e-02,  7.92098604e-03, -4.71197180e-02, -1.00799056e-03,\n",
      "        4.95295003e-02,  2.31034937e-03,  5.62482066e-02, -2.48823203e-02,\n",
      "       -3.06482278e-02,  2.93284915e-02,  6.75396174e-02, -2.74117608e-02,\n",
      "       -5.33804409e-02, -8.94646719e-03, -1.95449218e-02, -5.30550582e-03,\n",
      "        5.40340878e-03,  3.41613404e-02,  4.49685467e-04,  3.89312319e-02,\n",
      "        8.64807423e-03, -2.94748060e-02,  4.69318107e-02, -2.55382732e-02,\n",
      "       -6.95249811e-03, -2.21451391e-02,  1.50024286e-02, -2.72304472e-02,\n",
      "       -1.99077632e-02,  1.16197243e-02,  2.14718059e-02,  9.23487078e-03,\n",
      "       -4.65115607e-02, -1.84705760e-02,  3.88769023e-02,  2.77012084e-02,\n",
      "       -4.44757156e-02, -2.33707018e-03,  2.12429799e-02,  3.69417481e-02,\n",
      "        5.58716506e-02, -5.27598709e-03,  3.43235359e-02, -6.46929315e-04,\n",
      "        3.68267484e-02, -5.25278486e-02,  4.30528745e-02,  4.56728563e-02,\n",
      "       -2.62977276e-02,  3.08771022e-02,  5.52541241e-02, -6.92337230e-02,\n",
      "       -6.26656786e-02, -8.80939886e-03, -3.77872624e-02,  5.36527559e-02,\n",
      "        4.86080255e-03, -3.27337682e-02,  6.73913658e-02,  1.34462966e-02,\n",
      "        5.77231422e-02, -5.03410101e-02, -7.42582837e-04, -8.20065476e-03,\n",
      "       -1.63684431e-02, -4.31017689e-02, -3.52198035e-02,  3.79850753e-02,\n",
      "        1.26281306e-02, -6.00808859e-02, -1.58263289e-03, -5.32185333e-03,\n",
      "       -2.11717132e-02,  8.54870118e-03, -2.39747018e-03, -3.38117965e-02,\n",
      "       -4.98605184e-02,  2.54985387e-03, -1.08034834e-01, -2.18489859e-03,\n",
      "       -7.46365171e-04, -4.52962406e-02,  3.47931162e-02,  6.51120022e-02,\n",
      "       -3.78594385e-03,  4.92436886e-02, -7.75319785e-02, -5.29888123e-02,\n",
      "       -5.82965277e-02, -9.96870548e-03, -5.22434060e-03,  1.56590119e-02,\n",
      "        2.50663050e-02,  1.79744940e-02,  3.11264358e-02, -3.95370387e-02,\n",
      "        2.60152388e-02, -6.64924681e-02, -4.87969518e-02,  1.11978892e-02,\n",
      "        8.66050869e-02,  2.96801589e-02, -5.18019050e-02,  1.75305599e-04,\n",
      "        4.62672077e-02, -6.79961070e-02,  4.16380540e-02,  7.57197198e-03,\n",
      "       -2.44988259e-02, -6.55058585e-03,  1.82242409e-04,  7.61665171e-03,\n",
      "       -3.22525725e-02,  2.80643180e-02, -6.00307994e-02,  9.14485380e-03,\n",
      "       -9.06832665e-02,  9.99709126e-03, -2.26477645e-02,  3.98639776e-02,\n",
      "        3.78551185e-02, -4.61429320e-02,  6.34403750e-02,  4.24358528e-03,\n",
      "        4.64171693e-02, -4.21206513e-03, -2.85414904e-02, -2.62338780e-02,\n",
      "       -3.38075832e-02,  3.00862230e-02, -1.12564019e-04,  1.52792931e-02,\n",
      "       -4.19460684e-02, -5.92341321e-03,  5.76103590e-02, -1.73142888e-02,\n",
      "        6.63893744e-02,  2.39829645e-02,  1.15187466e-02,  4.25760187e-02,\n",
      "       -2.85428688e-02,  5.08107580e-02, -7.31515791e-03, -1.87884197e-02,\n",
      "        2.74429657e-02,  2.74670552e-02, -6.06312156e-02,  5.50492071e-02,\n",
      "        2.96977051e-02,  6.35649413e-02, -1.36879403e-02, -2.87126359e-02,\n",
      "       -4.25390340e-02,  5.55165745e-02,  9.80646070e-03,  4.16468978e-02,\n",
      "       -2.77407896e-02, -2.41888338e-03, -4.93565612e-02, -4.64567170e-02,\n",
      "        2.76150387e-02, -4.96451370e-02,  4.21040095e-02, -4.55285572e-02,\n",
      "       -1.48867248e-02, -8.74336064e-02,  2.76579522e-02, -1.60946026e-02,\n",
      "       -4.03847322e-02,  1.06164711e-02, -9.35487375e-02,  2.02241819e-02,\n",
      "        2.14684550e-02, -1.25721563e-02, -1.41733559e-02,  2.49100924e-02,\n",
      "       -1.38570312e-02,  8.08987767e-02,  4.06258479e-02, -3.67716067e-02,\n",
      "       -2.64002271e-02, -1.24111734e-02, -9.70829837e-03, -2.23203879e-02,\n",
      "        8.84508416e-02,  1.43081427e-03, -1.76907536e-02, -1.82338397e-03,\n",
      "        3.04034911e-03, -4.73373476e-03, -8.90359655e-03, -9.22928657e-03,\n",
      "       -5.17559946e-02,  1.84337776e-02, -1.29784155e-03, -5.59560511e-33,\n",
      "        2.31405813e-02, -2.30078865e-02, -4.23456207e-02,  1.76158268e-02,\n",
      "        2.40651723e-02, -2.21685469e-02, -1.35488175e-02,  4.26029228e-03,\n",
      "       -2.74379551e-02, -5.66512495e-02,  5.66937216e-03,  3.21720205e-02,\n",
      "        2.14419812e-02, -2.19820533e-03,  2.14502141e-02,  9.87102091e-03,\n",
      "       -1.72229894e-02, -2.05290318e-02, -1.71854571e-02, -2.61547100e-02,\n",
      "        8.29430204e-03, -4.63542454e-02, -3.03551015e-02,  3.67424637e-02,\n",
      "        2.92302854e-02, -8.75942260e-02, -8.50217231e-03, -7.99213722e-03,\n",
      "       -2.10973267e-02, -1.72156170e-02,  1.85686965e-02, -3.77359707e-03,\n",
      "       -1.04031793e-03,  1.24945203e-02, -4.05902490e-02,  2.07235888e-02,\n",
      "       -8.35189298e-02, -1.60706230e-02, -1.00943437e-02,  2.61971299e-02,\n",
      "        5.10517545e-02, -6.76221261e-03,  6.30032318e-03, -7.88200274e-03,\n",
      "       -7.49082770e-03, -6.03287444e-02, -4.80702780e-02,  2.52858102e-02,\n",
      "        2.16993433e-03, -1.23297498e-02, -4.58382536e-04, -2.06790864e-02,\n",
      "       -8.68209526e-02,  8.62749387e-03, -1.29465032e-02,  6.97714183e-03,\n",
      "       -1.16544990e-02, -7.91119188e-02, -2.02373806e-02,  8.67873877e-02,\n",
      "        6.95032477e-02,  2.79300548e-02, -3.61105539e-02, -4.92635854e-02,\n",
      "        2.45209914e-02, -4.58309725e-02,  5.02457507e-02, -3.35206054e-02,\n",
      "        3.89214675e-03,  3.38618644e-02, -9.63813253e-03,  2.85487548e-02,\n",
      "       -4.05224477e-04,  2.47465149e-02,  8.45938399e-02, -9.10285786e-02,\n",
      "        4.54866178e-02,  3.80549729e-02,  1.38677172e-02, -8.68385583e-02,\n",
      "       -4.49294411e-02, -1.00564277e-02, -2.49831825e-02, -3.70157100e-02,\n",
      "        1.14702629e-02, -4.01070118e-02,  1.03774322e-02,  3.34571451e-02,\n",
      "        4.03869115e-02, -1.75284594e-02,  8.35442916e-02,  5.04125841e-02,\n",
      "        1.92431733e-02, -1.11135254e-02, -4.66158241e-02, -1.36393448e-02,\n",
      "        3.20616324e-04,  1.59782004e-02, -1.83730610e-02, -1.16580212e-02,\n",
      "        5.43737337e-02, -3.78621407e-02, -2.68725716e-02,  1.91791356e-02,\n",
      "       -2.10335273e-02, -1.05300266e-02, -9.14164912e-03,  3.33048292e-02,\n",
      "       -2.02065092e-02, -2.62782555e-02,  3.80588649e-03,  2.72485893e-02,\n",
      "        2.32307687e-02, -1.37651507e-02, -3.05708847e-04, -3.89951840e-02,\n",
      "        3.76018398e-02,  3.96103561e-02, -1.08467285e-02, -1.88353565e-02,\n",
      "        1.35364465e-03, -2.04412397e-02, -1.30230570e-02,  1.72414239e-02,\n",
      "        2.09428985e-02, -2.05056779e-02, -2.67311558e-02,  3.08589954e-02,\n",
      "        7.98028111e-02,  3.36734354e-02, -1.35398246e-02,  2.92426087e-02,\n",
      "        2.89313078e-07,  4.35836315e-02, -1.47129651e-02,  4.86509427e-02,\n",
      "        2.07674354e-02, -1.82498004e-02, -2.90050134e-02, -1.91620830e-02,\n",
      "        1.82945747e-02,  3.00482474e-02,  2.56428998e-02,  4.41924557e-02,\n",
      "       -5.68829030e-02, -5.51935518e-03, -7.82983601e-02, -2.64177881e-02,\n",
      "       -6.08321130e-02,  4.40049954e-02, -3.55562940e-02,  8.59576277e-03,\n",
      "       -2.19895765e-02,  8.47048759e-02, -1.30316475e-02, -3.63265760e-02,\n",
      "        3.13180946e-02,  8.84837192e-03, -3.36738825e-02,  2.17928756e-02,\n",
      "        1.46342963e-02,  5.89515343e-02,  1.78972688e-02, -1.58754829e-02,\n",
      "       -2.07903497e-02,  6.43353909e-02, -2.06418466e-02, -4.50683050e-02,\n",
      "       -2.99338065e-02,  7.56631419e-02,  6.41556457e-02,  3.12582254e-02,\n",
      "        3.07458341e-02, -7.92081654e-02,  5.95297702e-02, -1.39916539e-02,\n",
      "        3.79360095e-02,  1.23831211e-02,  5.46956621e-02, -6.95164725e-02,\n",
      "       -3.60331498e-02, -6.70635849e-02,  1.76225733e-02, -2.11914815e-02,\n",
      "        4.37312163e-02,  1.79730100e-03,  2.50679981e-02, -2.55802050e-02,\n",
      "        4.57285065e-03,  5.11004170e-03,  4.29904796e-02, -7.45093897e-02,\n",
      "       -6.90515265e-02, -3.80541161e-02, -2.86235772e-02, -1.09550748e-02,\n",
      "        3.33825685e-02,  7.38003328e-02, -6.66945428e-02, -5.25230803e-02,\n",
      "        2.61205635e-34, -2.74577215e-02, -5.70107475e-02,  2.44925953e-02,\n",
      "        6.08241244e-04, -7.01223034e-03, -1.87219586e-02, -2.68005431e-02,\n",
      "        1.83218401e-02, -1.93969719e-03,  4.93450239e-02, -3.50926854e-02])}\n",
      "\n",
      "Context 3:\n",
      "{'page_number': 715, 'sentence_chunk': 'Input stops when the user presses enter. If the end of the console input stream has been reached, null is returned. An IOError is thrown on failure.char[ ] readPassword( ) Reads a string entered at the keyboard. Input stops when the user presses enter. The string is not displayed. If the end of the console input stream has been reached, null is returned. An IOError is thrown on failure.char[ ] readPassword(String fmtString,                   Object‚Ä¶ args) Displays a prompting string formatted as specified by fmtString and args, and then reads a string entered at the keyboard. Input stops when the user presses enter.', 'chunk_char_count': 623, 'chunk_word_count': 119, 'chunk_token_count': 155.75, 'embedding': array([ 6.01807749e-03, -7.00099915e-02,  6.24063611e-03,  5.01135848e-02,\n",
      "       -1.00930920e-02,  6.40139217e-03, -8.63229204e-03, -8.39415938e-03,\n",
      "        3.37127820e-02,  3.30409482e-02, -2.17301329e-03, -7.46696144e-02,\n",
      "        6.68397769e-02, -1.81396084e-04, -1.81715600e-02, -3.66612710e-02,\n",
      "        1.78672057e-02, -7.21950978e-02, -2.04893816e-02, -3.55350338e-02,\n",
      "        2.19623204e-02,  4.37170127e-03, -4.74364385e-02, -7.91448634e-03,\n",
      "        2.43994482e-02, -2.82777250e-02, -7.69216614e-03, -2.33196653e-02,\n",
      "        9.18600615e-03, -7.83756562e-03, -2.45653242e-02, -1.27035398e-02,\n",
      "       -6.62081409e-03, -7.97925331e-03,  2.04545063e-06, -2.18535997e-02,\n",
      "       -8.18899553e-03,  2.78601656e-03, -9.21493955e-03,  3.52460034e-02,\n",
      "        2.80154478e-02,  1.26731291e-01,  2.64059622e-02,  1.62986815e-02,\n",
      "        5.01197688e-02, -2.41590347e-02,  3.55638117e-02,  4.50983606e-02,\n",
      "        5.98462857e-03, -6.37069903e-03,  3.26310620e-02, -3.70198451e-02,\n",
      "       -5.01248846e-03, -5.92450611e-03, -2.18463410e-02, -4.64579798e-02,\n",
      "        4.82328832e-02, -2.13683732e-02,  4.92396485e-03,  4.37124446e-02,\n",
      "       -5.01079112e-03, -3.89166623e-02,  1.17487289e-04,  6.19144319e-03,\n",
      "        9.69248079e-03,  7.38785565e-02,  3.27002704e-02, -7.50583457e-03,\n",
      "       -4.78812307e-02, -2.12939978e-02,  1.07889213e-02,  5.53729665e-03,\n",
      "        2.49941424e-02,  9.04947799e-03,  2.92569175e-02,  5.82399555e-02,\n",
      "        5.33798747e-02, -2.53497772e-02, -3.52006704e-02, -1.56887434e-02,\n",
      "       -4.77183573e-02,  1.91648789e-02, -5.26660569e-02, -1.88215822e-02,\n",
      "        1.21410778e-02, -1.89859066e-02,  1.36144888e-02, -4.67987061e-02,\n",
      "        1.50211537e-02, -5.86048700e-02,  9.21527506e-04, -3.23899165e-02,\n",
      "       -2.87988484e-02,  1.44295404e-02,  1.53208710e-02, -1.16239861e-03,\n",
      "        4.42509316e-02, -1.08254237e-04,  2.27000695e-02, -4.23847698e-02,\n",
      "       -4.66181263e-02,  4.81190393e-03, -1.82843227e-02,  9.63126216e-03,\n",
      "        1.05026532e-02, -3.43527924e-03,  5.57753332e-02, -3.79629694e-02,\n",
      "        1.51377581e-02,  6.03582859e-02, -3.56853232e-02, -1.04210339e-02,\n",
      "       -2.75047738e-02,  2.63404604e-02,  2.49018688e-02,  9.48100351e-03,\n",
      "        5.18351123e-02, -1.41003393e-02,  5.44890463e-02,  4.60559353e-02,\n",
      "       -1.92102697e-02, -6.74374476e-02,  5.35227358e-02,  4.23508510e-02,\n",
      "       -6.32903278e-02, -2.90058032e-02,  4.32031136e-03, -3.41146365e-02,\n",
      "        2.07975111e-03, -5.66335069e-03,  1.01763541e-02, -3.87610793e-02,\n",
      "       -2.49485113e-02, -1.40571399e-02, -1.14587916e-03,  1.14197554e-02,\n",
      "        1.93369936e-03,  3.22676338e-02, -5.82281165e-02, -6.72886986e-03,\n",
      "        1.29129142e-02, -3.21932770e-02,  5.64437807e-02, -3.83301973e-02,\n",
      "        1.40086720e-02, -7.11347628e-03, -6.80129230e-03,  2.95162406e-02,\n",
      "        6.99233264e-03,  5.37386686e-02,  3.95872593e-02,  5.89610264e-02,\n",
      "        3.68648097e-02, -4.32451107e-02,  5.54923937e-02, -7.62672676e-03,\n",
      "       -3.38733429e-03, -2.02500205e-02, -4.88484502e-02,  5.89629002e-02,\n",
      "        3.86581034e-03, -2.05410812e-02,  4.19864245e-02, -1.55512569e-02,\n",
      "       -5.55833615e-02,  2.31281705e-02,  7.24288896e-02,  3.60221565e-02,\n",
      "        3.57557312e-02,  1.09321214e-02, -1.58925485e-02,  4.30869274e-02,\n",
      "        8.36313330e-03,  5.39928414e-02, -1.95922051e-02,  9.22050104e-02,\n",
      "        3.92626151e-02, -4.63100262e-02,  5.28327450e-02,  2.98030339e-02,\n",
      "        3.03575583e-02,  3.32263671e-02, -1.07227191e-02, -2.46342681e-02,\n",
      "       -1.28481127e-02,  1.61627308e-02,  5.52773476e-03,  1.56385563e-02,\n",
      "        2.47744713e-02,  4.03080955e-02,  4.40328605e-02, -3.63766328e-02,\n",
      "       -2.62556393e-02, -1.49046183e-02,  4.02285419e-02, -4.76066023e-02,\n",
      "        4.69689220e-02, -4.44736071e-02,  2.60161310e-02,  1.98020693e-03,\n",
      "       -1.67291500e-02, -2.75145825e-02,  5.15070818e-02,  3.65546681e-02,\n",
      "       -1.12022031e-02, -1.79784372e-03,  7.01757744e-02, -2.55378429e-04,\n",
      "        6.00773469e-02, -6.53173923e-02,  2.11966559e-02,  7.85725638e-02,\n",
      "       -1.57646444e-02,  1.12187471e-02,  1.91862006e-02,  8.65829661e-02,\n",
      "       -9.18755308e-03,  7.96457753e-02, -4.02020626e-02, -9.61528812e-03,\n",
      "       -6.60858257e-03,  5.48433959e-02,  2.56321840e-02,  2.99147945e-02,\n",
      "       -2.38587819e-02, -1.71995610e-02, -6.93401173e-02,  4.02158462e-02,\n",
      "       -5.02107628e-02,  1.82799008e-02, -6.34814473e-03,  2.44069770e-02,\n",
      "       -2.86304988e-02,  3.34113687e-02, -6.26687519e-03, -2.91896407e-02,\n",
      "       -6.60526082e-02,  1.84825491e-02,  3.82424146e-02, -2.55922489e-02,\n",
      "       -3.58376838e-02,  1.87694710e-02,  5.03253285e-03,  6.97614951e-03,\n",
      "        6.90525472e-02, -3.28223817e-02,  1.79271903e-02, -3.32217105e-02,\n",
      "       -1.38293719e-02, -7.65827252e-03, -4.88527380e-02, -7.26115238e-03,\n",
      "        1.44874696e-02,  1.00494502e-02,  3.48300822e-02, -2.00769044e-02,\n",
      "       -1.67207737e-02, -3.67726386e-02, -8.68109912e-02, -1.18603921e-02,\n",
      "        2.70119030e-02, -1.41696911e-02, -3.48333046e-02,  1.68062653e-02,\n",
      "        3.06380680e-03, -3.17814536e-02,  1.43182334e-02,  3.86529826e-02,\n",
      "       -3.26029435e-02, -9.41331440e-04, -1.55393630e-02,  1.23451045e-02,\n",
      "       -1.68375541e-02, -3.28711271e-02,  3.43610048e-02, -1.81127631e-03,\n",
      "       -3.22958492e-02, -4.60973792e-02, -4.82753329e-02,  7.11822417e-03,\n",
      "        2.54134666e-02,  1.42335529e-02, -1.22626266e-03, -1.45086963e-02,\n",
      "       -1.00959577e-02, -2.61227041e-02, -3.44742537e-02, -8.03553015e-02,\n",
      "        3.53566837e-03,  7.63707655e-03,  8.38964581e-02,  1.00744329e-02,\n",
      "       -4.09410670e-02, -1.96611974e-03, -1.00958562e-02, -4.20764461e-02,\n",
      "        7.10487599e-03, -3.41923572e-02,  3.98105122e-02, -3.10014555e-04,\n",
      "        1.96820460e-02,  3.96711491e-02, -2.52697561e-02,  7.04576168e-03,\n",
      "        6.32519871e-02,  2.56380569e-02,  7.32882097e-02, -2.31109858e-02,\n",
      "        3.73397022e-02, -2.18565539e-02,  5.33634657e-03,  3.36819068e-02,\n",
      "       -5.32060862e-02,  2.79785898e-02,  3.26281264e-02,  1.04200635e-02,\n",
      "       -3.50679904e-02, -2.57649366e-02, -6.39707819e-02, -5.23859747e-02,\n",
      "       -4.39605862e-02,  1.59311257e-02,  5.77380769e-02, -8.36725533e-02,\n",
      "       -4.30579707e-02,  7.02259922e-03,  2.51785517e-02,  5.29263020e-02,\n",
      "        1.54538238e-02,  1.22595150e-02, -2.41360385e-02,  8.38469863e-02,\n",
      "       -9.04816538e-02,  7.27385208e-02, -2.88697705e-03, -1.29472632e-02,\n",
      "       -2.11550836e-02,  1.86198018e-02, -1.54265426e-02, -4.53215204e-02,\n",
      "       -3.69275697e-02,  6.39456883e-02,  1.19320052e-02, -1.88407917e-02,\n",
      "       -1.53715936e-02, -6.57746121e-02, -4.10918891e-03, -5.00586890e-02,\n",
      "        4.62096781e-02, -3.47638465e-02,  3.26610059e-02,  2.45797653e-02,\n",
      "       -3.09781879e-02,  4.63055708e-02,  1.17212720e-02, -4.48255278e-02,\n",
      "       -1.82290673e-02, -3.14949284e-04, -5.00076413e-02, -2.53010690e-02,\n",
      "        5.53285852e-02, -4.32249196e-02, -3.39213647e-02, -5.95255010e-02,\n",
      "        1.85928456e-02, -4.06928845e-02, -1.42833246e-02, -3.97088192e-02,\n",
      "        4.99495789e-02,  6.16107769e-02,  1.58787630e-02, -2.51322538e-02,\n",
      "        3.76742706e-03, -1.40374107e-02,  1.33563681e-02,  1.16850603e-02,\n",
      "       -1.01397876e-02, -1.82226188e-02, -4.26038429e-02, -2.58199051e-02,\n",
      "       -1.72807015e-02, -8.61709099e-03,  1.07264519e-02,  1.81193911e-02,\n",
      "        1.00611001e-01,  2.77359281e-02,  7.31929531e-03, -2.42943857e-02,\n",
      "       -8.83577857e-03, -2.71132309e-02, -1.23884734e-02,  1.14550516e-02,\n",
      "       -7.95587450e-02,  2.07063928e-02,  9.23253410e-03,  2.81961095e-02,\n",
      "        8.37380160e-03,  5.76283671e-02,  7.02640880e-03, -6.80804951e-03,\n",
      "       -3.79638444e-03, -1.03400378e-02,  5.95792122e-02,  5.19211292e-02,\n",
      "        1.76480357e-02,  1.79776233e-02,  2.37572715e-02, -3.26601020e-03,\n",
      "        2.27995142e-02, -3.18478011e-02,  4.38264832e-02, -4.81833816e-02,\n",
      "        9.37521458e-03, -1.82003155e-02, -4.02539484e-02,  1.22522665e-02,\n",
      "        2.34246962e-02, -6.48682180e-04,  4.40475121e-02,  4.16088626e-02,\n",
      "       -1.19543849e-02,  6.52569830e-02, -1.12235267e-02,  2.69549638e-02,\n",
      "       -2.82962974e-02, -8.92795157e-03,  1.87805071e-02,  1.55629066e-03,\n",
      "       -7.12124212e-03,  2.70581059e-02,  1.69886816e-02, -1.60420388e-02,\n",
      "       -2.25194767e-02, -2.57731490e-02, -4.76241596e-02, -4.60088998e-02,\n",
      "       -1.77015197e-02,  4.52580713e-02,  5.12175336e-02,  1.25042787e-02,\n",
      "       -2.00171787e-02, -1.05430093e-02, -2.48825457e-02, -5.99233098e-02,\n",
      "       -3.33379321e-02,  1.99686326e-02, -7.19918543e-03,  4.62537780e-02,\n",
      "       -4.67382697e-03, -3.86657640e-02,  1.41445147e-02, -8.62464402e-03,\n",
      "        2.66109798e-02, -6.84813559e-02, -2.13418063e-02, -8.13154057e-02,\n",
      "       -1.87657271e-02,  2.27688495e-02, -5.06979637e-02,  3.33944932e-02,\n",
      "        2.21021473e-02, -2.39245244e-03, -4.03853431e-02, -4.13301438e-02,\n",
      "       -1.54188415e-02, -2.31037196e-02, -6.36661127e-02, -2.74483059e-02,\n",
      "       -3.92753705e-02, -3.74007486e-02, -6.47440320e-03,  6.31707013e-02,\n",
      "       -8.02078620e-02,  7.22183287e-03, -5.71496151e-02, -7.29613984e-03,\n",
      "       -8.55775997e-02,  2.08382327e-02,  1.98073220e-03, -6.58228341e-03,\n",
      "        3.32757644e-02,  9.16753546e-04, -1.81118324e-02,  3.97895910e-02,\n",
      "        2.85524502e-02,  4.09067348e-02, -3.20658572e-02, -4.86138416e-03,\n",
      "        1.28250392e-02, -3.71597288e-03, -8.42917897e-03,  1.34705482e-02,\n",
      "        2.44118758e-02, -1.17565490e-01, -2.02403627e-02,  4.68655564e-02,\n",
      "        5.42388558e-02,  6.87286854e-02,  8.98756385e-02,  2.81169172e-02,\n",
      "        3.10523566e-02, -5.19985259e-02, -5.02564758e-02, -2.07331777e-03,\n",
      "       -2.31980197e-02,  1.46606157e-03, -3.83798629e-02,  5.36066853e-02,\n",
      "        2.15974543e-03,  2.52778619e-03, -7.21351616e-03,  1.03622647e-02,\n",
      "       -4.57642265e-02, -2.11802814e-02,  5.23559041e-02, -5.56886569e-03,\n",
      "       -2.12349147e-02, -5.70032224e-02, -6.85339496e-02, -3.25834341e-02,\n",
      "        3.05615570e-02, -7.81809241e-02,  4.65848111e-03, -2.24148799e-02,\n",
      "        5.10754576e-03,  3.96304997e-04,  3.22492272e-02,  1.98460221e-02,\n",
      "       -4.97168340e-02, -1.01081403e-02, -4.47752401e-02, -1.23260533e-02,\n",
      "        4.40157801e-02,  1.16001740e-02, -3.04221120e-02, -7.98095483e-03,\n",
      "        2.43625063e-02,  2.88201515e-02, -6.85005561e-02, -2.61127688e-02,\n",
      "        2.66236700e-02,  3.74505334e-02, -1.36501174e-02,  6.67097699e-03,\n",
      "       -8.16936698e-03,  1.09412046e-02,  8.73304904e-04, -3.87726091e-02,\n",
      "       -2.95864269e-02, -8.92976020e-03, -3.77064105e-03,  5.24307862e-02,\n",
      "        2.35351417e-02, -4.01146077e-02, -3.71589400e-02, -5.19676281e-33,\n",
      "       -1.34384185e-02, -3.96721764e-03, -2.38372330e-02,  5.28194383e-02,\n",
      "       -1.19537236e-02, -8.03482011e-02,  7.11032888e-04,  6.22321703e-02,\n",
      "       -1.98624246e-02,  3.43299508e-02,  1.41066005e-02, -1.29932957e-02,\n",
      "        2.10802611e-02,  1.69525873e-02, -2.00812612e-02, -1.63074527e-02,\n",
      "       -1.33819245e-02,  2.09999792e-02,  3.05179283e-02, -2.96759903e-02,\n",
      "       -1.20100724e-02,  4.75328788e-02,  4.01992761e-02,  1.52496323e-02,\n",
      "        1.00056648e-01, -4.34475839e-02, -9.67605098e-04, -8.46839231e-03,\n",
      "        1.74453687e-02, -5.01076644e-03,  4.35791686e-02, -4.75409062e-04,\n",
      "        5.18103018e-02, -7.95974284e-02,  6.18490856e-03,  1.22906774e-01,\n",
      "       -1.28626833e-02,  1.01240939e-02,  5.32843918e-02,  2.49837097e-02,\n",
      "        3.27760577e-02, -2.86187157e-02, -2.20258608e-02, -5.01130447e-02,\n",
      "        1.45633984e-02, -1.74049870e-03,  5.78295719e-03,  5.83247840e-03,\n",
      "        4.57453765e-02, -4.61681522e-02,  2.03372892e-02,  1.45232789e-02,\n",
      "        4.32864763e-03, -9.80430190e-03, -1.69344489e-02,  5.82805388e-02,\n",
      "        5.38223796e-03, -8.21525529e-02,  2.93790158e-02, -2.02864874e-02,\n",
      "        3.95912901e-02, -2.00864058e-02, -6.49812669e-02,  2.29464676e-02,\n",
      "       -2.86159497e-02, -2.21222118e-02, -2.84541957e-02, -9.46234614e-02,\n",
      "       -4.13231291e-02,  4.64888364e-02, -3.95451039e-02, -7.82696456e-02,\n",
      "        3.15574445e-02,  2.86343824e-02,  7.22679868e-03, -5.03657833e-02,\n",
      "       -2.85462681e-02, -3.14032286e-02, -5.01002977e-03,  5.25949262e-02,\n",
      "       -5.33336482e-04, -4.67049219e-02, -2.92226654e-02,  2.09026574e-03,\n",
      "        5.57949301e-03,  2.48501939e-03, -2.37969272e-02, -2.73465104e-02,\n",
      "        3.71382385e-03, -4.74845953e-02,  2.87320465e-02, -3.10178306e-02,\n",
      "        9.49167553e-03,  1.97680462e-02,  2.82720500e-03, -5.30773290e-02,\n",
      "        4.71052714e-02, -7.39566162e-02, -2.51386389e-02,  4.69091497e-02,\n",
      "        2.95840204e-02,  3.25330198e-02,  5.09051867e-02,  3.21478210e-02,\n",
      "       -2.00870656e-03,  4.89642960e-04, -9.11367014e-02, -4.12472105e-03,\n",
      "       -6.44516386e-03,  2.92650447e-03,  1.53260576e-02, -1.51058659e-03,\n",
      "       -1.52981374e-02,  1.03599042e-01,  4.58324850e-02, -3.08017116e-02,\n",
      "       -3.32606235e-03, -5.31196781e-02,  1.67674404e-02, -6.22206628e-02,\n",
      "       -2.10867543e-02,  4.48814780e-02,  3.08874855e-03,  6.05982579e-02,\n",
      "       -3.14893201e-02,  5.03082573e-03, -3.25367823e-02,  1.42590953e-02,\n",
      "        6.44593313e-02,  4.17355858e-02,  6.39230758e-02,  1.75143592e-02,\n",
      "        2.68048694e-07,  3.71543244e-02,  2.30103377e-02,  3.89046706e-02,\n",
      "        2.59587578e-02, -2.04731580e-02,  3.20008956e-02, -3.89184095e-02,\n",
      "        2.64698383e-03,  3.30940410e-02, -2.82744672e-02, -3.78516200e-03,\n",
      "       -2.64027622e-02, -1.56185078e-03, -4.05076668e-02, -8.44258592e-02,\n",
      "       -6.04087412e-02, -4.53142263e-03,  2.70544961e-02, -2.00970545e-02,\n",
      "        3.56823206e-02,  9.30715501e-02, -2.80863792e-02, -2.32700240e-02,\n",
      "        2.23125592e-02,  5.04357703e-02, -5.21504432e-02, -3.16234641e-02,\n",
      "        3.03309690e-02,  2.62782294e-02, -3.45613174e-02,  3.37409489e-02,\n",
      "        1.43013215e-02,  5.10854870e-02,  9.75696277e-03,  9.73213650e-03,\n",
      "       -1.00383647e-02,  1.52673228e-02,  1.82587542e-02,  3.78835760e-02,\n",
      "       -1.95188522e-02,  3.76593880e-03,  7.00569060e-03, -4.60626110e-02,\n",
      "       -5.76762622e-03,  5.43438364e-03,  3.37281898e-02,  5.70069514e-02,\n",
      "       -2.06742622e-02,  1.02606667e-02, -1.28202820e-02, -3.13849375e-02,\n",
      "        4.18662233e-03, -7.74126267e-03,  3.97284329e-02,  1.65569838e-02,\n",
      "        1.63800642e-02,  4.70054522e-02,  2.08497383e-02, -5.71070313e-02,\n",
      "       -3.58672552e-02, -7.63681680e-02, -1.72934551e-02, -9.37748794e-03,\n",
      "        9.86511726e-03,  2.48108171e-02, -5.33016548e-02, -3.67366448e-02,\n",
      "        2.21427871e-34, -1.24359387e-03, -3.27195483e-03,  1.97321605e-02,\n",
      "        2.36070268e-02, -2.06110086e-02,  1.79382134e-02, -2.24184263e-02,\n",
      "        8.50643218e-03, -2.68693152e-03,  2.88054012e-02, -4.09247465e-02])}\n",
      "\n",
      "Question: What role does fibre play in digestion? Name five fibre containing foods.\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "# Define helper functions first\n",
    "def retrieve_relevant_resources(query, embeddings, k=3):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant text chunks based on similarity to the query\n",
    "    \"\"\"\n",
    "    # Get query embedding\n",
    "    query_embedding = embedding_model.encode([query])[0]  # Get the first (and only) embedding\n",
    "    query_embedding = torch.tensor(query_embedding).to(device)\n",
    "    \n",
    "    # Calculate similarity scores\n",
    "    scores = torch.matmul(embeddings, query_embedding)\n",
    "    \n",
    "    # Get top k scores and indices\n",
    "    top_k_scores, top_k_indices = torch.topk(scores, k=min(k, len(scores)))\n",
    "    \n",
    "    return top_k_scores, top_k_indices\n",
    "\n",
    "def prompt_formatter(query, context_items):\n",
    "    \"\"\"\n",
    "    Format the prompt with context information\n",
    "    \"\"\"\n",
    "    # Combine context items into a single string\n",
    "    context = \"\\n\\n\".join([f\"Context {i+1}:\\n{item}\" for i, item in enumerate(context_items)])\n",
    "    \n",
    "    # Create the full prompt\n",
    "    prompt = f\"\"\"Use the following pieces of context to answer the question. If you cannot find \n",
    "the answer in the context, say \"I don't have enough information to answer that.\"\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer: \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Now use the functions\n",
    "print(\"Processing query...\")\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                           embeddings=embeddings)\n",
    "    \n",
    "# Create a list of context items\n",
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "# Format prompt with context items\n",
    "prompt = prompt_formatter(query=query,\n",
    "                        context_items=context_items)\n",
    "print(\"\\nGenerated prompt:\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a good looking prompt!\n",
    "\n",
    "We can tokenize this and pass it straight to our LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query...\n",
      "\n",
      "Generating response...\n",
      "Generating response...\n",
      "\n",
      "Model's response:\n",
      "14.235423803][by130187\n"
     ]
    }
   ],
   "source": [
    "# Generate response using the T5 model\n",
    "def generate_response(prompt, max_length=512):\n",
    "    \"\"\"\n",
    "    Generate a response using the T5 model\n",
    "    \"\"\"\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    \n",
    "    # Generate response\n",
    "    print(\"Generating response...\")\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        outputs = llm_model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,  # Control randomness (higher = more random)\n",
    "            do_sample=True,   # Use sampling instead of greedy decoding\n",
    "            no_repeat_ngram_size=2  # Avoid repeating 2-grams\n",
    "        )\n",
    "    \n",
    "    # Decode the response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Now use the functions\n",
    "print(\"Processing query...\")\n",
    "scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                           embeddings=embeddings)\n",
    "\n",
    "# Create a list of context items\n",
    "context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "# Format prompt with context items\n",
    "prompt = prompt_formatter(query=query,\n",
    "                        context_items=context_items)\n",
    "\n",
    "# Generate and print the response\n",
    "print(\"\\nGenerating response...\")\n",
    "response = generate_response(prompt)\n",
    "print(\"\\nModel's response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yesssssss!!!\n",
    "\n",
    "Our RAG pipeline is complete!\n",
    "\n",
    "We just Retrieved, Augmented and Generated!\n",
    "\n",
    "And all on our own local GPU!\n",
    "\n",
    "How about we functionize the generation step to make it easier to use?\n",
    "\n",
    "We can put a little formatting on the text being returned to make it look nice too.\n",
    "\n",
    "And we'll make an option to return the context items if needed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get just the scores and indices of top related results\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings)\n",
    "    \n",
    "    # Create a list of context items\n",
    "    context_items = [pages_and_chunks[i] for i in indices]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i].cpu() # return score back to CPU \n",
    "        \n",
    "    # Format the prompt with context items\n",
    "    prompt = prompt_formatter(query=query,\n",
    "                              context_items=context_items)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llm_model.generate(**input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return output_text\n",
    "    \n",
    "    return output_text, context_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a good looking function!\n",
    "\n",
    "The workflow could probably be a little refined but this should work!\n",
    "\n",
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the key benefits of exercise?\n",
      "Error in ask function: generate_response() got an unexpected keyword argument 'temperature'\n",
      "\n",
      "Answer: I'm sorry, I encountered an error while trying to answer your question.\n"
     ]
    }
   ],
   "source": [
    "def ask(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The question to ask\n",
    "        temperature (float): Controls randomness in generation (0.0 to 1.0)\n",
    "        max_new_tokens (int): Maximum length of generated response\n",
    "        format_answer_text (bool): Whether to format the answer text nicely\n",
    "        return_answer_only (bool): If True, returns only the answer. If False, returns (answer, context_items)\n",
    "    \n",
    "    Returns:\n",
    "        str or tuple: Generated answer text, or tuple of (answer, context_items) if return_answer_only=False\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Get relevant resources\n",
    "        scores, indices = retrieve_relevant_resources(query=query, embeddings=embeddings)\n",
    "        context_items = [pages_and_chunks[i] for i in indices]\n",
    "        \n",
    "        # 2. Format the prompt with context\n",
    "        prompt = prompt_formatter(query=query, context_items=context_items)\n",
    "        \n",
    "        # 3. Generate response\n",
    "        response = generate_response(\n",
    "            prompt,\n",
    "            max_length=max_new_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        # 4. Format the response if requested\n",
    "        if format_answer_text:\n",
    "            # Remove any extra whitespace and newlines\n",
    "            response = ' '.join(response.split())\n",
    "            # Capitalize first letter\n",
    "            response = response[0].upper() + response[1:] if response else response\n",
    "            # Add period if missing\n",
    "            if response and response[-1] not in '.!?':\n",
    "                response += '.'\n",
    "        \n",
    "        # 5. Return results\n",
    "        if return_answer_only:\n",
    "            return response\n",
    "        else:\n",
    "            return response, context_items\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ask function: {str(e)}\")\n",
    "        return \"I'm sorry, I encountered an error while trying to answer your question.\"\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the key benefits of exercise?\"\n",
    "print(\"Question:\", query)\n",
    "print(\"\\nAnswer:\", ask(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local RAG workflow complete!\n",
    "\n",
    "We've now officially got a way to Retrieve, Augment and Generate answers based on a source.\n",
    "\n",
    "For now we can verify our answers manually by reading them and reading through the textbook.\n",
    "\n",
    "But if you want to put this into a production system, it'd be a good idea to have some kind of evaluation on how well our pipeline works.\n",
    "\n",
    "For example, you could use another LLM to rate the answers returned by our LLM and then use those ratings as a proxy evaluation.\n",
    "\n",
    "However, I'll leave this and a few more interesting ideas as extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "* May want to improve text extraction with something like Marker - https://github.com/VikParuchuri/marker\n",
    "* Guide to more advanced PDF extraction - https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517 \n",
    "* See the following prompt engineering resources for more prompting techniques - promptinguide.ai, Brex's Prompt Engineering Guide \n",
    "* What happens when a query comes through that there isn't any context in the textbook on?\n",
    "* Try another embedding model (e.g. Mixed Bread AI large, `mixedbread-ai/mxbai-embed-large-v1`, see: https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1)\n",
    "* Try another LLM... (e.g. Mistral-Instruct)\n",
    "* Try different prompts (e.g. see prompting techniques online)\n",
    "* Our example only focuses on text from a PDF, however, we could extend it to include figures and images \n",
    "* Evaluate the answers -> could use another LLM to rate our answers (e.g. use GPT-4 to make)\n",
    "* Vector database/index for larger setup (e.g. 100,000+ chunks)\n",
    "* Libraries/frameworks such as LangChain / LlamaIndex can help do many of the steps for you - so it's worth looking into those next, wanted to recreate a workflow with lower-level tools to show the principles\n",
    "* Optimizations for speed\n",
    "    * See Hugging Face docs for recommended speed ups on GPU - https://huggingface.co/docs/transformers/perf_infer_gpu_one \n",
    "    * Optimum NVIDIA - https://huggingface.co/blog/optimum-nvidia, GitHub: https://github.com/huggingface/optimum-nvidia \n",
    "    * See NVIDIA TensorRT-LLM - https://github.com/NVIDIA/TensorRT-LLM \n",
    "    * See GPT-Fast for PyTorch-based optimizations - https://github.com/pytorch-labs/gpt-fast \n",
    "    * Flash attention 2 (requires Ampere GPUs or newer) - https://github.com/Dao-AILab/flash-attention\n",
    "* Stream text output so it looks prettier (e.g. each token appears as it gets output from the model)\n",
    "* Turn the workflow into an app, see Gradio type chatbots for this - https://www.gradio.app/guides/creating-a-chatbot-fast, see local example: https://www.gradio.app/guides/creating-a-chatbot-fast#example-using-a-local-open-source-llm-with-hugging-face "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

